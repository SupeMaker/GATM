2024-03-25 18:20:13,347 - train - INFO - PretrainedBaseline(
  (model): BertForSequenceClassification(
    (bert): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0-11): 12 x BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (classifier): Linear(in_features=768, out_features=11, bias=True)
  )
)
Trainable params: 102,276,107
Freeze params: 0
2024-03-25 18:21:29,220 - train - INFO - PretrainedBaseline(
  (model): BertForSequenceClassification(
    (bert): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0-11): 12 x BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (classifier): Linear(in_features=768, out_features=11, bias=True)
  )
)
Trainable params: 102,276,107
Freeze params: 0
2024-03-26 18:45:14,502 - train - INFO - PretrainedBaseline(
  (model): BertForSequenceClassification(
    (bert): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (classifier): Linear(in_features=768, out_features=11, bias=True)
  )
)
Trainable params: 24,309,515
Freeze params: 0
2024-03-26 18:51:48,696 - trainer - INFO -     epoch          : 1
2024-03-26 18:51:48,696 - trainer - INFO -     loss           : 0.712084
2024-03-26 18:51:48,696 - trainer - INFO -     accuracy       : 0.7943
2024-03-26 18:51:48,696 - trainer - INFO -     macro_f        : 0.791817
2024-03-26 18:51:48,696 - trainer - INFO -     precision      : 0.83872
2024-03-26 18:51:48,696 - trainer - INFO -     recall         : 0.7943
2024-03-26 18:51:48,696 - trainer - INFO -     val_loss       : 0.625736
2024-03-26 18:51:48,696 - trainer - INFO -     val_accuracy   : 0.815273
2024-03-26 18:51:48,696 - trainer - INFO -     val_macro_f    : 0.81656
2024-03-26 18:51:48,696 - trainer - INFO -     val_precision  : 0.867954
2024-03-26 18:51:48,696 - trainer - INFO -     val_recall     : 0.815273
2024-03-26 18:51:48,696 - trainer - INFO -     test_loss      : 0.608589
2024-03-26 18:51:48,696 - trainer - INFO -     test_accuracy  : 0.818909
2024-03-26 18:51:48,696 - trainer - INFO -     test_macro_f   : 0.821253
2024-03-26 18:51:48,696 - trainer - INFO -     test_precision : 0.871311
2024-03-26 18:51:48,696 - trainer - INFO -     test_recall    : 0.818909
2024-03-26 18:58:30,920 - trainer - INFO -     epoch          : 2
2024-03-26 18:58:30,920 - trainer - INFO -     loss           : 0.518156
2024-03-26 18:58:30,920 - trainer - INFO -     accuracy       : 0.850927
2024-03-26 18:58:30,920 - trainer - INFO -     macro_f        : 0.850155
2024-03-26 18:58:30,920 - trainer - INFO -     precision      : 0.886902
2024-03-26 18:58:30,920 - trainer - INFO -     recall         : 0.850927
2024-03-26 18:58:30,920 - trainer - INFO -     val_loss       : 0.540248
2024-03-26 18:58:30,920 - trainer - INFO -     val_accuracy   : 0.845636
2024-03-26 18:58:30,920 - trainer - INFO -     val_macro_f    : 0.845367
2024-03-26 18:58:30,920 - trainer - INFO -     val_precision  : 0.883318
2024-03-26 18:58:30,920 - trainer - INFO -     val_recall     : 0.845636
2024-03-26 18:58:30,920 - trainer - INFO -     test_loss      : 0.530977
2024-03-26 18:58:30,920 - trainer - INFO -     test_accuracy  : 0.850091
2024-03-26 18:58:30,920 - trainer - INFO -     test_macro_f   : 0.848561
2024-03-26 18:58:30,920 - trainer - INFO -     test_precision : 0.883991
2024-03-26 18:58:30,920 - trainer - INFO -     test_recall    : 0.850091
2024-03-26 19:05:15,526 - trainer - INFO -     epoch          : 3
2024-03-26 19:05:15,526 - trainer - INFO -     loss           : 0.479006
2024-03-26 19:05:15,526 - trainer - INFO -     accuracy       : 0.860336
2024-03-26 19:05:15,526 - trainer - INFO -     macro_f        : 0.859857
2024-03-26 19:05:15,526 - trainer - INFO -     precision      : 0.895377
2024-03-26 19:05:15,526 - trainer - INFO -     recall         : 0.860336
2024-03-26 19:05:15,526 - trainer - INFO -     val_loss       : 0.568054
2024-03-26 19:05:15,526 - trainer - INFO -     val_accuracy   : 0.839909
2024-03-26 19:05:15,526 - trainer - INFO -     val_macro_f    : 0.83965
2024-03-26 19:05:15,541 - trainer - INFO -     val_precision  : 0.88041
2024-03-26 19:05:15,541 - trainer - INFO -     val_recall     : 0.839909
2024-03-26 19:05:15,541 - trainer - INFO -     test_loss      : 0.543732
2024-03-26 19:05:15,541 - trainer - INFO -     test_accuracy  : 0.845182
2024-03-26 19:05:15,541 - trainer - INFO -     test_macro_f   : 0.845646
2024-03-26 19:05:15,541 - trainer - INFO -     test_precision : 0.886255
2024-03-26 19:05:15,541 - trainer - INFO -     test_recall    : 0.845182
2024-03-26 19:12:04,597 - trainer - INFO -     epoch          : 4
2024-03-26 19:12:04,597 - trainer - INFO -     loss           : 0.456188
2024-03-26 19:12:04,597 - trainer - INFO -     accuracy       : 0.866209
2024-03-26 19:12:04,597 - trainer - INFO -     macro_f        : 0.865138
2024-03-26 19:12:04,597 - trainer - INFO -     precision      : 0.898804
2024-03-26 19:12:04,597 - trainer - INFO -     recall         : 0.866209
2024-03-26 19:12:04,597 - trainer - INFO -     val_loss       : 0.518877
2024-03-26 19:12:04,597 - trainer - INFO -     val_accuracy   : 0.858545
2024-03-26 19:12:04,597 - trainer - INFO -     val_macro_f    : 0.856376
2024-03-26 19:12:04,597 - trainer - INFO -     val_precision  : 0.88964
2024-03-26 19:12:04,597 - trainer - INFO -     val_recall     : 0.858545
2024-03-26 19:12:04,597 - trainer - INFO -     test_loss      : 0.491469
2024-03-26 19:12:04,597 - trainer - INFO -     test_accuracy  : 0.865
2024-03-26 19:12:04,597 - trainer - INFO -     test_macro_f   : 0.862706
2024-03-26 19:12:04,597 - trainer - INFO -     test_precision : 0.892837
2024-03-26 19:12:04,597 - trainer - INFO -     test_recall    : 0.865
2024-03-26 19:18:54,424 - trainer - INFO -     epoch          : 5
2024-03-26 19:18:54,424 - trainer - INFO -     loss           : 0.433518
2024-03-26 19:18:54,424 - trainer - INFO -     accuracy       : 0.8718
2024-03-26 19:18:54,424 - trainer - INFO -     macro_f        : 0.87096
2024-03-26 19:18:54,424 - trainer - INFO -     precision      : 0.902939
2024-03-26 19:18:54,424 - trainer - INFO -     recall         : 0.8718
2024-03-26 19:18:54,424 - trainer - INFO -     val_loss       : 0.51177
2024-03-26 19:18:54,424 - trainer - INFO -     val_accuracy   : 0.859091
2024-03-26 19:18:54,424 - trainer - INFO -     val_macro_f    : 0.858332
2024-03-26 19:18:54,424 - trainer - INFO -     val_precision  : 0.891846
2024-03-26 19:18:54,424 - trainer - INFO -     val_recall     : 0.859091
2024-03-26 19:18:54,424 - trainer - INFO -     test_loss      : 0.491837
2024-03-26 19:18:54,424 - trainer - INFO -     test_accuracy  : 0.864
2024-03-26 19:18:54,424 - trainer - INFO -     test_macro_f   : 0.863559
2024-03-26 19:18:54,424 - trainer - INFO -     test_precision : 0.896314
2024-03-26 19:18:54,424 - trainer - INFO -     test_recall    : 0.864
2024-03-26 19:19:30,866 - train - INFO - PretrainedBaseline(
  (model): BertForSequenceClassification(
    (bert): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (classifier): Linear(in_features=768, out_features=11, bias=True)
  )
)
Trainable params: 24,309,515
Freeze params: 0
2024-03-26 19:26:19,415 - trainer - INFO -     epoch          : 1
2024-03-26 19:26:19,415 - trainer - INFO -     loss           : 0.71135
2024-03-26 19:26:19,415 - trainer - INFO -     accuracy       : 0.794982
2024-03-26 19:26:19,415 - trainer - INFO -     macro_f        : 0.792966
2024-03-26 19:26:19,415 - trainer - INFO -     precision      : 0.83962
2024-03-26 19:26:19,415 - trainer - INFO -     recall         : 0.794982
2024-03-26 19:26:19,415 - trainer - INFO -     val_loss       : 0.569093
2024-03-26 19:26:19,415 - trainer - INFO -     val_accuracy   : 0.835
2024-03-26 19:26:19,430 - trainer - INFO -     val_macro_f    : 0.834568
2024-03-26 19:26:19,430 - trainer - INFO -     val_precision  : 0.874413
2024-03-26 19:26:19,430 - trainer - INFO -     val_recall     : 0.835
2024-03-26 19:26:19,430 - trainer - INFO -     test_loss      : 0.545451
2024-03-26 19:26:19,430 - trainer - INFO -     test_accuracy  : 0.843909
2024-03-26 19:26:19,430 - trainer - INFO -     test_macro_f   : 0.844413
2024-03-26 19:26:19,430 - trainer - INFO -     test_precision : 0.883135
2024-03-26 19:26:19,430 - trainer - INFO -     test_recall    : 0.843909
2024-03-26 19:33:06,812 - trainer - INFO -     epoch          : 2
2024-03-26 19:33:06,812 - trainer - INFO -     loss           : 0.518367
2024-03-26 19:33:06,812 - trainer - INFO -     accuracy       : 0.850245
2024-03-26 19:33:06,812 - trainer - INFO -     macro_f        : 0.849175
2024-03-26 19:33:06,812 - trainer - INFO -     precision      : 0.886626
2024-03-26 19:33:06,812 - trainer - INFO -     recall         : 0.850245
2024-03-26 19:33:06,828 - trainer - INFO -     val_loss       : 0.518756
2024-03-26 19:33:06,828 - trainer - INFO -     val_accuracy   : 0.848909
2024-03-26 19:33:06,828 - trainer - INFO -     val_macro_f    : 0.849686
2024-03-26 19:33:06,828 - trainer - INFO -     val_precision  : 0.886776
2024-03-26 19:33:06,828 - trainer - INFO -     val_recall     : 0.848909
2024-03-26 19:33:06,828 - trainer - INFO -     test_loss      : 0.500103
2024-03-26 19:33:06,828 - trainer - INFO -     test_accuracy  : 0.855636
2024-03-26 19:33:06,828 - trainer - INFO -     test_macro_f   : 0.855532
2024-03-26 19:33:06,828 - trainer - INFO -     test_precision : 0.888834
2024-03-26 19:33:06,828 - trainer - INFO -     test_recall    : 0.855636
2024-03-26 19:39:55,129 - trainer - INFO -     epoch          : 3
2024-03-26 19:39:55,129 - trainer - INFO -     loss           : 0.480991
2024-03-26 19:39:55,129 - trainer - INFO -     accuracy       : 0.859427
2024-03-26 19:39:55,129 - trainer - INFO -     macro_f        : 0.858585
2024-03-26 19:39:55,129 - trainer - INFO -     precision      : 0.894172
2024-03-26 19:39:55,129 - trainer - INFO -     recall         : 0.859427
2024-03-26 19:39:55,129 - trainer - INFO -     val_loss       : 0.56169
2024-03-26 19:39:55,129 - trainer - INFO -     val_accuracy   : 0.845
2024-03-26 19:39:55,129 - trainer - INFO -     val_macro_f    : 0.842965
2024-03-26 19:39:55,129 - trainer - INFO -     val_precision  : 0.878947
2024-03-26 19:39:55,129 - trainer - INFO -     val_recall     : 0.845
2024-03-26 19:39:55,129 - trainer - INFO -     test_loss      : 0.522163
2024-03-26 19:39:55,129 - trainer - INFO -     test_accuracy  : 0.854455
2024-03-26 19:39:55,129 - trainer - INFO -     test_macro_f   : 0.85296
2024-03-26 19:39:55,129 - trainer - INFO -     test_precision : 0.889484
2024-03-26 19:39:55,129 - trainer - INFO -     test_recall    : 0.854455
2024-03-26 19:46:44,300 - trainer - INFO -     epoch          : 4
2024-03-26 19:46:44,300 - trainer - INFO -     loss           : 0.452429
2024-03-26 19:46:44,300 - trainer - INFO -     accuracy       : 0.867191
2024-03-26 19:46:44,300 - trainer - INFO -     macro_f        : 0.866721
2024-03-26 19:46:44,300 - trainer - INFO -     precision      : 0.900106
2024-03-26 19:46:44,300 - trainer - INFO -     recall         : 0.867191
2024-03-26 19:46:44,300 - trainer - INFO -     val_loss       : 0.522665
2024-03-26 19:46:44,300 - trainer - INFO -     val_accuracy   : 0.847545
2024-03-26 19:46:44,300 - trainer - INFO -     val_macro_f    : 0.84633
2024-03-26 19:46:44,300 - trainer - INFO -     val_precision  : 0.882491
2024-03-26 19:46:44,300 - trainer - INFO -     val_recall     : 0.847545
2024-03-26 19:46:44,300 - trainer - INFO -     test_loss      : 0.500523
2024-03-26 19:46:44,300 - trainer - INFO -     test_accuracy  : 0.853091
2024-03-26 19:46:44,300 - trainer - INFO -     test_macro_f   : 0.851158
2024-03-26 19:46:44,300 - trainer - INFO -     test_precision : 0.885107
2024-03-26 19:46:44,300 - trainer - INFO -     test_recall    : 0.853091
2024-03-26 19:53:32,585 - trainer - INFO -     epoch          : 5
2024-03-26 19:53:32,585 - trainer - INFO -     loss           : 0.428041
2024-03-26 19:53:32,601 - trainer - INFO -     accuracy       : 0.874509
2024-03-26 19:53:32,601 - trainer - INFO -     macro_f        : 0.873639
2024-03-26 19:53:32,601 - trainer - INFO -     precision      : 0.904881
2024-03-26 19:53:32,601 - trainer - INFO -     recall         : 0.874509
2024-03-26 19:53:32,601 - trainer - INFO -     val_loss       : 0.550806
2024-03-26 19:53:32,601 - trainer - INFO -     val_accuracy   : 0.839818
2024-03-26 19:53:32,601 - trainer - INFO -     val_macro_f    : 0.839165
2024-03-26 19:53:32,601 - trainer - INFO -     val_precision  : 0.879245
2024-03-26 19:53:32,601 - trainer - INFO -     val_recall     : 0.839818
2024-03-26 19:53:32,601 - trainer - INFO -     test_loss      : 0.531614
2024-03-26 19:53:32,601 - trainer - INFO -     test_accuracy  : 0.849818
2024-03-26 19:53:32,601 - trainer - INFO -     test_macro_f   : 0.850011
2024-03-26 19:53:32,601 - trainer - INFO -     test_precision : 0.889753
2024-03-26 19:53:32,601 - trainer - INFO -     test_recall    : 0.849818
2024-03-26 19:54:08,192 - train - INFO - PretrainedBaseline(
  (model): BertForSequenceClassification(
    (bert): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (classifier): Linear(in_features=768, out_features=11, bias=True)
  )
)
Trainable params: 24,309,515
Freeze params: 0
2024-03-26 20:00:55,784 - trainer - INFO -     epoch          : 1
2024-03-26 20:00:55,784 - trainer - INFO -     loss           : 0.670917
2024-03-26 20:00:55,784 - trainer - INFO -     accuracy       : 0.807055
2024-03-26 20:00:55,784 - trainer - INFO -     macro_f        : 0.804896
2024-03-26 20:00:55,784 - trainer - INFO -     precision      : 0.85019
2024-03-26 20:00:55,784 - trainer - INFO -     recall         : 0.807055
2024-03-26 20:00:55,784 - trainer - INFO -     val_loss       : 0.554341
2024-03-26 20:00:55,784 - trainer - INFO -     val_accuracy   : 0.837545
2024-03-26 20:00:55,784 - trainer - INFO -     val_macro_f    : 0.837206
2024-03-26 20:00:55,784 - trainer - INFO -     val_precision  : 0.877528
2024-03-26 20:00:55,784 - trainer - INFO -     val_recall     : 0.837545
2024-03-26 20:00:55,784 - trainer - INFO -     test_loss      : 0.53527
2024-03-26 20:00:55,784 - trainer - INFO -     test_accuracy  : 0.845545
2024-03-26 20:00:55,784 - trainer - INFO -     test_macro_f   : 0.845076
2024-03-26 20:00:55,784 - trainer - INFO -     test_precision : 0.883126
2024-03-26 20:00:55,784 - trainer - INFO -     test_recall    : 0.845545
2024-03-26 20:07:43,088 - trainer - INFO -     epoch          : 2
2024-03-26 20:07:43,088 - trainer - INFO -     loss           : 0.511436
2024-03-26 20:07:43,088 - trainer - INFO -     accuracy       : 0.850509
2024-03-26 20:07:43,088 - trainer - INFO -     macro_f        : 0.84923
2024-03-26 20:07:43,088 - trainer - INFO -     precision      : 0.88599
2024-03-26 20:07:43,088 - trainer - INFO -     recall         : 0.850509
2024-03-26 20:07:43,088 - trainer - INFO -     val_loss       : 0.54855
2024-03-26 20:07:43,088 - trainer - INFO -     val_accuracy   : 0.841636
2024-03-26 20:07:43,088 - trainer - INFO -     val_macro_f    : 0.843164
2024-03-26 20:07:43,088 - trainer - INFO -     val_precision  : 0.881591
2024-03-26 20:07:43,088 - trainer - INFO -     val_recall     : 0.841636
2024-03-26 20:07:43,088 - trainer - INFO -     test_loss      : 0.540687
2024-03-26 20:07:43,088 - trainer - INFO -     test_accuracy  : 0.843545
2024-03-26 20:07:43,088 - trainer - INFO -     test_macro_f   : 0.844978
2024-03-26 20:07:43,088 - trainer - INFO -     test_precision : 0.884245
2024-03-26 20:07:43,088 - trainer - INFO -     test_recall    : 0.843545
2024-03-26 20:14:28,965 - trainer - INFO -     epoch          : 3
2024-03-26 20:14:28,965 - trainer - INFO -     loss           : 0.469772
2024-03-26 20:14:28,965 - trainer - INFO -     accuracy       : 0.861873
2024-03-26 20:14:28,965 - trainer - INFO -     macro_f        : 0.861315
2024-03-26 20:14:28,965 - trainer - INFO -     precision      : 0.895912
2024-03-26 20:14:28,965 - trainer - INFO -     recall         : 0.861873
2024-03-26 20:14:28,965 - trainer - INFO -     val_loss       : 0.538771
2024-03-26 20:14:28,965 - trainer - INFO -     val_accuracy   : 0.845273
2024-03-26 20:14:28,965 - trainer - INFO -     val_macro_f    : 0.844336
2024-03-26 20:14:28,981 - trainer - INFO -     val_precision  : 0.880042
2024-03-26 20:14:28,981 - trainer - INFO -     val_recall     : 0.845273
2024-03-26 20:14:28,981 - trainer - INFO -     test_loss      : 0.521931
2024-03-26 20:14:28,981 - trainer - INFO -     test_accuracy  : 0.850818
2024-03-26 20:14:28,981 - trainer - INFO -     test_macro_f   : 0.850219
2024-03-26 20:14:28,981 - trainer - INFO -     test_precision : 0.886131
2024-03-26 20:14:28,981 - trainer - INFO -     test_recall    : 0.850818
2024-03-26 20:21:14,923 - trainer - INFO -     epoch          : 4
2024-03-26 20:21:14,923 - trainer - INFO -     loss           : 0.440201
2024-03-26 20:21:14,923 - trainer - INFO -     accuracy       : 0.869482
2024-03-26 20:21:14,923 - trainer - INFO -     macro_f        : 0.86824
2024-03-26 20:21:14,923 - trainer - INFO -     precision      : 0.900747
2024-03-26 20:21:14,923 - trainer - INFO -     recall         : 0.869482
2024-03-26 20:21:14,923 - trainer - INFO -     val_loss       : 0.530939
2024-03-26 20:21:14,923 - trainer - INFO -     val_accuracy   : 0.847636
2024-03-26 20:21:14,923 - trainer - INFO -     val_macro_f    : 0.847369
2024-03-26 20:21:14,923 - trainer - INFO -     val_precision  : 0.884642
2024-03-26 20:21:14,923 - trainer - INFO -     val_recall     : 0.847636
2024-03-26 20:21:14,923 - trainer - INFO -     test_loss      : 0.513661
2024-03-26 20:21:14,938 - trainer - INFO -     test_accuracy  : 0.852091
2024-03-26 20:21:14,938 - trainer - INFO -     test_macro_f   : 0.851563
2024-03-26 20:21:14,938 - trainer - INFO -     test_precision : 0.88888
2024-03-26 20:21:14,938 - trainer - INFO -     test_recall    : 0.852091
2024-03-26 20:28:00,942 - trainer - INFO -     epoch          : 5
2024-03-26 20:28:00,942 - trainer - INFO -     loss           : 0.418341
2024-03-26 20:28:00,942 - trainer - INFO -     accuracy       : 0.875627
2024-03-26 20:28:00,942 - trainer - INFO -     macro_f        : 0.874803
2024-03-26 20:28:00,942 - trainer - INFO -     precision      : 0.906057
2024-03-26 20:28:00,942 - trainer - INFO -     recall         : 0.875627
2024-03-26 20:28:00,942 - trainer - INFO -     val_loss       : 0.528064
2024-03-26 20:28:00,942 - trainer - INFO -     val_accuracy   : 0.845182
2024-03-26 20:28:00,942 - trainer - INFO -     val_macro_f    : 0.845592
2024-03-26 20:28:00,942 - trainer - INFO -     val_precision  : 0.886758
2024-03-26 20:28:00,942 - trainer - INFO -     val_recall     : 0.845182
2024-03-26 20:28:00,942 - trainer - INFO -     test_loss      : 0.506872
2024-03-26 20:28:00,942 - trainer - INFO -     test_accuracy  : 0.850364
2024-03-26 20:28:00,942 - trainer - INFO -     test_macro_f   : 0.850814
2024-03-26 20:28:00,942 - trainer - INFO -     test_precision : 0.889921
2024-03-26 20:28:00,942 - trainer - INFO -     test_recall    : 0.850364
2024-03-26 20:28:35,715 - train - INFO - PretrainedBaseline(
  (model): BertForSequenceClassification(
    (bert): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (classifier): Linear(in_features=768, out_features=11, bias=True)
  )
)
Trainable params: 24,309,515
Freeze params: 0
2024-03-26 20:35:20,535 - trainer - INFO -     epoch          : 1
2024-03-26 20:35:20,535 - trainer - INFO -     loss           : 0.676329
2024-03-26 20:35:20,535 - trainer - INFO -     accuracy       : 0.804727
2024-03-26 20:35:20,535 - trainer - INFO -     macro_f        : 0.802854
2024-03-26 20:35:20,535 - trainer - INFO -     precision      : 0.848925
2024-03-26 20:35:20,535 - trainer - INFO -     recall         : 0.804727
2024-03-26 20:35:20,535 - trainer - INFO -     val_loss       : 0.56915
2024-03-26 20:35:20,535 - trainer - INFO -     val_accuracy   : 0.838545
2024-03-26 20:35:20,535 - trainer - INFO -     val_macro_f    : 0.837572
2024-03-26 20:35:20,535 - trainer - INFO -     val_precision  : 0.874746
2024-03-26 20:35:20,535 - trainer - INFO -     val_recall     : 0.838545
2024-03-26 20:35:20,535 - trainer - INFO -     test_loss      : 0.538019
2024-03-26 20:35:20,535 - trainer - INFO -     test_accuracy  : 0.843818
2024-03-26 20:35:20,535 - trainer - INFO -     test_macro_f   : 0.843311
2024-03-26 20:35:20,535 - trainer - INFO -     test_precision : 0.87924
2024-03-26 20:35:20,535 - trainer - INFO -     test_recall    : 0.843818
2024-03-26 20:42:05,721 - trainer - INFO -     epoch          : 2
2024-03-26 20:42:05,721 - trainer - INFO -     loss           : 0.503991
2024-03-26 20:42:05,721 - trainer - INFO -     accuracy       : 0.852755
2024-03-26 20:42:05,721 - trainer - INFO -     macro_f        : 0.851786
2024-03-26 20:42:05,721 - trainer - INFO -     precision      : 0.887969
2024-03-26 20:42:05,721 - trainer - INFO -     recall         : 0.852755
2024-03-26 20:42:05,721 - trainer - INFO -     val_loss       : 0.512115
2024-03-26 20:42:05,721 - trainer - INFO -     val_accuracy   : 0.854727
2024-03-26 20:42:05,721 - trainer - INFO -     val_macro_f    : 0.853987
2024-03-26 20:42:05,721 - trainer - INFO -     val_precision  : 0.887273
2024-03-26 20:42:05,721 - trainer - INFO -     val_recall     : 0.854727
2024-03-26 20:42:05,737 - trainer - INFO -     test_loss      : 0.496194
2024-03-26 20:42:05,737 - trainer - INFO -     test_accuracy  : 0.858182
2024-03-26 20:42:05,737 - trainer - INFO -     test_macro_f   : 0.857164
2024-03-26 20:42:05,737 - trainer - INFO -     test_precision : 0.891571
2024-03-26 20:42:05,737 - trainer - INFO -     test_recall    : 0.858182
2024-03-26 20:48:51,112 - trainer - INFO -     epoch          : 3
2024-03-26 20:48:51,112 - trainer - INFO -     loss           : 0.448151
2024-03-26 20:48:51,112 - trainer - INFO -     accuracy       : 0.866618
2024-03-26 20:48:51,112 - trainer - INFO -     macro_f        : 0.865669
2024-03-26 20:48:51,112 - trainer - INFO -     precision      : 0.898678
2024-03-26 20:48:51,112 - trainer - INFO -     recall         : 0.866618
2024-03-26 20:48:51,112 - trainer - INFO -     val_loss       : 0.476545
2024-03-26 20:48:51,112 - trainer - INFO -     val_accuracy   : 0.859727
2024-03-26 20:48:51,112 - trainer - INFO -     val_macro_f    : 0.858711
2024-03-26 20:48:51,112 - trainer - INFO -     val_precision  : 0.893335
2024-03-26 20:48:51,112 - trainer - INFO -     val_recall     : 0.859727
2024-03-26 20:48:51,112 - trainer - INFO -     test_loss      : 0.453483
2024-03-26 20:48:51,112 - trainer - INFO -     test_accuracy  : 0.863818
2024-03-26 20:48:51,112 - trainer - INFO -     test_macro_f   : 0.86481
2024-03-26 20:48:51,112 - trainer - INFO -     test_precision : 0.897895
2024-03-26 20:48:51,112 - trainer - INFO -     test_recall    : 0.863818
2024-03-26 20:55:36,088 - trainer - INFO -     epoch          : 4
2024-03-26 20:55:36,088 - trainer - INFO -     loss           : 0.40873
2024-03-26 20:55:36,088 - trainer - INFO -     accuracy       : 0.875609
2024-03-26 20:55:36,088 - trainer - INFO -     macro_f        : 0.875405
2024-03-26 20:55:36,088 - trainer - INFO -     precision      : 0.906348
2024-03-26 20:55:36,088 - trainer - INFO -     recall         : 0.875609
2024-03-26 20:55:36,088 - trainer - INFO -     val_loss       : 0.493157
2024-03-26 20:55:36,088 - trainer - INFO -     val_accuracy   : 0.852273
2024-03-26 20:55:36,088 - trainer - INFO -     val_macro_f    : 0.852378
2024-03-26 20:55:36,088 - trainer - INFO -     val_precision  : 0.889507
2024-03-26 20:55:36,088 - trainer - INFO -     val_recall     : 0.852273
2024-03-26 20:55:36,088 - trainer - INFO -     test_loss      : 0.478744
2024-03-26 20:55:36,088 - trainer - INFO -     test_accuracy  : 0.859091
2024-03-26 20:55:36,088 - trainer - INFO -     test_macro_f   : 0.859476
2024-03-26 20:55:36,088 - trainer - INFO -     test_precision : 0.893342
2024-03-26 20:55:36,088 - trainer - INFO -     test_recall    : 0.859091
2024-03-26 21:02:21,596 - trainer - INFO -     epoch          : 5
2024-03-26 21:02:21,596 - trainer - INFO -     loss           : 0.378264
2024-03-26 21:02:21,596 - trainer - INFO -     accuracy       : 0.885309
2024-03-26 21:02:21,596 - trainer - INFO -     macro_f        : 0.884543
2024-03-26 21:02:21,596 - trainer - INFO -     precision      : 0.912895
2024-03-26 21:02:21,596 - trainer - INFO -     recall         : 0.885309
2024-03-26 21:02:21,596 - trainer - INFO -     val_loss       : 0.455229
2024-03-26 21:02:21,596 - trainer - INFO -     val_accuracy   : 0.867727
2024-03-26 21:02:21,596 - trainer - INFO -     val_macro_f    : 0.866903
2024-03-26 21:02:21,596 - trainer - INFO -     val_precision  : 0.897664
2024-03-26 21:02:21,596 - trainer - INFO -     val_recall     : 0.867727
2024-03-26 21:02:21,612 - trainer - INFO -     test_loss      : 0.448853
2024-03-26 21:02:21,612 - trainer - INFO -     test_accuracy  : 0.867182
2024-03-26 21:02:21,612 - trainer - INFO -     test_macro_f   : 0.866809
2024-03-26 21:02:21,612 - trainer - INFO -     test_precision : 0.897378
2024-03-26 21:02:21,612 - trainer - INFO -     test_recall    : 0.867182
2024-03-26 21:02:56,033 - train - INFO - PretrainedBaseline(
  (model): BertForSequenceClassification(
    (bert): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (classifier): Linear(in_features=768, out_features=11, bias=True)
  )
)
Trainable params: 24,309,515
Freeze params: 0
2024-03-26 21:09:40,857 - trainer - INFO -     epoch          : 1
2024-03-26 21:09:40,857 - trainer - INFO -     loss           : 0.682159
2024-03-26 21:09:40,857 - trainer - INFO -     accuracy       : 0.803445
2024-03-26 21:09:40,857 - trainer - INFO -     macro_f        : 0.801774
2024-03-26 21:09:40,857 - trainer - INFO -     precision      : 0.847077
2024-03-26 21:09:40,857 - trainer - INFO -     recall         : 0.803445
2024-03-26 21:09:40,857 - trainer - INFO -     val_loss       : 0.558953
2024-03-26 21:09:40,857 - trainer - INFO -     val_accuracy   : 0.837455
2024-03-26 21:09:40,857 - trainer - INFO -     val_macro_f    : 0.837704
2024-03-26 21:09:40,857 - trainer - INFO -     val_precision  : 0.876164
2024-03-26 21:09:40,857 - trainer - INFO -     val_recall     : 0.837455
2024-03-26 21:09:40,857 - trainer - INFO -     test_loss      : 0.546125
2024-03-26 21:09:40,857 - trainer - INFO -     test_accuracy  : 0.839091
2024-03-26 21:09:40,857 - trainer - INFO -     test_macro_f   : 0.837993
2024-03-26 21:09:40,857 - trainer - INFO -     test_precision : 0.877114
2024-03-26 21:09:40,857 - trainer - INFO -     test_recall    : 0.839091
2024-03-26 21:16:27,801 - trainer - INFO -     epoch          : 2
2024-03-26 21:16:27,801 - trainer - INFO -     loss           : 0.521755
2024-03-26 21:16:27,801 - trainer - INFO -     accuracy       : 0.849664
2024-03-26 21:16:27,801 - trainer - INFO -     macro_f        : 0.848448
2024-03-26 21:16:27,801 - trainer - INFO -     precision      : 0.885356
2024-03-26 21:16:27,816 - trainer - INFO -     recall         : 0.849664
2024-03-26 21:16:27,816 - trainer - INFO -     val_loss       : 0.5504
2024-03-26 21:16:27,816 - trainer - INFO -     val_accuracy   : 0.838273
2024-03-26 21:16:27,816 - trainer - INFO -     val_macro_f    : 0.837831
2024-03-26 21:16:27,816 - trainer - INFO -     val_precision  : 0.878707
2024-03-26 21:16:27,816 - trainer - INFO -     val_recall     : 0.838273
2024-03-26 21:16:27,816 - trainer - INFO -     test_loss      : 0.534193
2024-03-26 21:16:27,816 - trainer - INFO -     test_accuracy  : 0.842727
2024-03-26 21:16:27,816 - trainer - INFO -     test_macro_f   : 0.84321
2024-03-26 21:16:27,816 - trainer - INFO -     test_precision : 0.885139
2024-03-26 21:16:27,816 - trainer - INFO -     test_recall    : 0.842727
2024-03-26 21:23:14,146 - trainer - INFO -     epoch          : 3
2024-03-26 21:23:14,146 - trainer - INFO -     loss           : 0.477305
2024-03-26 21:23:14,146 - trainer - INFO -     accuracy       : 0.8614
2024-03-26 21:23:14,146 - trainer - INFO -     macro_f        : 0.860642
2024-03-26 21:23:14,146 - trainer - INFO -     precision      : 0.894744
2024-03-26 21:23:14,146 - trainer - INFO -     recall         : 0.8614
2024-03-26 21:23:14,146 - trainer - INFO -     val_loss       : 0.573385
2024-03-26 21:23:14,162 - trainer - INFO -     val_accuracy   : 0.839
2024-03-26 21:23:14,162 - trainer - INFO -     val_macro_f    : 0.839056
2024-03-26 21:23:14,162 - trainer - INFO -     val_precision  : 0.880772
2024-03-26 21:23:14,162 - trainer - INFO -     val_recall     : 0.839
2024-03-26 21:23:14,163 - trainer - INFO -     test_loss      : 0.537906
2024-03-26 21:23:14,163 - trainer - INFO -     test_accuracy  : 0.846818
2024-03-26 21:23:14,163 - trainer - INFO -     test_macro_f   : 0.846427
2024-03-26 21:23:14,163 - trainer - INFO -     test_precision : 0.883604
2024-03-26 21:23:14,163 - trainer - INFO -     test_recall    : 0.846818
2024-03-26 21:30:01,521 - trainer - INFO -     epoch          : 4
2024-03-26 21:30:01,521 - trainer - INFO -     loss           : 0.453702
2024-03-26 21:30:01,521 - trainer - INFO -     accuracy       : 0.8676
2024-03-26 21:30:01,521 - trainer - INFO -     macro_f        : 0.866719
2024-03-26 21:30:01,521 - trainer - INFO -     precision      : 0.899612
2024-03-26 21:30:01,521 - trainer - INFO -     recall         : 0.8676
2024-03-26 21:30:01,521 - trainer - INFO -     val_loss       : 0.558561
2024-03-26 21:30:01,521 - trainer - INFO -     val_accuracy   : 0.847818
2024-03-26 21:30:01,521 - trainer - INFO -     val_macro_f    : 0.847901
2024-03-26 21:30:01,521 - trainer - INFO -     val_precision  : 0.886663
2024-03-26 21:30:01,536 - trainer - INFO -     val_recall     : 0.847818
2024-03-26 21:30:01,536 - trainer - INFO -     test_loss      : 0.54717
2024-03-26 21:30:01,536 - trainer - INFO -     test_accuracy  : 0.846909
2024-03-26 21:30:01,536 - trainer - INFO -     test_macro_f   : 0.846823
2024-03-26 21:30:01,536 - trainer - INFO -     test_precision : 0.884494
2024-03-26 21:30:01,536 - trainer - INFO -     test_recall    : 0.846909
2024-03-26 21:36:48,858 - trainer - INFO -     epoch          : 5
2024-03-26 21:36:48,858 - trainer - INFO -     loss           : 0.431312
2024-03-26 21:36:48,858 - trainer - INFO -     accuracy       : 0.874091
2024-03-26 21:36:48,858 - trainer - INFO -     macro_f        : 0.87345
2024-03-26 21:36:48,858 - trainer - INFO -     precision      : 0.905279
2024-03-26 21:36:48,858 - trainer - INFO -     recall         : 0.874091
2024-03-26 21:36:48,858 - trainer - INFO -     val_loss       : 0.555496
2024-03-26 21:36:48,858 - trainer - INFO -     val_accuracy   : 0.841909
2024-03-26 21:36:48,858 - trainer - INFO -     val_macro_f    : 0.842938
2024-03-26 21:36:48,858 - trainer - INFO -     val_precision  : 0.883881
2024-03-26 21:36:48,858 - trainer - INFO -     val_recall     : 0.841909
2024-03-26 21:36:48,858 - trainer - INFO -     test_loss      : 0.520736
2024-03-26 21:36:48,858 - trainer - INFO -     test_accuracy  : 0.844455
2024-03-26 21:36:48,858 - trainer - INFO -     test_macro_f   : 0.845893
2024-03-26 21:36:48,858 - trainer - INFO -     test_precision : 0.885
2024-03-26 21:36:48,858 - trainer - INFO -     test_recall    : 0.844455
2024-04-08 09:00:43,863 - train - INFO - PretrainedBaseline(
  (model): BertForSequenceClassification(
    (bert): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (classifier): Linear(in_features=768, out_features=11, bias=True)
  )
)
Trainable params: 24,309,515
Freeze params: 0
2024-04-08 09:07:21,378 - trainer - INFO -     epoch          : 1
2024-04-08 09:07:21,378 - trainer - INFO -     loss           : 0.552989
2024-04-08 09:07:21,378 - trainer - INFO -     accuracy       : 0.827891
2024-04-08 09:07:21,378 - trainer - INFO -     macro_f        : 0.82621
2024-04-08 09:07:21,378 - trainer - INFO -     precision      : 0.86261
2024-04-08 09:07:21,378 - trainer - INFO -     recall         : 0.827891
2024-04-08 09:07:21,378 - trainer - INFO -     val_loss       : 0.431068
2024-04-08 09:07:21,378 - trainer - INFO -     val_accuracy   : 0.862636
2024-04-08 09:07:21,378 - trainer - INFO -     val_macro_f    : 0.862652
2024-04-08 09:07:21,378 - trainer - INFO -     val_precision  : 0.895218
2024-04-08 09:07:21,378 - trainer - INFO -     val_recall     : 0.862636
2024-04-08 09:07:21,378 - trainer - INFO -     test_loss      : 0.41595
2024-04-08 09:07:21,378 - trainer - INFO -     test_accuracy  : 0.870182
2024-04-08 09:07:21,378 - trainer - INFO -     test_macro_f   : 0.871023
2024-04-08 09:07:21,378 - trainer - INFO -     test_precision : 0.903106
2024-04-08 09:07:21,378 - trainer - INFO -     test_recall    : 0.870182
2024-04-08 09:14:01,670 - trainer - INFO -     epoch          : 2
2024-04-08 09:14:01,670 - trainer - INFO -     loss           : 0.381538
2024-04-08 09:14:01,670 - trainer - INFO -     accuracy       : 0.882836
2024-04-08 09:14:01,670 - trainer - INFO -     macro_f        : 0.882718
2024-04-08 09:14:01,670 - trainer - INFO -     precision      : 0.911621
2024-04-08 09:14:01,670 - trainer - INFO -     recall         : 0.882836
2024-04-08 09:14:01,670 - trainer - INFO -     val_loss       : 0.413383
2024-04-08 09:14:01,670 - trainer - INFO -     val_accuracy   : 0.869182
2024-04-08 09:14:01,670 - trainer - INFO -     val_macro_f    : 0.867823
2024-04-08 09:14:01,670 - trainer - INFO -     val_precision  : 0.899843
2024-04-08 09:14:01,670 - trainer - INFO -     val_recall     : 0.869182
2024-04-08 09:14:01,670 - trainer - INFO -     test_loss      : 0.400205
2024-04-08 09:14:01,670 - trainer - INFO -     test_accuracy  : 0.872818
2024-04-08 09:14:01,670 - trainer - INFO -     test_macro_f   : 0.870892
2024-04-08 09:14:01,670 - trainer - INFO -     test_precision : 0.899554
2024-04-08 09:14:01,670 - trainer - INFO -     test_recall    : 0.872818
2024-04-08 09:20:42,744 - trainer - INFO -     epoch          : 3
2024-04-08 09:20:42,744 - trainer - INFO -     loss           : 0.323601
2024-04-08 09:20:42,744 - trainer - INFO -     accuracy       : 0.898491
2024-04-08 09:20:42,744 - trainer - INFO -     macro_f        : 0.898364
2024-04-08 09:20:42,744 - trainer - INFO -     precision      : 0.923829
2024-04-08 09:20:42,744 - trainer - INFO -     recall         : 0.898491
2024-04-08 09:20:42,744 - trainer - INFO -     val_loss       : 0.406127
2024-04-08 09:20:42,744 - trainer - INFO -     val_accuracy   : 0.876818
2024-04-08 09:20:42,744 - trainer - INFO -     val_macro_f    : 0.87615
2024-04-08 09:20:42,744 - trainer - INFO -     val_precision  : 0.905047
2024-04-08 09:20:42,744 - trainer - INFO -     val_recall     : 0.876818
2024-04-08 09:20:42,744 - trainer - INFO -     test_loss      : 0.385727
2024-04-08 09:20:42,744 - trainer - INFO -     test_accuracy  : 0.882545
2024-04-08 09:20:42,744 - trainer - INFO -     test_macro_f   : 0.882647
2024-04-08 09:20:42,744 - trainer - INFO -     test_precision : 0.911418
2024-04-08 09:20:42,744 - trainer - INFO -     test_recall    : 0.882545
2024-04-08 09:21:31,002 - train - INFO - PretrainedBaseline(
  (model): BertForSequenceClassification(
    (bert): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (classifier): Linear(in_features=768, out_features=11, bias=True)
  )
)
Trainable params: 24,309,515
Freeze params: 0
2024-04-08 09:28:11,897 - trainer - INFO -     epoch          : 1
2024-04-08 09:28:11,897 - trainer - INFO -     loss           : 0.554672
2024-04-08 09:28:11,897 - trainer - INFO -     accuracy       : 0.829582
2024-04-08 09:28:11,897 - trainer - INFO -     macro_f        : 0.827758
2024-04-08 09:28:11,897 - trainer - INFO -     precision      : 0.864025
2024-04-08 09:28:11,897 - trainer - INFO -     recall         : 0.829582
2024-04-08 09:28:11,897 - trainer - INFO -     val_loss       : 0.433548
2024-04-08 09:28:11,897 - trainer - INFO -     val_accuracy   : 0.862364
2024-04-08 09:28:11,897 - trainer - INFO -     val_macro_f    : 0.86156
2024-04-08 09:28:11,897 - trainer - INFO -     val_precision  : 0.893493
2024-04-08 09:28:11,897 - trainer - INFO -     val_recall     : 0.862364
2024-04-08 09:28:11,897 - trainer - INFO -     test_loss      : 0.417674
2024-04-08 09:28:11,897 - trainer - INFO -     test_accuracy  : 0.870182
2024-04-08 09:28:11,897 - trainer - INFO -     test_macro_f   : 0.869679
2024-04-08 09:28:11,897 - trainer - INFO -     test_precision : 0.90015
2024-04-08 09:28:11,897 - trainer - INFO -     test_recall    : 0.870182
2024-04-08 09:36:05,925 - trainer - INFO -     epoch          : 2
2024-04-08 09:36:05,925 - trainer - INFO -     loss           : 0.382425
2024-04-08 09:36:05,925 - trainer - INFO -     accuracy       : 0.881945
2024-04-08 09:36:05,925 - trainer - INFO -     macro_f        : 0.881418
2024-04-08 09:36:05,925 - trainer - INFO -     precision      : 0.909975
2024-04-08 09:36:05,925 - trainer - INFO -     recall         : 0.881945
2024-04-08 09:36:05,925 - trainer - INFO -     val_loss       : 0.403909
2024-04-08 09:36:05,925 - trainer - INFO -     val_accuracy   : 0.874545
2024-04-08 09:36:05,925 - trainer - INFO -     val_macro_f    : 0.874404
2024-04-08 09:36:05,925 - trainer - INFO -     val_precision  : 0.905289
2024-04-08 09:36:05,925 - trainer - INFO -     val_recall     : 0.874545
2024-04-08 09:36:05,925 - trainer - INFO -     test_loss      : 0.390051
2024-04-08 09:36:05,925 - trainer - INFO -     test_accuracy  : 0.879
2024-04-08 09:36:05,925 - trainer - INFO -     test_macro_f   : 0.87879
2024-04-08 09:36:05,925 - trainer - INFO -     test_precision : 0.906106
2024-04-08 09:36:05,925 - trainer - INFO -     test_recall    : 0.879
2024-04-08 09:45:02,024 - trainer - INFO -     epoch          : 3
2024-04-08 09:45:02,024 - trainer - INFO -     loss           : 0.323815
2024-04-08 09:45:02,024 - trainer - INFO -     accuracy       : 0.898609
2024-04-08 09:45:02,024 - trainer - INFO -     macro_f        : 0.89877
2024-04-08 09:45:02,024 - trainer - INFO -     precision      : 0.924194
2024-04-08 09:45:02,024 - trainer - INFO -     recall         : 0.898609
2024-04-08 09:45:02,024 - trainer - INFO -     val_loss       : 0.407645
2024-04-08 09:45:02,024 - trainer - INFO -     val_accuracy   : 0.876545
2024-04-08 09:45:02,024 - trainer - INFO -     val_macro_f    : 0.875581
2024-04-08 09:45:02,024 - trainer - INFO -     val_precision  : 0.904394
2024-04-08 09:45:02,024 - trainer - INFO -     val_recall     : 0.876545
2024-04-08 09:45:02,024 - trainer - INFO -     test_loss      : 0.386497
2024-04-08 09:45:02,024 - trainer - INFO -     test_accuracy  : 0.880727
2024-04-08 09:45:02,024 - trainer - INFO -     test_macro_f   : 0.880053
2024-04-08 09:45:02,024 - trainer - INFO -     test_precision : 0.910714
2024-04-08 09:45:02,024 - trainer - INFO -     test_recall    : 0.880727
2024-04-08 09:46:02,544 - train - INFO - PretrainedBaseline(
  (model): BertForSequenceClassification(
    (bert): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (classifier): Linear(in_features=768, out_features=11, bias=True)
  )
)
Trainable params: 24,309,515
Freeze params: 0
2024-04-08 18:14:11,391 - train - INFO - PretrainedBaseline(
  (model): BertForSequenceClassification(
    (bert): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (classifier): Linear(in_features=768, out_features=11, bias=True)
  )
)
Trainable params: 24,309,515
Freeze params: 0
2024-04-08 18:20:37,341 - trainer - INFO -     epoch          : 1
2024-04-08 18:20:37,341 - trainer - INFO -     loss           : 0.552989
2024-04-08 18:20:37,341 - trainer - INFO -     accuracy       : 0.827891
2024-04-08 18:20:37,341 - trainer - INFO -     macro_f        : 0.82621
2024-04-08 18:20:37,341 - trainer - INFO -     precision      : 0.86261
2024-04-08 18:20:37,341 - trainer - INFO -     recall         : 0.827891
2024-04-08 18:20:37,341 - trainer - INFO -     val_loss       : 0.431068
2024-04-08 18:20:37,341 - trainer - INFO -     val_accuracy   : 0.862636
2024-04-08 18:20:37,357 - trainer - INFO -     val_macro_f    : 0.862652
2024-04-08 18:20:37,357 - trainer - INFO -     val_precision  : 0.895218
2024-04-08 18:20:37,357 - trainer - INFO -     val_recall     : 0.862636
2024-04-08 18:20:37,357 - trainer - INFO -     test_loss      : 0.41595
2024-04-08 18:20:37,357 - trainer - INFO -     test_accuracy  : 0.870182
2024-04-08 18:20:37,357 - trainer - INFO -     test_macro_f   : 0.871023
2024-04-08 18:20:37,357 - trainer - INFO -     test_precision : 0.903106
2024-04-08 18:20:37,357 - trainer - INFO -     test_recall    : 0.870182
2024-04-08 18:27:12,315 - trainer - INFO -     epoch          : 2
2024-04-08 18:27:12,315 - trainer - INFO -     loss           : 0.381538
2024-04-08 18:27:12,315 - trainer - INFO -     accuracy       : 0.882836
2024-04-08 18:27:12,315 - trainer - INFO -     macro_f        : 0.882718
2024-04-08 18:27:12,315 - trainer - INFO -     precision      : 0.911621
2024-04-08 18:27:12,315 - trainer - INFO -     recall         : 0.882836
2024-04-08 18:27:12,315 - trainer - INFO -     val_loss       : 0.413383
2024-04-08 18:27:12,315 - trainer - INFO -     val_accuracy   : 0.869182
2024-04-08 18:27:12,315 - trainer - INFO -     val_macro_f    : 0.867823
2024-04-08 18:27:12,315 - trainer - INFO -     val_precision  : 0.899843
2024-04-08 18:27:12,315 - trainer - INFO -     val_recall     : 0.869182
2024-04-08 18:27:12,315 - trainer - INFO -     test_loss      : 0.400205
2024-04-08 18:27:12,315 - trainer - INFO -     test_accuracy  : 0.872818
2024-04-08 18:27:12,315 - trainer - INFO -     test_macro_f   : 0.870892
2024-04-08 18:27:12,315 - trainer - INFO -     test_precision : 0.899554
2024-04-08 18:27:12,315 - trainer - INFO -     test_recall    : 0.872818
2024-04-08 18:33:48,515 - trainer - INFO -     epoch          : 3
2024-04-08 18:33:48,515 - trainer - INFO -     loss           : 0.323601
2024-04-08 18:33:48,515 - trainer - INFO -     accuracy       : 0.898491
2024-04-08 18:33:48,515 - trainer - INFO -     macro_f        : 0.898364
2024-04-08 18:33:48,515 - trainer - INFO -     precision      : 0.923829
2024-04-08 18:33:48,515 - trainer - INFO -     recall         : 0.898491
2024-04-08 18:33:48,515 - trainer - INFO -     val_loss       : 0.406127
2024-04-08 18:33:48,515 - trainer - INFO -     val_accuracy   : 0.876818
2024-04-08 18:33:48,515 - trainer - INFO -     val_macro_f    : 0.87615
2024-04-08 18:33:48,515 - trainer - INFO -     val_precision  : 0.905047
2024-04-08 18:33:48,515 - trainer - INFO -     val_recall     : 0.876818
2024-04-08 18:33:48,515 - trainer - INFO -     test_loss      : 0.385727
2024-04-08 18:33:48,515 - trainer - INFO -     test_accuracy  : 0.882545
2024-04-08 18:33:48,515 - trainer - INFO -     test_macro_f   : 0.882647
2024-04-08 18:33:48,515 - trainer - INFO -     test_precision : 0.911418
2024-04-08 18:33:48,515 - trainer - INFO -     test_recall    : 0.882545
2024-04-08 18:34:31,182 - train - INFO - PretrainedBaseline(
  (model): BertForSequenceClassification(
    (bert): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (classifier): Linear(in_features=768, out_features=11, bias=True)
  )
)
Trainable params: 24,309,515
Freeze params: 0
2024-04-08 18:41:08,155 - trainer - INFO -     epoch          : 1
2024-04-08 18:41:08,155 - trainer - INFO -     loss           : 0.554672
2024-04-08 18:41:08,155 - trainer - INFO -     accuracy       : 0.829582
2024-04-08 18:41:08,155 - trainer - INFO -     macro_f        : 0.827758
2024-04-08 18:41:08,155 - trainer - INFO -     precision      : 0.864025
2024-04-08 18:41:08,155 - trainer - INFO -     recall         : 0.829582
2024-04-08 18:41:08,155 - trainer - INFO -     val_loss       : 0.433548
2024-04-08 18:41:08,155 - trainer - INFO -     val_accuracy   : 0.862364
2024-04-08 18:41:08,155 - trainer - INFO -     val_macro_f    : 0.86156
2024-04-08 18:41:08,155 - trainer - INFO -     val_precision  : 0.893493
2024-04-08 18:41:08,155 - trainer - INFO -     val_recall     : 0.862364
2024-04-08 18:41:08,155 - trainer - INFO -     test_loss      : 0.417674
2024-04-08 18:41:08,155 - trainer - INFO -     test_accuracy  : 0.870182
2024-04-08 18:41:08,155 - trainer - INFO -     test_macro_f   : 0.869679
2024-04-08 18:41:08,155 - trainer - INFO -     test_precision : 0.90015
2024-04-08 18:41:08,155 - trainer - INFO -     test_recall    : 0.870182
2024-04-08 18:47:45,394 - trainer - INFO -     epoch          : 2
2024-04-08 18:47:45,394 - trainer - INFO -     loss           : 0.382425
2024-04-08 18:47:45,394 - trainer - INFO -     accuracy       : 0.881945
2024-04-08 18:47:45,394 - trainer - INFO -     macro_f        : 0.881418
2024-04-08 18:47:45,394 - trainer - INFO -     precision      : 0.909975
2024-04-08 18:47:45,394 - trainer - INFO -     recall         : 0.881945
2024-04-08 18:47:45,394 - trainer - INFO -     val_loss       : 0.403909
2024-04-08 18:47:45,394 - trainer - INFO -     val_accuracy   : 0.874545
2024-04-08 18:47:45,394 - trainer - INFO -     val_macro_f    : 0.874404
2024-04-08 18:47:45,394 - trainer - INFO -     val_precision  : 0.905289
2024-04-08 18:47:45,394 - trainer - INFO -     val_recall     : 0.874545
2024-04-08 18:47:45,394 - trainer - INFO -     test_loss      : 0.390051
2024-04-08 18:47:45,394 - trainer - INFO -     test_accuracy  : 0.879
2024-04-08 18:47:45,394 - trainer - INFO -     test_macro_f   : 0.87879
2024-04-08 18:47:45,394 - trainer - INFO -     test_precision : 0.906106
2024-04-08 18:47:45,394 - trainer - INFO -     test_recall    : 0.879
2024-04-08 18:54:22,710 - trainer - INFO -     epoch          : 3
2024-04-08 18:54:22,710 - trainer - INFO -     loss           : 0.323815
2024-04-08 18:54:22,710 - trainer - INFO -     accuracy       : 0.898609
2024-04-08 18:54:22,710 - trainer - INFO -     macro_f        : 0.89877
2024-04-08 18:54:22,710 - trainer - INFO -     precision      : 0.924194
2024-04-08 18:54:22,710 - trainer - INFO -     recall         : 0.898609
2024-04-08 18:54:22,710 - trainer - INFO -     val_loss       : 0.407645
2024-04-08 18:54:22,710 - trainer - INFO -     val_accuracy   : 0.876545
2024-04-08 18:54:22,710 - trainer - INFO -     val_macro_f    : 0.875581
2024-04-08 18:54:22,710 - trainer - INFO -     val_precision  : 0.904394
2024-04-08 18:54:22,710 - trainer - INFO -     val_recall     : 0.876545
2024-04-08 18:54:22,710 - trainer - INFO -     test_loss      : 0.386497
2024-04-08 18:54:22,710 - trainer - INFO -     test_accuracy  : 0.880727
2024-04-08 18:54:22,710 - trainer - INFO -     test_macro_f   : 0.880053
2024-04-08 18:54:22,710 - trainer - INFO -     test_precision : 0.910714
2024-04-08 18:54:22,710 - trainer - INFO -     test_recall    : 0.880727
2024-04-08 18:55:05,642 - train - INFO - PretrainedBaseline(
  (model): BertForSequenceClassification(
    (bert): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (classifier): Linear(in_features=768, out_features=11, bias=True)
  )
)
Trainable params: 24,309,515
Freeze params: 0
2024-04-08 19:01:44,023 - trainer - INFO -     epoch          : 1
2024-04-08 19:01:44,023 - trainer - INFO -     loss           : 0.552148
2024-04-08 19:01:44,023 - trainer - INFO -     accuracy       : 0.830273
2024-04-08 19:01:44,023 - trainer - INFO -     macro_f        : 0.828781
2024-04-08 19:01:44,023 - trainer - INFO -     precision      : 0.86481
2024-04-08 19:01:44,023 - trainer - INFO -     recall         : 0.830273
2024-04-08 19:01:44,023 - trainer - INFO -     val_loss       : 0.426947
2024-04-08 19:01:44,023 - trainer - INFO -     val_accuracy   : 0.865636
2024-04-08 19:01:44,023 - trainer - INFO -     val_macro_f    : 0.865576
2024-04-08 19:01:44,023 - trainer - INFO -     val_precision  : 0.898556
2024-04-08 19:01:44,023 - trainer - INFO -     val_recall     : 0.865636
2024-04-08 19:01:44,023 - trainer - INFO -     test_loss      : 0.411425
2024-04-08 19:01:44,023 - trainer - INFO -     test_accuracy  : 0.871
2024-04-08 19:01:44,023 - trainer - INFO -     test_macro_f   : 0.869978
2024-04-08 19:01:44,023 - trainer - INFO -     test_precision : 0.898919
2024-04-08 19:01:44,023 - trainer - INFO -     test_recall    : 0.871
2024-04-08 19:08:15,035 - trainer - INFO -     epoch          : 2
2024-04-08 19:08:15,035 - trainer - INFO -     loss           : 0.383308
2024-04-08 19:08:15,035 - trainer - INFO -     accuracy       : 0.881073
2024-04-08 19:08:15,035 - trainer - INFO -     macro_f        : 0.880715
2024-04-08 19:08:15,035 - trainer - INFO -     precision      : 0.909395
2024-04-08 19:08:15,035 - trainer - INFO -     recall         : 0.881073
2024-04-08 19:08:15,035 - trainer - INFO -     val_loss       : 0.418989
2024-04-08 19:08:15,035 - trainer - INFO -     val_accuracy   : 0.872273
2024-04-08 19:08:15,035 - trainer - INFO -     val_macro_f    : 0.872104
2024-04-08 19:08:15,035 - trainer - INFO -     val_precision  : 0.904297
2024-04-08 19:08:15,035 - trainer - INFO -     val_recall     : 0.872273
2024-04-08 19:08:15,035 - trainer - INFO -     test_loss      : 0.402036
2024-04-08 19:08:15,035 - trainer - INFO -     test_accuracy  : 0.875182
2024-04-08 19:08:15,035 - trainer - INFO -     test_macro_f   : 0.874819
2024-04-08 19:08:15,035 - trainer - INFO -     test_precision : 0.904981
2024-04-08 19:08:15,035 - trainer - INFO -     test_recall    : 0.875182
2024-04-08 19:14:45,958 - trainer - INFO -     epoch          : 3
2024-04-08 19:14:45,958 - trainer - INFO -     loss           : 0.324263
2024-04-08 19:14:45,958 - trainer - INFO -     accuracy       : 0.898118
2024-04-08 19:14:45,958 - trainer - INFO -     macro_f        : 0.898009
2024-04-08 19:14:45,958 - trainer - INFO -     precision      : 0.923205
2024-04-08 19:14:45,958 - trainer - INFO -     recall         : 0.898118
2024-04-08 19:14:45,958 - trainer - INFO -     val_loss       : 0.419846
2024-04-08 19:14:45,958 - trainer - INFO -     val_accuracy   : 0.874909
2024-04-08 19:14:45,958 - trainer - INFO -     val_macro_f    : 0.874346
2024-04-08 19:14:45,958 - trainer - INFO -     val_precision  : 0.902445
2024-04-08 19:14:45,958 - trainer - INFO -     val_recall     : 0.874909
2024-04-08 19:14:45,958 - trainer - INFO -     test_loss      : 0.390772
2024-04-08 19:14:45,958 - trainer - INFO -     test_accuracy  : 0.880545
2024-04-08 19:14:45,958 - trainer - INFO -     test_macro_f   : 0.880614
2024-04-08 19:14:45,958 - trainer - INFO -     test_precision : 0.909026
2024-04-08 19:14:45,958 - trainer - INFO -     test_recall    : 0.880545
2024-04-08 19:15:28,064 - train - INFO - PretrainedBaseline(
  (model): BertForSequenceClassification(
    (bert): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (classifier): Linear(in_features=768, out_features=11, bias=True)
  )
)
Trainable params: 24,309,515
Freeze params: 0
2024-04-08 19:21:58,850 - trainer - INFO -     epoch          : 1
2024-04-08 19:21:58,850 - trainer - INFO -     loss           : 0.55106
2024-04-08 19:21:58,850 - trainer - INFO -     accuracy       : 0.830118
2024-04-08 19:21:58,850 - trainer - INFO -     macro_f        : 0.828853
2024-04-08 19:21:58,850 - trainer - INFO -     precision      : 0.865226
2024-04-08 19:21:58,850 - trainer - INFO -     recall         : 0.830118
2024-04-08 19:21:58,850 - trainer - INFO -     val_loss       : 0.437499
2024-04-08 19:21:58,850 - trainer - INFO -     val_accuracy   : 0.862909
2024-04-08 19:21:58,850 - trainer - INFO -     val_macro_f    : 0.862221
2024-04-08 19:21:58,850 - trainer - INFO -     val_precision  : 0.894133
2024-04-08 19:21:58,850 - trainer - INFO -     val_recall     : 0.862909
2024-04-08 19:21:58,850 - trainer - INFO -     test_loss      : 0.421411
2024-04-08 19:21:58,850 - trainer - INFO -     test_accuracy  : 0.868091
2024-04-08 19:21:58,850 - trainer - INFO -     test_macro_f   : 0.867807
2024-04-08 19:21:58,850 - trainer - INFO -     test_precision : 0.899237
2024-04-08 19:21:58,865 - trainer - INFO -     test_recall    : 0.868091
2024-04-08 19:28:32,206 - trainer - INFO -     epoch          : 2
2024-04-08 19:28:32,206 - trainer - INFO -     loss           : 0.38191
2024-04-08 19:28:32,206 - trainer - INFO -     accuracy       : 0.880927
2024-04-08 19:28:32,206 - trainer - INFO -     macro_f        : 0.880633
2024-04-08 19:28:32,206 - trainer - INFO -     precision      : 0.909493
2024-04-08 19:28:32,206 - trainer - INFO -     recall         : 0.880927
2024-04-08 19:28:32,206 - trainer - INFO -     val_loss       : 0.414199
2024-04-08 19:28:32,206 - trainer - INFO -     val_accuracy   : 0.873364
2024-04-08 19:28:32,206 - trainer - INFO -     val_macro_f    : 0.87315
2024-04-08 19:28:32,206 - trainer - INFO -     val_precision  : 0.902418
2024-04-08 19:28:32,206 - trainer - INFO -     val_recall     : 0.873364
2024-04-08 19:28:32,206 - trainer - INFO -     test_loss      : 0.392812
2024-04-08 19:28:32,206 - trainer - INFO -     test_accuracy  : 0.879182
2024-04-08 19:28:32,206 - trainer - INFO -     test_macro_f   : 0.880006
2024-04-08 19:28:32,206 - trainer - INFO -     test_precision : 0.911448
2024-04-08 19:28:32,206 - trainer - INFO -     test_recall    : 0.879182
2024-04-08 19:35:06,611 - trainer - INFO -     epoch          : 3
2024-04-08 19:35:06,611 - trainer - INFO -     loss           : 0.326192
2024-04-08 19:35:06,611 - trainer - INFO -     accuracy       : 0.8981
2024-04-08 19:35:06,611 - trainer - INFO -     macro_f        : 0.897824
2024-04-08 19:35:06,611 - trainer - INFO -     precision      : 0.92283
2024-04-08 19:35:06,611 - trainer - INFO -     recall         : 0.8981
2024-04-08 19:35:06,611 - trainer - INFO -     val_loss       : 0.403088
2024-04-08 19:35:06,611 - trainer - INFO -     val_accuracy   : 0.879091
2024-04-08 19:35:06,611 - trainer - INFO -     val_macro_f    : 0.878668
2024-04-08 19:35:06,611 - trainer - INFO -     val_precision  : 0.908721
2024-04-08 19:35:06,611 - trainer - INFO -     val_recall     : 0.879091
2024-04-08 19:35:06,611 - trainer - INFO -     test_loss      : 0.383956
2024-04-08 19:35:06,611 - trainer - INFO -     test_accuracy  : 0.884636
2024-04-08 19:35:06,611 - trainer - INFO -     test_macro_f   : 0.885545
2024-04-08 19:35:06,611 - trainer - INFO -     test_precision : 0.914682
2024-04-08 19:35:06,611 - trainer - INFO -     test_recall    : 0.884636
2024-04-08 19:35:48,150 - train - INFO - PretrainedBaseline(
  (model): BertForSequenceClassification(
    (bert): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (classifier): Linear(in_features=768, out_features=11, bias=True)
  )
)
Trainable params: 24,309,515
Freeze params: 0
2024-04-08 19:42:21,087 - trainer - INFO -     epoch          : 1
2024-04-08 19:42:21,087 - trainer - INFO -     loss           : 0.554462
2024-04-08 19:42:21,087 - trainer - INFO -     accuracy       : 0.828064
2024-04-08 19:42:21,087 - trainer - INFO -     macro_f        : 0.826578
2024-04-08 19:42:21,087 - trainer - INFO -     precision      : 0.86256
2024-04-08 19:42:21,087 - trainer - INFO -     recall         : 0.828064
2024-04-08 19:42:21,087 - trainer - INFO -     val_loss       : 0.430057
2024-04-08 19:42:21,087 - trainer - INFO -     val_accuracy   : 0.864818
2024-04-08 19:42:21,087 - trainer - INFO -     val_macro_f    : 0.864891
2024-04-08 19:42:21,102 - trainer - INFO -     val_precision  : 0.89599
2024-04-08 19:42:21,102 - trainer - INFO -     val_recall     : 0.864818
2024-04-08 19:42:21,102 - trainer - INFO -     test_loss      : 0.412724
2024-04-08 19:42:21,102 - trainer - INFO -     test_accuracy  : 0.871182
2024-04-08 19:42:21,102 - trainer - INFO -     test_macro_f   : 0.871111
2024-04-08 19:42:21,102 - trainer - INFO -     test_precision : 0.901893
2024-04-08 19:42:21,102 - trainer - INFO -     test_recall    : 0.871182
2024-04-08 19:48:53,098 - trainer - INFO -     epoch          : 2
2024-04-08 19:48:53,098 - trainer - INFO -     loss           : 0.384609
2024-04-08 19:48:53,098 - trainer - INFO -     accuracy       : 0.880882
2024-04-08 19:48:53,098 - trainer - INFO -     macro_f        : 0.880489
2024-04-08 19:48:53,098 - trainer - INFO -     precision      : 0.909237
2024-04-08 19:48:53,098 - trainer - INFO -     recall         : 0.880882
2024-04-08 19:48:53,098 - trainer - INFO -     val_loss       : 0.413674
2024-04-08 19:48:53,098 - trainer - INFO -     val_accuracy   : 0.873364
2024-04-08 19:48:53,098 - trainer - INFO -     val_macro_f    : 0.87236
2024-04-08 19:48:53,098 - trainer - INFO -     val_precision  : 0.902859
2024-04-08 19:48:53,098 - trainer - INFO -     val_recall     : 0.873364
2024-04-08 19:48:53,098 - trainer - INFO -     test_loss      : 0.393806
2024-04-08 19:48:53,098 - trainer - INFO -     test_accuracy  : 0.877909
2024-04-08 19:48:53,098 - trainer - INFO -     test_macro_f   : 0.877584
2024-04-08 19:48:53,098 - trainer - INFO -     test_precision : 0.906032
2024-04-08 19:48:53,098 - trainer - INFO -     test_recall    : 0.877909
2024-04-08 19:55:24,525 - trainer - INFO -     epoch          : 3
2024-04-08 19:55:24,525 - trainer - INFO -     loss           : 0.324186
2024-04-08 19:55:24,525 - trainer - INFO -     accuracy       : 0.898864
2024-04-08 19:55:24,525 - trainer - INFO -     macro_f        : 0.898661
2024-04-08 19:55:24,525 - trainer - INFO -     precision      : 0.923467
2024-04-08 19:55:24,525 - trainer - INFO -     recall         : 0.898864
2024-04-08 19:55:24,525 - trainer - INFO -     val_loss       : 0.409608
2024-04-08 19:55:24,525 - trainer - INFO -     val_accuracy   : 0.879364
2024-04-08 19:55:24,525 - trainer - INFO -     val_macro_f    : 0.87991
2024-04-08 19:55:24,525 - trainer - INFO -     val_precision  : 0.910842
2024-04-08 19:55:24,525 - trainer - INFO -     val_recall     : 0.879364
2024-04-08 19:55:24,525 - trainer - INFO -     test_loss      : 0.389575
2024-04-08 19:55:24,525 - trainer - INFO -     test_accuracy  : 0.882727
2024-04-08 19:55:24,525 - trainer - INFO -     test_macro_f   : 0.88295
2024-04-08 19:55:24,525 - trainer - INFO -     test_precision : 0.911868
2024-04-08 19:55:24,525 - trainer - INFO -     test_recall    : 0.882727
2024-04-27 12:07:22,169 - train - INFO - PretrainedBaseline(
  (model): BertForSequenceClassification(
    (bert): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 1024, padding_idx=0)
        (position_embeddings): Embedding(512, 1024)
        (token_type_embeddings): Embedding(2, 1024)
        (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=1024, out_features=1024, bias=True)
                (key): Linear(in_features=1024, out_features=1024, bias=True)
                (value): Linear(in_features=1024, out_features=1024, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=1024, out_features=4096, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=4096, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=1024, out_features=1024, bias=True)
        (activation): Tanh()
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (classifier): Linear(in_features=1024, out_features=11, bias=True)
  )
)
Trainable params: 35,820,555
Freeze params: 0
2024-04-27 12:16:47,724 - trainer - INFO -     epoch          : 1
2024-04-27 12:16:47,724 - trainer - INFO -     loss           : 0.513702
2024-04-27 12:16:47,724 - trainer - INFO -     accuracy       : 0.843173
2024-04-27 12:16:47,724 - trainer - INFO -     macro_f        : 0.841874
2024-04-27 12:16:47,724 - trainer - INFO -     precision      : 0.876905
2024-04-27 12:16:47,724 - trainer - INFO -     recall         : 0.843173
2024-04-27 12:16:47,724 - trainer - INFO -     val_loss       : 0.403244
2024-04-27 12:16:47,724 - trainer - INFO -     val_accuracy   : 0.873636
2024-04-27 12:16:47,724 - trainer - INFO -     val_macro_f    : 0.873361
2024-04-27 12:16:47,724 - trainer - INFO -     val_precision  : 0.903502
2024-04-27 12:16:47,724 - trainer - INFO -     val_recall     : 0.873636
2024-04-27 12:16:47,724 - trainer - INFO -     test_loss      : 0.391086
2024-04-27 12:16:47,724 - trainer - INFO -     test_accuracy  : 0.878545
2024-04-27 12:16:47,724 - trainer - INFO -     test_macro_f   : 0.878492
2024-04-27 12:16:47,724 - trainer - INFO -     test_precision : 0.906297
2024-04-27 12:16:47,724 - trainer - INFO -     test_recall    : 0.878545
2024-04-27 12:26:17,428 - trainer - INFO -     epoch          : 2
2024-04-27 12:26:17,428 - trainer - INFO -     loss           : 0.353421
2024-04-27 12:26:17,428 - trainer - INFO -     accuracy       : 0.890818
2024-04-27 12:26:17,428 - trainer - INFO -     macro_f        : 0.890734
2024-04-27 12:26:17,428 - trainer - INFO -     precision      : 0.917709
2024-04-27 12:26:17,428 - trainer - INFO -     recall         : 0.890818
2024-04-27 12:26:17,428 - trainer - INFO -     val_loss       : 0.407513
2024-04-27 12:26:17,428 - trainer - INFO -     val_accuracy   : 0.881636
2024-04-27 12:26:17,428 - trainer - INFO -     val_macro_f    : 0.881446
2024-04-27 12:26:17,428 - trainer - INFO -     val_precision  : 0.90929
2024-04-27 12:26:17,428 - trainer - INFO -     val_recall     : 0.881636
2024-04-27 12:26:17,428 - trainer - INFO -     test_loss      : 0.383183
2024-04-27 12:26:17,428 - trainer - INFO -     test_accuracy  : 0.884091
2024-04-27 12:26:17,428 - trainer - INFO -     test_macro_f   : 0.883777
2024-04-27 12:26:17,428 - trainer - INFO -     test_precision : 0.910535
2024-04-27 12:26:17,428 - trainer - INFO -     test_recall    : 0.884091
2024-04-27 12:35:47,505 - trainer - INFO -     epoch          : 3
2024-04-27 12:35:47,505 - trainer - INFO -     loss           : 0.294491
2024-04-27 12:35:47,505 - trainer - INFO -     accuracy       : 0.908
2024-04-27 12:35:47,505 - trainer - INFO -     macro_f        : 0.907423
2024-04-27 12:35:47,505 - trainer - INFO -     precision      : 0.929966
2024-04-27 12:35:47,505 - trainer - INFO -     recall         : 0.908
2024-04-27 12:35:47,505 - trainer - INFO -     val_loss       : 0.395967
2024-04-27 12:35:47,505 - trainer - INFO -     val_accuracy   : 0.879545
2024-04-27 12:35:47,505 - trainer - INFO -     val_macro_f    : 0.878981
2024-04-27 12:35:47,505 - trainer - INFO -     val_precision  : 0.907546
2024-04-27 12:35:47,505 - trainer - INFO -     val_recall     : 0.879545
2024-04-27 12:35:47,505 - trainer - INFO -     test_loss      : 0.375614
2024-04-27 12:35:47,505 - trainer - INFO -     test_accuracy  : 0.885
2024-04-27 12:35:47,505 - trainer - INFO -     test_macro_f   : 0.885523
2024-04-27 12:35:47,505 - trainer - INFO -     test_precision : 0.912807
2024-04-27 12:35:47,505 - trainer - INFO -     test_recall    : 0.885
2024-04-27 12:36:43,033 - train - INFO - PretrainedBaseline(
  (model): BertForSequenceClassification(
    (bert): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 1024, padding_idx=0)
        (position_embeddings): Embedding(512, 1024)
        (token_type_embeddings): Embedding(2, 1024)
        (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=1024, out_features=1024, bias=True)
                (key): Linear(in_features=1024, out_features=1024, bias=True)
                (value): Linear(in_features=1024, out_features=1024, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=1024, out_features=4096, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=4096, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=1024, out_features=1024, bias=True)
        (activation): Tanh()
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (classifier): Linear(in_features=1024, out_features=11, bias=True)
  )
)
Trainable params: 35,820,555
Freeze params: 0
2024-04-27 12:46:16,062 - trainer - INFO -     epoch          : 1
2024-04-27 12:46:16,062 - trainer - INFO -     loss           : 0.514087
2024-04-27 12:46:16,062 - trainer - INFO -     accuracy       : 0.842655
2024-04-27 12:46:16,062 - trainer - INFO -     macro_f        : 0.841706
2024-04-27 12:46:16,062 - trainer - INFO -     precision      : 0.877191
2024-04-27 12:46:16,062 - trainer - INFO -     recall         : 0.842655
2024-04-27 12:46:16,062 - trainer - INFO -     val_loss       : 0.40815
2024-04-27 12:46:16,062 - trainer - INFO -     val_accuracy   : 0.873455
2024-04-27 12:46:16,062 - trainer - INFO -     val_macro_f    : 0.873853
2024-04-27 12:46:16,062 - trainer - INFO -     val_precision  : 0.904973
2024-04-27 12:46:16,062 - trainer - INFO -     val_recall     : 0.873455
2024-04-27 12:46:16,062 - trainer - INFO -     test_loss      : 0.393007
2024-04-27 12:46:16,062 - trainer - INFO -     test_accuracy  : 0.879091
2024-04-27 12:46:16,062 - trainer - INFO -     test_macro_f   : 0.878415
2024-04-27 12:46:16,062 - trainer - INFO -     test_precision : 0.908447
2024-04-27 12:46:16,062 - trainer - INFO -     test_recall    : 0.879091
2024-04-27 12:55:46,072 - trainer - INFO -     epoch          : 2
2024-04-27 12:55:46,072 - trainer - INFO -     loss           : 0.35614
2024-04-27 12:55:46,072 - trainer - INFO -     accuracy       : 0.889518
2024-04-27 12:55:46,072 - trainer - INFO -     macro_f        : 0.88958
2024-04-27 12:55:46,072 - trainer - INFO -     precision      : 0.9172
2024-04-27 12:55:46,072 - trainer - INFO -     recall         : 0.889518
2024-04-27 12:55:46,072 - trainer - INFO -     val_loss       : 0.397981
2024-04-27 12:55:46,072 - trainer - INFO -     val_accuracy   : 0.877727
2024-04-27 12:55:46,072 - trainer - INFO -     val_macro_f    : 0.87685
2024-04-27 12:55:46,072 - trainer - INFO -     val_precision  : 0.904586
2024-04-27 12:55:46,088 - trainer - INFO -     val_recall     : 0.877727
2024-04-27 12:55:46,088 - trainer - INFO -     test_loss      : 0.386249
2024-04-27 12:55:46,088 - trainer - INFO -     test_accuracy  : 0.881455
2024-04-27 12:55:46,088 - trainer - INFO -     test_macro_f   : 0.882248
2024-04-27 12:55:46,088 - trainer - INFO -     test_precision : 0.910985
2024-04-27 12:55:46,088 - trainer - INFO -     test_recall    : 0.881455
2024-04-27 13:05:17,079 - trainer - INFO -     epoch          : 3
2024-04-27 13:05:17,079 - trainer - INFO -     loss           : 0.294655
2024-04-27 13:05:17,079 - trainer - INFO -     accuracy       : 0.907345
2024-04-27 13:05:17,079 - trainer - INFO -     macro_f        : 0.906903
2024-04-27 13:05:17,079 - trainer - INFO -     precision      : 0.930154
2024-04-27 13:05:17,079 - trainer - INFO -     recall         : 0.907345
2024-04-27 13:05:17,079 - trainer - INFO -     val_loss       : 0.403129
2024-04-27 13:05:17,094 - trainer - INFO -     val_accuracy   : 0.880545
2024-04-27 13:05:17,094 - trainer - INFO -     val_macro_f    : 0.880371
2024-04-27 13:05:17,094 - trainer - INFO -     val_precision  : 0.908965
2024-04-27 13:05:17,094 - trainer - INFO -     val_recall     : 0.880545
2024-04-27 13:05:17,094 - trainer - INFO -     test_loss      : 0.381885
2024-04-27 13:05:17,094 - trainer - INFO -     test_accuracy  : 0.887818
2024-04-27 13:05:17,094 - trainer - INFO -     test_macro_f   : 0.888157
2024-04-27 13:05:17,094 - trainer - INFO -     test_precision : 0.915569
2024-04-27 13:05:17,094 - trainer - INFO -     test_recall    : 0.887818
2024-04-27 13:06:12,713 - train - INFO - PretrainedBaseline(
  (model): BertForSequenceClassification(
    (bert): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 1024, padding_idx=0)
        (position_embeddings): Embedding(512, 1024)
        (token_type_embeddings): Embedding(2, 1024)
        (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=1024, out_features=1024, bias=True)
                (key): Linear(in_features=1024, out_features=1024, bias=True)
                (value): Linear(in_features=1024, out_features=1024, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=1024, out_features=4096, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=4096, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=1024, out_features=1024, bias=True)
        (activation): Tanh()
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (classifier): Linear(in_features=1024, out_features=11, bias=True)
  )
)
Trainable params: 35,820,555
Freeze params: 0
2024-04-27 13:15:45,140 - trainer - INFO -     epoch          : 1
2024-04-27 13:15:45,140 - trainer - INFO -     loss           : 0.516513
2024-04-27 13:15:45,140 - trainer - INFO -     accuracy       : 0.840773
2024-04-27 13:15:45,140 - trainer - INFO -     macro_f        : 0.839792
2024-04-27 13:15:45,140 - trainer - INFO -     precision      : 0.874914
2024-04-27 13:15:45,140 - trainer - INFO -     recall         : 0.840773
2024-04-27 13:15:45,140 - trainer - INFO -     val_loss       : 0.401227
2024-04-27 13:15:45,140 - trainer - INFO -     val_accuracy   : 0.877
2024-04-27 13:15:45,140 - trainer - INFO -     val_macro_f    : 0.877036
2024-04-27 13:15:45,140 - trainer - INFO -     val_precision  : 0.905367
2024-04-27 13:15:45,140 - trainer - INFO -     val_recall     : 0.877
2024-04-27 13:15:45,140 - trainer - INFO -     test_loss      : 0.391368
2024-04-27 13:15:45,140 - trainer - INFO -     test_accuracy  : 0.877727
2024-04-27 13:15:45,140 - trainer - INFO -     test_macro_f   : 0.877461
2024-04-27 13:15:45,140 - trainer - INFO -     test_precision : 0.905994
2024-04-27 13:15:45,140 - trainer - INFO -     test_recall    : 0.877727
2024-04-27 13:25:15,094 - trainer - INFO -     epoch          : 2
2024-04-27 13:25:15,094 - trainer - INFO -     loss           : 0.353007
2024-04-27 13:25:15,094 - trainer - INFO -     accuracy       : 0.890164
2024-04-27 13:25:15,094 - trainer - INFO -     macro_f        : 0.8899
2024-04-27 13:25:15,094 - trainer - INFO -     precision      : 0.916911
2024-04-27 13:25:15,094 - trainer - INFO -     recall         : 0.890164
2024-04-27 13:25:15,094 - trainer - INFO -     val_loss       : 0.393969
2024-04-27 13:25:15,094 - trainer - INFO -     val_accuracy   : 0.879364
2024-04-27 13:25:15,094 - trainer - INFO -     val_macro_f    : 0.879241
2024-04-27 13:25:15,094 - trainer - INFO -     val_precision  : 0.908863
2024-04-27 13:25:15,110 - trainer - INFO -     val_recall     : 0.879364
2024-04-27 13:25:15,110 - trainer - INFO -     test_loss      : 0.383875
2024-04-27 13:25:15,110 - trainer - INFO -     test_accuracy  : 0.880818
2024-04-27 13:25:15,110 - trainer - INFO -     test_macro_f   : 0.880124
2024-04-27 13:25:15,110 - trainer - INFO -     test_precision : 0.908193
2024-04-27 13:25:15,110 - trainer - INFO -     test_recall    : 0.880818
2024-04-27 13:34:46,459 - trainer - INFO -     epoch          : 3
2024-04-27 13:34:46,459 - trainer - INFO -     loss           : 0.291972
2024-04-27 13:34:46,459 - trainer - INFO -     accuracy       : 0.907882
2024-04-27 13:34:46,459 - trainer - INFO -     macro_f        : 0.907681
2024-04-27 13:34:46,459 - trainer - INFO -     precision      : 0.930776
2024-04-27 13:34:46,459 - trainer - INFO -     recall         : 0.907882
2024-04-27 13:34:46,459 - trainer - INFO -     val_loss       : 0.412487
2024-04-27 13:34:46,459 - trainer - INFO -     val_accuracy   : 0.876091
2024-04-27 13:34:46,459 - trainer - INFO -     val_macro_f    : 0.875661
2024-04-27 13:34:46,459 - trainer - INFO -     val_precision  : 0.905983
2024-04-27 13:34:46,459 - trainer - INFO -     val_recall     : 0.876091
2024-04-27 13:34:46,459 - trainer - INFO -     test_loss      : 0.395158
2024-04-27 13:34:46,459 - trainer - INFO -     test_accuracy  : 0.883182
2024-04-27 13:34:46,459 - trainer - INFO -     test_macro_f   : 0.883169
2024-04-27 13:34:46,459 - trainer - INFO -     test_precision : 0.911852
2024-04-27 13:34:46,459 - trainer - INFO -     test_recall    : 0.883182
2024-04-27 13:35:38,862 - train - INFO - PretrainedBaseline(
  (model): BertForSequenceClassification(
    (bert): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 1024, padding_idx=0)
        (position_embeddings): Embedding(512, 1024)
        (token_type_embeddings): Embedding(2, 1024)
        (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=1024, out_features=1024, bias=True)
                (key): Linear(in_features=1024, out_features=1024, bias=True)
                (value): Linear(in_features=1024, out_features=1024, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=1024, out_features=4096, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=4096, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=1024, out_features=1024, bias=True)
        (activation): Tanh()
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (classifier): Linear(in_features=1024, out_features=11, bias=True)
  )
)
Trainable params: 35,820,555
Freeze params: 0
2024-04-27 13:45:09,020 - trainer - INFO -     epoch          : 1
2024-04-27 13:45:09,020 - trainer - INFO -     loss           : 0.514285
2024-04-27 13:45:09,020 - trainer - INFO -     accuracy       : 0.841309
2024-04-27 13:45:09,020 - trainer - INFO -     macro_f        : 0.839705
2024-04-27 13:45:09,020 - trainer - INFO -     precision      : 0.87465
2024-04-27 13:45:09,020 - trainer - INFO -     recall         : 0.841309
2024-04-27 13:45:09,020 - trainer - INFO -     val_loss       : 0.414842
2024-04-27 13:45:09,020 - trainer - INFO -     val_accuracy   : 0.871
2024-04-27 13:45:09,020 - trainer - INFO -     val_macro_f    : 0.871467
2024-04-27 13:45:09,020 - trainer - INFO -     val_precision  : 0.901548
2024-04-27 13:45:09,020 - trainer - INFO -     val_recall     : 0.871
2024-04-27 13:45:09,020 - trainer - INFO -     test_loss      : 0.398523
2024-04-27 13:45:09,020 - trainer - INFO -     test_accuracy  : 0.875273
2024-04-27 13:45:09,020 - trainer - INFO -     test_macro_f   : 0.876044
2024-04-27 13:45:09,020 - trainer - INFO -     test_precision : 0.907675
2024-04-27 13:45:09,020 - trainer - INFO -     test_recall    : 0.875273
2024-04-27 13:54:39,162 - trainer - INFO -     epoch          : 2
2024-04-27 13:54:39,162 - trainer - INFO -     loss           : 0.354654
2024-04-27 13:54:39,162 - trainer - INFO -     accuracy       : 0.890536
2024-04-27 13:54:39,162 - trainer - INFO -     macro_f        : 0.890314
2024-04-27 13:54:39,162 - trainer - INFO -     precision      : 0.917181
2024-04-27 13:54:39,162 - trainer - INFO -     recall         : 0.890536
2024-04-27 13:54:39,162 - trainer - INFO -     val_loss       : 0.399247
2024-04-27 13:54:39,162 - trainer - INFO -     val_accuracy   : 0.876364
2024-04-27 13:54:39,162 - trainer - INFO -     val_macro_f    : 0.876191
2024-04-27 13:54:39,162 - trainer - INFO -     val_precision  : 0.905532
2024-04-27 13:54:39,162 - trainer - INFO -     val_recall     : 0.876364
2024-04-27 13:54:39,162 - trainer - INFO -     test_loss      : 0.383328
2024-04-27 13:54:39,162 - trainer - INFO -     test_accuracy  : 0.881818
2024-04-27 13:54:39,162 - trainer - INFO -     test_macro_f   : 0.881642
2024-04-27 13:54:39,162 - trainer - INFO -     test_precision : 0.911561
2024-04-27 13:54:39,162 - trainer - INFO -     test_recall    : 0.881818
2024-04-27 14:04:09,224 - trainer - INFO -     epoch          : 3
2024-04-27 14:04:09,224 - trainer - INFO -     loss           : 0.29268
2024-04-27 14:04:09,224 - trainer - INFO -     accuracy       : 0.907636
2024-04-27 14:04:09,224 - trainer - INFO -     macro_f        : 0.907228
2024-04-27 14:04:09,224 - trainer - INFO -     precision      : 0.929984
2024-04-27 14:04:09,224 - trainer - INFO -     recall         : 0.907636
2024-04-27 14:04:09,224 - trainer - INFO -     val_loss       : 0.405457
2024-04-27 14:04:09,224 - trainer - INFO -     val_accuracy   : 0.881091
2024-04-27 14:04:09,224 - trainer - INFO -     val_macro_f    : 0.879924
2024-04-27 14:04:09,239 - trainer - INFO -     val_precision  : 0.907666
2024-04-27 14:04:09,239 - trainer - INFO -     val_recall     : 0.881091
2024-04-27 14:04:09,239 - trainer - INFO -     test_loss      : 0.387725
2024-04-27 14:04:09,239 - trainer - INFO -     test_accuracy  : 0.883727
2024-04-27 14:04:09,239 - trainer - INFO -     test_macro_f   : 0.885569
2024-04-27 14:04:09,239 - trainer - INFO -     test_precision : 0.915747
2024-04-27 14:04:09,239 - trainer - INFO -     test_recall    : 0.883727
2024-04-27 14:05:03,937 - train - INFO - PretrainedBaseline(
  (model): BertForSequenceClassification(
    (bert): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 1024, padding_idx=0)
        (position_embeddings): Embedding(512, 1024)
        (token_type_embeddings): Embedding(2, 1024)
        (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=1024, out_features=1024, bias=True)
                (key): Linear(in_features=1024, out_features=1024, bias=True)
                (value): Linear(in_features=1024, out_features=1024, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=1024, out_features=4096, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=4096, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=1024, out_features=1024, bias=True)
        (activation): Tanh()
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (classifier): Linear(in_features=1024, out_features=11, bias=True)
  )
)
Trainable params: 35,820,555
Freeze params: 0
2024-04-27 14:14:34,523 - trainer - INFO -     epoch          : 1
2024-04-27 14:14:34,523 - trainer - INFO -     loss           : 0.513669
2024-04-27 14:14:34,523 - trainer - INFO -     accuracy       : 0.842409
2024-04-27 14:14:34,523 - trainer - INFO -     macro_f        : 0.841042
2024-04-27 14:14:34,523 - trainer - INFO -     precision      : 0.876501
2024-04-27 14:14:34,523 - trainer - INFO -     recall         : 0.842409
2024-04-27 14:14:34,523 - trainer - INFO -     val_loss       : 0.428828
2024-04-27 14:14:34,523 - trainer - INFO -     val_accuracy   : 0.867182
2024-04-27 14:14:34,523 - trainer - INFO -     val_macro_f    : 0.866254
2024-04-27 14:14:34,523 - trainer - INFO -     val_precision  : 0.898209
2024-04-27 14:14:34,523 - trainer - INFO -     val_recall     : 0.867182
2024-04-27 14:14:34,523 - trainer - INFO -     test_loss      : 0.410224
2024-04-27 14:14:34,523 - trainer - INFO -     test_accuracy  : 0.873545
2024-04-27 14:14:34,523 - trainer - INFO -     test_macro_f   : 0.873085
2024-04-27 14:14:34,523 - trainer - INFO -     test_precision : 0.903506
2024-04-27 14:14:34,523 - trainer - INFO -     test_recall    : 0.873545
2024-04-27 14:24:05,947 - trainer - INFO -     epoch          : 2
2024-04-27 14:24:05,947 - trainer - INFO -     loss           : 0.353983
2024-04-27 14:24:05,947 - trainer - INFO -     accuracy       : 0.890418
2024-04-27 14:24:05,947 - trainer - INFO -     macro_f        : 0.89027
2024-04-27 14:24:05,947 - trainer - INFO -     precision      : 0.917234
2024-04-27 14:24:05,947 - trainer - INFO -     recall         : 0.890418
2024-04-27 14:24:05,947 - trainer - INFO -     val_loss       : 0.40972
2024-04-27 14:24:05,947 - trainer - INFO -     val_accuracy   : 0.877545
2024-04-27 14:24:05,947 - trainer - INFO -     val_macro_f    : 0.877146
2024-04-27 14:24:05,947 - trainer - INFO -     val_precision  : 0.907393
2024-04-27 14:24:05,947 - trainer - INFO -     val_recall     : 0.877545
2024-04-27 14:24:05,947 - trainer - INFO -     test_loss      : 0.391851
2024-04-27 14:24:05,947 - trainer - INFO -     test_accuracy  : 0.882364
2024-04-27 14:24:05,947 - trainer - INFO -     test_macro_f   : 0.881279
2024-04-27 14:24:05,947 - trainer - INFO -     test_precision : 0.907638
2024-04-27 14:24:05,947 - trainer - INFO -     test_recall    : 0.882364
2024-04-27 14:33:36,886 - trainer - INFO -     epoch          : 3
2024-04-27 14:33:36,886 - trainer - INFO -     loss           : 0.295515
2024-04-27 14:33:36,886 - trainer - INFO -     accuracy       : 0.907109
2024-04-27 14:33:36,886 - trainer - INFO -     macro_f        : 0.906776
2024-04-27 14:33:36,886 - trainer - INFO -     precision      : 0.930017
2024-04-27 14:33:36,886 - trainer - INFO -     recall         : 0.907109
2024-04-27 14:33:36,886 - trainer - INFO -     val_loss       : 0.409101
2024-04-27 14:33:36,886 - trainer - INFO -     val_accuracy   : 0.880455
2024-04-27 14:33:36,886 - trainer - INFO -     val_macro_f    : 0.880041
2024-04-27 14:33:36,886 - trainer - INFO -     val_precision  : 0.908884
2024-04-27 14:33:36,886 - trainer - INFO -     val_recall     : 0.880455
2024-04-27 14:33:36,886 - trainer - INFO -     test_loss      : 0.392772
2024-04-27 14:33:36,886 - trainer - INFO -     test_accuracy  : 0.885273
2024-04-27 14:33:36,886 - trainer - INFO -     test_macro_f   : 0.886267
2024-04-27 14:33:36,886 - trainer - INFO -     test_precision : 0.913732
2024-04-27 14:33:36,886 - trainer - INFO -     test_recall    : 0.885273
