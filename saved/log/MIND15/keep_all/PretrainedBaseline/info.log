2024-02-26 12:41:19,288 - train - INFO - PretrainedBaseline(
  (model): BertForSequenceClassification(
    (bert): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(30522, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (classifier): Linear(in_features=768, out_features=15, bias=True)
  )
)
Trainable params: 31,527,183
Freeze params: 0
2024-02-26 12:47:06,765 - trainer - INFO -     epoch          : 1
2024-02-26 12:47:06,767 - trainer - INFO -     loss           : 0.939644
2024-02-26 12:47:06,767 - trainer - INFO -     accuracy       : 0.700611
2024-02-26 12:47:06,767 - trainer - INFO -     macro_f        : 0.462227
2024-02-26 12:47:06,767 - trainer - INFO -     val_loss       : 0.727442
2024-02-26 12:47:06,767 - trainer - INFO -     val_accuracy   : 0.757095
2024-02-26 12:47:06,768 - trainer - INFO -     val_macro_f    : 0.562245
2024-02-26 12:52:52,959 - trainer - INFO -     epoch          : 2
2024-02-26 12:52:52,959 - trainer - INFO -     loss           : 0.630136
2024-02-26 12:52:52,959 - trainer - INFO -     accuracy       : 0.787313
2024-02-26 12:52:52,959 - trainer - INFO -     macro_f        : 0.606987
2024-02-26 12:52:52,960 - trainer - INFO -     val_loss       : 0.760077
2024-02-26 12:52:52,960 - trainer - INFO -     val_accuracy   : 0.753336
2024-02-26 12:52:52,960 - trainer - INFO -     val_macro_f    : 0.562242
2024-02-26 12:58:38,974 - trainer - INFO -     epoch          : 3
2024-02-26 12:58:38,975 - trainer - INFO -     loss           : 0.477439
2024-02-26 12:58:38,975 - trainer - INFO -     accuracy       : 0.83391
2024-02-26 12:58:38,975 - trainer - INFO -     macro_f        : 0.689491
2024-02-26 12:58:38,975 - trainer - INFO -     val_loss       : 0.762255
2024-02-26 12:58:38,976 - trainer - INFO -     val_accuracy   : 0.761697
2024-02-26 12:58:38,976 - trainer - INFO -     val_macro_f    : 0.568257
2024-02-26 13:04:00,658 - train - INFO - PretrainedBaseline(
  (model): DistilBertForSequenceClassification(
    (distilbert): DistilBertModel(
      (embeddings): Embeddings(
        (word_embeddings): Embedding(30522, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (transformer): Transformer(
        (layer): ModuleList(
          (0): TransformerBlock(
            (attention): MultiHeadSelfAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (q_lin): Linear(in_features=768, out_features=768, bias=True)
              (k_lin): Linear(in_features=768, out_features=768, bias=True)
              (v_lin): Linear(in_features=768, out_features=768, bias=True)
              (out_lin): Linear(in_features=768, out_features=768, bias=True)
            )
            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (ffn): FFN(
              (dropout): Dropout(p=0.1, inplace=False)
              (lin1): Linear(in_features=768, out_features=3072, bias=True)
              (lin2): Linear(in_features=3072, out_features=768, bias=True)
              (activation): GELUActivation()
            )
            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          )
        )
      )
    )
    (pre_classifier): Linear(in_features=768, out_features=768, bias=True)
    (classifier): Linear(in_features=768, out_features=15, bias=True)
    (dropout): Dropout(p=0.2, inplace=False)
  )
)
Trainable params: 31,525,647
Freeze params: 0
2024-02-26 13:09:49,523 - trainer - INFO -     epoch          : 1
2024-02-26 13:09:49,525 - trainer - INFO -     loss           : 0.884844
2024-02-26 13:09:49,525 - trainer - INFO -     accuracy       : 0.716095
2024-02-26 13:09:49,525 - trainer - INFO -     macro_f        : 0.482622
2024-02-26 13:09:49,525 - trainer - INFO -     val_loss       : 0.741124
2024-02-26 13:09:49,525 - trainer - INFO -     val_accuracy   : 0.746357
2024-02-26 13:09:49,525 - trainer - INFO -     val_macro_f    : 0.558087
2024-02-26 13:15:47,602 - trainer - INFO -     epoch          : 2
2024-02-26 13:15:47,603 - trainer - INFO -     loss           : 0.604488
2024-02-26 13:15:47,603 - trainer - INFO -     accuracy       : 0.797889
2024-02-26 13:15:47,604 - trainer - INFO -     macro_f        : 0.621375
2024-02-26 13:15:47,604 - trainer - INFO -     val_loss       : 0.712843
2024-02-26 13:15:47,604 - trainer - INFO -     val_accuracy   : 0.76254
2024-02-26 13:15:47,604 - trainer - INFO -     val_macro_f    : 0.577795
2024-02-26 13:21:34,429 - trainer - INFO -     epoch          : 3
2024-02-26 13:21:34,430 - trainer - INFO -     loss           : 0.460052
2024-02-26 13:21:34,430 - trainer - INFO -     accuracy       : 0.842252
2024-02-26 13:21:34,431 - trainer - INFO -     macro_f        : 0.701964
2024-02-26 13:21:34,431 - trainer - INFO -     val_loss       : 0.836139
2024-02-26 13:21:34,431 - trainer - INFO -     val_accuracy   : 0.738457
2024-02-26 13:21:34,431 - trainer - INFO -     val_macro_f    : 0.549566
2024-02-26 13:27:19,010 - trainer - INFO -     epoch          : 4
2024-02-26 13:27:19,010 - trainer - INFO -     loss           : 0.35458
2024-02-26 13:27:19,010 - trainer - INFO -     accuracy       : 0.875838
2024-02-26 13:27:19,010 - trainer - INFO -     macro_f        : 0.768044
2024-02-26 13:27:19,011 - trainer - INFO -     val_loss       : 0.850597
2024-02-26 13:27:19,011 - trainer - INFO -     val_accuracy   : 0.76093
2024-02-26 13:27:19,011 - trainer - INFO -     val_macro_f    : 0.575084
2024-02-26 13:33:03,103 - trainer - INFO -     epoch          : 5
2024-02-26 13:33:03,103 - trainer - INFO -     loss           : 0.277788
2024-02-26 13:33:03,103 - trainer - INFO -     accuracy       : 0.902137
2024-02-26 13:33:03,103 - trainer - INFO -     macro_f        : 0.813428
2024-02-26 13:33:03,104 - trainer - INFO -     val_loss       : 1.026502
2024-02-26 13:33:03,104 - trainer - INFO -     val_accuracy   : 0.740221
2024-02-26 13:33:03,104 - trainer - INFO -     val_macro_f    : 0.545659
2024-02-26 13:42:32,087 - train - INFO - PretrainedBaseline(
  (model): XLNetForSequenceClassification(
    (transformer): XLNetModel(
      (word_embedding): Embedding(32000, 768)
      (layer): ModuleList(
        (0): XLNetLayer(
          (rel_attn): XLNetRelativeAttention(
            (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (ff): XLNetFeedForward(
            (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (layer_1): Linear(in_features=768, out_features=3072, bias=True)
            (layer_2): Linear(in_features=3072, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (activation_function): GELUActivation()
          )
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (sequence_summary): SequenceSummary(
      (summary): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
      (first_dropout): Identity()
      (last_dropout): Dropout(p=0.1, inplace=False)
    )
    (logits_proj): Linear(in_features=768, out_features=15, bias=True)
  )
)
Trainable params: 32,857,359
Freeze params: 0
2024-02-26 13:51:06,867 - trainer - INFO -     epoch          : 1
2024-02-26 13:51:06,872 - trainer - INFO -     loss           : 0.870393
2024-02-26 13:51:06,872 - trainer - INFO -     accuracy       : 0.720371
2024-02-26 13:51:06,872 - trainer - INFO -     macro_f        : 0.493256
2024-02-26 13:51:06,872 - trainer - INFO -     val_loss       : 0.748322
2024-02-26 13:51:06,873 - trainer - INFO -     val_accuracy   : 0.752953
2024-02-26 13:51:06,873 - trainer - INFO -     val_macro_f    : 0.56146
2024-02-26 13:59:12,201 - trainer - INFO -     epoch          : 2
2024-02-26 13:59:12,201 - trainer - INFO -     loss           : 0.58406
2024-02-26 13:59:12,202 - trainer - INFO -     accuracy       : 0.806853
2024-02-26 13:59:12,202 - trainer - INFO -     macro_f        : 0.635675
2024-02-26 13:59:12,202 - trainer - INFO -     val_loss       : 0.738279
2024-02-26 13:59:12,202 - trainer - INFO -     val_accuracy   : 0.763
2024-02-26 13:59:12,203 - trainer - INFO -     val_macro_f    : 0.579011
2024-02-26 14:07:14,366 - trainer - INFO -     epoch          : 3
2024-02-26 14:07:14,366 - trainer - INFO -     loss           : 0.425415
2024-02-26 14:07:14,366 - trainer - INFO -     accuracy       : 0.856365
2024-02-26 14:07:14,366 - trainer - INFO -     macro_f        : 0.725316
2024-02-26 14:07:14,367 - trainer - INFO -     val_loss       : 0.864682
2024-02-26 14:07:14,367 - trainer - INFO -     val_accuracy   : 0.745667
2024-02-26 14:07:14,367 - trainer - INFO -     val_macro_f    : 0.566583
2024-02-26 14:15:17,404 - trainer - INFO -     epoch          : 4
2024-02-26 14:15:17,406 - trainer - INFO -     loss           : 0.30654
2024-02-26 14:15:17,406 - trainer - INFO -     accuracy       : 0.896806
2024-02-26 14:15:17,406 - trainer - INFO -     macro_f        : 0.80244
2024-02-26 14:15:17,407 - trainer - INFO -     val_loss       : 0.948368
2024-02-26 14:15:17,407 - trainer - INFO -     val_accuracy   : 0.754027
2024-02-26 14:15:17,407 - trainer - INFO -     val_macro_f    : 0.561622
2024-02-26 14:23:31,158 - trainer - INFO -     epoch          : 5
2024-02-26 14:23:31,158 - trainer - INFO -     loss           : 0.219367
2024-02-26 14:23:31,159 - trainer - INFO -     accuracy       : 0.927133
2024-02-26 14:23:31,159 - trainer - INFO -     macro_f        : 0.856394
2024-02-26 14:23:31,159 - trainer - INFO -     val_loss       : 1.083076
2024-02-26 14:23:31,159 - trainer - INFO -     val_accuracy   : 0.747661
2024-02-26 14:23:31,160 - trainer - INFO -     val_macro_f    : 0.559152
2024-02-26 16:48:30,690 - train - INFO - PretrainedBaseline(
  (model): RobertaForSequenceClassification(
    (roberta): RobertaModel(
      (embeddings): RobertaEmbeddings(
        (word_embeddings): Embedding(50265, 768, padding_idx=0)
        (position_embeddings): Embedding(514, 768, padding_idx=0)
        (token_type_embeddings): Embedding(1, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): RobertaEncoder(
        (layer): ModuleList(
          (0): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
    )
    (classifier): RobertaClassificationHead(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (dropout): Dropout(p=0.1, inplace=False)
      (out_proj): Linear(in_features=768, out_features=15, bias=True)
    )
  )
)
Trainable params: 46,690,575
Freeze params: 0
2024-02-26 16:55:03,854 - trainer - INFO -     epoch          : 1
2024-02-26 16:55:03,857 - trainer - INFO -     loss           : 0.826596
2024-02-26 16:55:03,857 - trainer - INFO -     accuracy       : 0.730544
2024-02-26 16:55:03,858 - trainer - INFO -     macro_f        : 0.510677
2024-02-26 16:55:03,858 - trainer - INFO -     val_loss       : 0.706793
2024-02-26 16:55:03,858 - trainer - INFO -     val_accuracy   : 0.757095
2024-02-26 16:55:03,858 - trainer - INFO -     val_macro_f    : 0.582446
2024-02-26 17:01:23,086 - trainer - INFO -     epoch          : 2
2024-02-26 17:01:23,086 - trainer - INFO -     loss           : 0.540556
2024-02-26 17:01:23,086 - trainer - INFO -     accuracy       : 0.818905
2024-02-26 17:01:23,086 - trainer - INFO -     macro_f        : 0.658857
2024-02-26 17:01:23,086 - trainer - INFO -     val_loss       : 0.710428
2024-02-26 17:01:23,086 - trainer - INFO -     val_accuracy   : 0.762157
2024-02-26 17:01:23,086 - trainer - INFO -     val_macro_f    : 0.580017
2024-02-26 17:07:39,017 - trainer - INFO -     epoch          : 3
2024-02-26 17:07:39,018 - trainer - INFO -     loss           : 0.35844
2024-02-26 17:07:39,018 - trainer - INFO -     accuracy       : 0.878503
2024-02-26 17:07:39,018 - trainer - INFO -     macro_f        : 0.767169
2024-02-26 17:07:39,019 - trainer - INFO -     val_loss       : 0.919538
2024-02-26 17:07:39,019 - trainer - INFO -     val_accuracy   : 0.742982
2024-02-26 17:07:39,019 - trainer - INFO -     val_macro_f    : 0.566484
2024-02-26 17:13:54,215 - trainer - INFO -     epoch          : 4
2024-02-26 17:13:54,217 - trainer - INFO -     loss           : 0.245176
2024-02-26 17:13:54,217 - trainer - INFO -     accuracy       : 0.917353
2024-02-26 17:13:54,217 - trainer - INFO -     macro_f        : 0.841135
2024-02-26 17:13:54,217 - trainer - INFO -     val_loss       : 1.027782
2024-02-26 17:13:54,218 - trainer - INFO -     val_accuracy   : 0.747047
2024-02-26 17:13:54,218 - trainer - INFO -     val_macro_f    : 0.561417
2024-02-26 17:20:12,228 - trainer - INFO -     epoch          : 5
2024-02-26 17:20:12,230 - trainer - INFO -     loss           : 0.174536
2024-02-26 17:20:12,231 - trainer - INFO -     accuracy       : 0.942138
2024-02-26 17:20:12,231 - trainer - INFO -     macro_f        : 0.886419
2024-02-26 17:20:12,231 - trainer - INFO -     val_loss       : 1.143952
2024-02-26 17:20:12,231 - trainer - INFO -     val_accuracy   : 0.750959
2024-02-26 17:20:12,231 - trainer - INFO -     val_macro_f    : 0.557197
2024-02-26 17:36:28,424 - train - INFO - PretrainedBaseline(
  (model): LongformerForSequenceClassification(
    (longformer): LongformerModel(
      (embeddings): LongformerEmbeddings(
        (word_embeddings): Embedding(50265, 768, padding_idx=0)
        (token_type_embeddings): Embedding(1, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (position_embeddings): Embedding(4098, 768, padding_idx=0)
      )
      (encoder): LongformerEncoder(
        (layer): ModuleList(
          (0): LongformerLayer(
            (attention): LongformerAttention(
              (self): LongformerSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (query_global): Linear(in_features=768, out_features=768, bias=True)
                (key_global): Linear(in_features=768, out_features=768, bias=True)
                (value_global): Linear(in_features=768, out_features=768, bias=True)
              )
              (output): LongformerSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): LongformerIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): LongformerOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
    )
    (classifier): LongformerClassificationHead(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (dropout): Dropout(p=0.1, inplace=False)
      (out_proj): Linear(in_features=768, out_features=15, bias=True)
    )
  )
)
Trainable params: 51,214,863
Freeze params: 0
2024-02-26 19:18:34,394 - trainer - INFO -     epoch          : 1
2024-02-26 19:18:34,396 - trainer - INFO -     loss           : 0.825771
2024-02-26 19:18:34,397 - trainer - INFO -     accuracy       : 0.730544
2024-02-26 19:18:34,397 - trainer - INFO -     macro_f        : 0.509622
2024-02-26 19:18:34,397 - trainer - INFO -     val_loss       : 0.706572
2024-02-26 19:18:34,397 - trainer - INFO -     val_accuracy   : 0.758782
2024-02-26 19:18:34,397 - trainer - INFO -     val_macro_f    : 0.577778
2024-02-26 21:42:18,118 - trainer - INFO -     epoch          : 2
2024-02-26 21:42:18,982 - trainer - INFO -     loss           : 0.53627
2024-02-26 21:42:18,982 - trainer - INFO -     accuracy       : 0.820717
2024-02-26 21:42:18,982 - trainer - INFO -     macro_f        : 0.661996
2024-02-26 21:42:18,983 - trainer - INFO -     val_loss       : 0.71242
2024-02-26 21:42:18,983 - trainer - INFO -     val_accuracy   : 0.767219
2024-02-26 21:42:18,983 - trainer - INFO -     val_macro_f    : 0.581762
2024-03-03 12:20:44,626 - train - INFO - PretrainedBaseline(
  (model): BertForSequenceClassification(
    (bert): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(30522, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (classifier): Linear(in_features=768, out_features=15, bias=True)
  )
)
Trainable params: 31,527,183
Freeze params: 0
2024-03-03 12:26:31,889 - trainer - INFO -     epoch          : 1
2024-03-03 12:26:31,889 - trainer - INFO -     loss           : 0.939644
2024-03-03 12:26:31,889 - trainer - INFO -     accuracy       : 0.700611
2024-03-03 12:26:31,889 - trainer - INFO -     macro_f        : 0.462227
2024-03-03 12:26:31,889 - trainer - INFO -     val_loss       : 0.727442
2024-03-03 12:26:31,889 - trainer - INFO -     val_accuracy   : 0.757095
2024-03-03 12:26:31,889 - trainer - INFO -     val_macro_f    : 0.562245
2024-03-03 12:32:18,771 - trainer - INFO -     epoch          : 2
2024-03-03 12:32:18,771 - trainer - INFO -     loss           : 0.630136
2024-03-03 12:32:18,771 - trainer - INFO -     accuracy       : 0.787313
2024-03-03 12:32:18,771 - trainer - INFO -     macro_f        : 0.606987
2024-03-03 12:32:18,771 - trainer - INFO -     val_loss       : 0.760077
2024-03-03 12:32:18,771 - trainer - INFO -     val_accuracy   : 0.753336
2024-03-03 12:32:18,771 - trainer - INFO -     val_macro_f    : 0.562242
2024-03-03 12:38:08,243 - trainer - INFO -     epoch          : 3
2024-03-03 12:38:08,243 - trainer - INFO -     loss           : 0.477439
2024-03-03 12:38:08,243 - trainer - INFO -     accuracy       : 0.83391
2024-03-03 12:38:08,243 - trainer - INFO -     macro_f        : 0.689491
2024-03-03 12:38:08,243 - trainer - INFO -     val_loss       : 0.762255
2024-03-03 12:38:08,243 - trainer - INFO -     val_accuracy   : 0.761697
2024-03-03 12:38:08,243 - trainer - INFO -     val_macro_f    : 0.568257
2024-03-03 12:39:23,533 - train - INFO - PretrainedBaseline(
  (model): BertForSequenceClassification(
    (bert): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(30522, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (classifier): Linear(in_features=768, out_features=15, bias=True)
  )
)
Trainable params: 31,527,183
Freeze params: 0
2024-03-03 12:45:22,712 - trainer - INFO -     epoch          : 1
2024-03-03 12:45:22,712 - trainer - INFO -     loss           : 0.914063
2024-03-03 12:45:22,712 - trainer - INFO -     accuracy       : 0.706747
2024-03-03 12:45:22,728 - trainer - INFO -     macro_f        : 0.474866
2024-03-03 12:45:22,728 - trainer - INFO -     val_loss       : 0.728091
2024-03-03 12:45:22,728 - trainer - INFO -     val_accuracy   : 0.757632
2024-03-03 12:45:22,728 - trainer - INFO -     val_macro_f    : 0.557713
2024-03-03 12:51:09,393 - trainer - INFO -     epoch          : 2
2024-03-03 12:51:09,393 - trainer - INFO -     loss           : 0.619617
2024-03-03 12:51:09,393 - trainer - INFO -     accuracy       : 0.791522
2024-03-03 12:51:09,393 - trainer - INFO -     macro_f        : 0.614481
2024-03-03 12:51:09,393 - trainer - INFO -     val_loss       : 0.701228
2024-03-03 12:51:09,393 - trainer - INFO -     val_accuracy   : 0.768599
2024-03-03 12:51:09,393 - trainer - INFO -     val_macro_f    : 0.585086
2024-03-03 12:56:56,834 - trainer - INFO -     epoch          : 3
2024-03-03 12:56:56,834 - trainer - INFO -     loss           : 0.46619
2024-03-03 12:56:56,850 - trainer - INFO -     accuracy       : 0.839241
2024-03-03 12:56:56,850 - trainer - INFO -     macro_f        : 0.700068
2024-03-03 12:56:56,850 - trainer - INFO -     val_loss       : 0.798141
2024-03-03 12:56:56,850 - trainer - INFO -     val_accuracy   : 0.752953
2024-03-03 12:56:56,850 - trainer - INFO -     val_macro_f    : 0.558932
2024-03-03 12:58:04,062 - train - INFO - PretrainedBaseline(
  (model): BertForSequenceClassification(
    (bert): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(30522, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (classifier): Linear(in_features=768, out_features=15, bias=True)
  )
)
Trainable params: 31,527,183
Freeze params: 0
2024-03-03 13:03:54,982 - trainer - INFO -     epoch          : 1
2024-03-03 13:03:54,988 - trainer - INFO -     loss           : 1.160626
2024-03-03 13:03:54,988 - trainer - INFO -     accuracy       : 0.640533
2024-03-03 13:03:54,989 - trainer - INFO -     macro_f        : 0.366626
2024-03-03 13:03:54,989 - trainer - INFO -     val_loss       : 1.071082
2024-03-03 13:03:54,989 - trainer - INFO -     val_accuracy   : 0.65892
2024-03-03 13:03:54,989 - trainer - INFO -     val_macro_f    : 0.401936
2024-03-03 13:09:44,334 - trainer - INFO -     epoch          : 2
2024-03-03 13:09:44,334 - trainer - INFO -     loss           : 1.039766
2024-03-03 13:09:44,334 - trainer - INFO -     accuracy       : 0.672087
2024-03-03 13:09:44,334 - trainer - INFO -     macro_f        : 0.421614
2024-03-03 13:09:44,334 - trainer - INFO -     val_loss       : 1.058792
2024-03-03 13:09:44,334 - trainer - INFO -     val_accuracy   : 0.663215
2024-03-03 13:09:44,334 - trainer - INFO -     val_macro_f    : 0.416098
2024-03-03 13:15:28,710 - trainer - INFO -     epoch          : 3
2024-03-03 13:15:28,710 - trainer - INFO -     loss           : 0.953662
2024-03-03 13:15:28,710 - trainer - INFO -     accuracy       : 0.69481
2024-03-03 13:15:28,710 - trainer - INFO -     macro_f        : 0.452078
2024-03-03 13:15:28,710 - trainer - INFO -     val_loss       : 0.97339
2024-03-03 13:15:28,710 - trainer - INFO -     val_accuracy   : 0.692361
2024-03-03 13:15:28,710 - trainer - INFO -     val_macro_f    : 0.455791
2024-03-03 13:16:36,663 - train - INFO - PretrainedBaseline(
  (model): BertForSequenceClassification(
    (bert): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(30522, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (classifier): Linear(in_features=768, out_features=15, bias=True)
  )
)
Trainable params: 31,527,183
Freeze params: 0
2024-03-03 13:22:27,516 - trainer - INFO -     epoch          : 1
2024-03-03 13:22:27,516 - trainer - INFO -     loss           : 1.136771
2024-03-03 13:22:27,516 - trainer - INFO -     accuracy       : 0.646833
2024-03-03 13:22:27,531 - trainer - INFO -     macro_f        : 0.380447
2024-03-03 13:22:27,531 - trainer - INFO -     val_loss       : 1.041606
2024-03-03 13:22:27,531 - trainer - INFO -     val_accuracy   : 0.669888
2024-03-03 13:22:27,531 - trainer - INFO -     val_macro_f    : 0.428881
2024-03-03 13:28:14,458 - trainer - INFO -     epoch          : 2
2024-03-03 13:28:14,458 - trainer - INFO -     loss           : 1.005792
2024-03-03 13:28:14,458 - trainer - INFO -     accuracy       : 0.680428
2024-03-03 13:28:14,458 - trainer - INFO -     macro_f        : 0.434194
2024-03-03 13:28:14,458 - trainer - INFO -     val_loss       : 1.013055
2024-03-03 13:28:14,458 - trainer - INFO -     val_accuracy   : 0.676714
2024-03-03 13:28:14,458 - trainer - INFO -     val_macro_f    : 0.430192
2024-03-03 13:34:01,395 - trainer - INFO -     epoch          : 3
2024-03-03 13:34:01,395 - trainer - INFO -     loss           : 0.918204
2024-03-03 13:34:01,396 - trainer - INFO -     accuracy       : 0.70598
2024-03-03 13:34:01,396 - trainer - INFO -     macro_f        : 0.473442
2024-03-03 13:34:01,396 - trainer - INFO -     val_loss       : 0.93997
2024-03-03 13:34:01,396 - trainer - INFO -     val_accuracy   : 0.696963
2024-03-03 13:34:01,396 - trainer - INFO -     val_macro_f    : 0.462447
2024-03-03 13:35:07,456 - train - INFO - PretrainedBaseline(
  (model): BertForSequenceClassification(
    (bert): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(30522, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (classifier): Linear(in_features=768, out_features=15, bias=True)
  )
)
Trainable params: 31,527,183
Freeze params: 0
2024-03-03 13:40:59,857 - trainer - INFO -     epoch          : 1
2024-03-03 13:40:59,857 - trainer - INFO -     loss           : 0.86065
2024-03-03 13:40:59,857 - trainer - INFO -     accuracy       : 0.720879
2024-03-03 13:40:59,857 - trainer - INFO -     macro_f        : 0.495899
2024-03-03 13:40:59,857 - trainer - INFO -     val_loss       : 0.724758
2024-03-03 13:40:59,857 - trainer - INFO -     val_accuracy   : 0.762233
2024-03-03 13:40:59,857 - trainer - INFO -     val_macro_f    : 0.568956
2024-03-03 13:46:51,103 - trainer - INFO -     epoch          : 2
2024-03-03 13:46:51,119 - trainer - INFO -     loss           : 0.586052
2024-03-03 13:46:51,119 - trainer - INFO -     accuracy       : 0.800842
2024-03-03 13:46:51,119 - trainer - INFO -     macro_f        : 0.631532
2024-03-03 13:46:51,119 - trainer - INFO -     val_loss       : 0.703174
2024-03-03 13:46:51,119 - trainer - INFO -     val_accuracy   : 0.766759
2024-03-03 13:46:51,119 - trainer - INFO -     val_macro_f    : 0.57776
2024-03-03 13:52:38,392 - trainer - INFO -     epoch          : 3
2024-03-03 13:52:38,392 - trainer - INFO -     loss           : 0.438815
2024-03-03 13:52:38,392 - trainer - INFO -     accuracy       : 0.845444
2024-03-03 13:52:38,392 - trainer - INFO -     macro_f        : 0.713673
2024-03-03 13:52:38,392 - trainer - INFO -     val_loss       : 0.77722
2024-03-03 13:52:38,392 - trainer - INFO -     val_accuracy   : 0.759242
2024-03-03 13:52:38,392 - trainer - INFO -     val_macro_f    : 0.567484
2024-03-11 12:16:54,897 - train - INFO - PretrainedBaseline(
  (model): DistilBertForSequenceClassification(
    (distilbert): DistilBertModel(
      (embeddings): Embeddings(
        (word_embeddings): Embedding(30522, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (transformer): Transformer(
        (layer): ModuleList(
          (0): TransformerBlock(
            (attention): MultiHeadSelfAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (q_lin): Linear(in_features=768, out_features=768, bias=True)
              (k_lin): Linear(in_features=768, out_features=768, bias=True)
              (v_lin): Linear(in_features=768, out_features=768, bias=True)
              (out_lin): Linear(in_features=768, out_features=768, bias=True)
            )
            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (ffn): FFN(
              (dropout): Dropout(p=0.1, inplace=False)
              (lin1): Linear(in_features=768, out_features=3072, bias=True)
              (lin2): Linear(in_features=3072, out_features=768, bias=True)
              (activation): GELUActivation()
            )
            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          )
        )
      )
    )
    (pre_classifier): Linear(in_features=768, out_features=768, bias=True)
    (classifier): Linear(in_features=768, out_features=15, bias=True)
    (dropout): Dropout(p=0.2, inplace=False)
  )
)
Trainable params: 31,525,647
Freeze params: 0
2024-03-11 12:22:46,598 - trainer - INFO -     epoch          : 1
2024-03-11 12:22:46,598 - trainer - INFO -     loss           : 0.884844
2024-03-11 12:22:46,598 - trainer - INFO -     accuracy       : 0.716095
2024-03-11 12:22:46,598 - trainer - INFO -     macro_f        : 0.482622
2024-03-11 12:22:46,598 - trainer - INFO -     val_loss       : 0.741124
2024-03-11 12:22:46,598 - trainer - INFO -     val_accuracy   : 0.746357
2024-03-11 12:22:46,598 - trainer - INFO -     val_macro_f    : 0.558087
2024-03-11 12:28:37,040 - trainer - INFO -     epoch          : 2
2024-03-11 12:28:37,040 - trainer - INFO -     loss           : 0.604488
2024-03-11 12:28:37,042 - trainer - INFO -     accuracy       : 0.797889
2024-03-11 12:28:37,042 - trainer - INFO -     macro_f        : 0.621375
2024-03-11 12:28:37,042 - trainer - INFO -     val_loss       : 0.712843
2024-03-11 12:28:37,042 - trainer - INFO -     val_accuracy   : 0.76254
2024-03-11 12:28:37,042 - trainer - INFO -     val_macro_f    : 0.577795
2024-03-11 12:34:28,484 - trainer - INFO -     epoch          : 3
2024-03-11 12:34:28,484 - trainer - INFO -     loss           : 0.460052
2024-03-11 12:34:28,484 - trainer - INFO -     accuracy       : 0.842252
2024-03-11 12:34:28,484 - trainer - INFO -     macro_f        : 0.701964
2024-03-11 12:34:28,484 - trainer - INFO -     val_loss       : 0.836139
2024-03-11 12:34:28,484 - trainer - INFO -     val_accuracy   : 0.738457
2024-03-11 12:34:28,484 - trainer - INFO -     val_macro_f    : 0.549566
2024-03-11 12:35:41,816 - train - INFO - PretrainedBaseline(
  (model): DistilBertForSequenceClassification(
    (distilbert): DistilBertModel(
      (embeddings): Embeddings(
        (word_embeddings): Embedding(30522, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (transformer): Transformer(
        (layer): ModuleList(
          (0): TransformerBlock(
            (attention): MultiHeadSelfAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (q_lin): Linear(in_features=768, out_features=768, bias=True)
              (k_lin): Linear(in_features=768, out_features=768, bias=True)
              (v_lin): Linear(in_features=768, out_features=768, bias=True)
              (out_lin): Linear(in_features=768, out_features=768, bias=True)
            )
            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (ffn): FFN(
              (dropout): Dropout(p=0.1, inplace=False)
              (lin1): Linear(in_features=768, out_features=3072, bias=True)
              (lin2): Linear(in_features=3072, out_features=768, bias=True)
              (activation): GELUActivation()
            )
            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          )
        )
      )
    )
    (pre_classifier): Linear(in_features=768, out_features=768, bias=True)
    (classifier): Linear(in_features=768, out_features=15, bias=True)
    (dropout): Dropout(p=0.2, inplace=False)
  )
)
Trainable params: 31,525,647
Freeze params: 0
2024-03-11 12:41:40,949 - trainer - INFO -     epoch          : 1
2024-03-11 12:41:40,949 - trainer - INFO -     loss           : 0.894717
2024-03-11 12:41:40,949 - trainer - INFO -     accuracy       : 0.711205
2024-03-11 12:41:40,949 - trainer - INFO -     macro_f        : 0.472941
2024-03-11 12:41:40,949 - trainer - INFO -     val_loss       : 0.759
2024-03-11 12:41:40,949 - trainer - INFO -     val_accuracy   : 0.753873
2024-03-11 12:41:40,949 - trainer - INFO -     val_macro_f    : 0.557995
2024-03-11 12:47:31,070 - trainer - INFO -     epoch          : 2
2024-03-11 12:47:31,070 - trainer - INFO -     loss           : 0.617179
2024-03-11 12:47:31,070 - trainer - INFO -     accuracy       : 0.793833
2024-03-11 12:47:31,070 - trainer - INFO -     macro_f        : 0.611837
2024-03-11 12:47:31,070 - trainer - INFO -     val_loss       : 0.729677
2024-03-11 12:47:31,070 - trainer - INFO -     val_accuracy   : 0.758705
2024-03-11 12:47:31,070 - trainer - INFO -     val_macro_f    : 0.571814
2024-03-11 12:53:21,613 - trainer - INFO -     epoch          : 3
2024-03-11 12:53:21,616 - trainer - INFO -     loss           : 0.485829
2024-03-11 12:53:21,616 - trainer - INFO -     accuracy       : 0.832884
2024-03-11 12:53:21,617 - trainer - INFO -     macro_f        : 0.682359
2024-03-11 12:53:21,617 - trainer - INFO -     val_loss       : 0.841313
2024-03-11 12:53:21,617 - trainer - INFO -     val_accuracy   : 0.758552
2024-03-11 12:53:21,617 - trainer - INFO -     val_macro_f    : 0.561331
2024-03-11 12:54:31,616 - train - INFO - PretrainedBaseline(
  (model): DistilBertForSequenceClassification(
    (distilbert): DistilBertModel(
      (embeddings): Embeddings(
        (word_embeddings): Embedding(30522, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (transformer): Transformer(
        (layer): ModuleList(
          (0): TransformerBlock(
            (attention): MultiHeadSelfAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (q_lin): Linear(in_features=768, out_features=768, bias=True)
              (k_lin): Linear(in_features=768, out_features=768, bias=True)
              (v_lin): Linear(in_features=768, out_features=768, bias=True)
              (out_lin): Linear(in_features=768, out_features=768, bias=True)
            )
            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (ffn): FFN(
              (dropout): Dropout(p=0.1, inplace=False)
              (lin1): Linear(in_features=768, out_features=3072, bias=True)
              (lin2): Linear(in_features=3072, out_features=768, bias=True)
              (activation): GELUActivation()
            )
            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          )
        )
      )
    )
    (pre_classifier): Linear(in_features=768, out_features=768, bias=True)
    (classifier): Linear(in_features=768, out_features=15, bias=True)
    (dropout): Dropout(p=0.2, inplace=False)
  )
)
Trainable params: 31,525,647
Freeze params: 0
2024-03-11 13:00:23,831 - trainer - INFO -     epoch          : 1
2024-03-11 13:00:23,831 - trainer - INFO -     loss           : 0.895642
2024-03-11 13:00:23,831 - trainer - INFO -     accuracy       : 0.713506
2024-03-11 13:00:23,831 - trainer - INFO -     macro_f        : 0.477474
2024-03-11 13:00:23,831 - trainer - INFO -     val_loss       : 0.798216
2024-03-11 13:00:23,831 - trainer - INFO -     val_accuracy   : 0.732781
2024-03-11 13:00:23,831 - trainer - INFO -     val_macro_f    : 0.52146
2024-03-11 13:06:17,230 - trainer - INFO -     epoch          : 2
2024-03-11 13:06:17,235 - trainer - INFO -     loss           : 0.614663
2024-03-11 13:06:17,235 - trainer - INFO -     accuracy       : 0.795703
2024-03-11 13:06:17,235 - trainer - INFO -     macro_f        : 0.619139
2024-03-11 13:06:17,235 - trainer - INFO -     val_loss       : 0.727021
2024-03-11 13:06:17,235 - trainer - INFO -     val_accuracy   : 0.76208
2024-03-11 13:06:17,235 - trainer - INFO -     val_macro_f    : 0.562706
2024-03-11 13:12:10,228 - trainer - INFO -     epoch          : 3
2024-03-11 13:12:10,228 - trainer - INFO -     loss           : 0.470278
2024-03-11 13:12:10,229 - trainer - INFO -     accuracy       : 0.839672
2024-03-11 13:12:10,229 - trainer - INFO -     macro_f        : 0.698269
2024-03-11 13:12:10,229 - trainer - INFO -     val_loss       : 0.842433
2024-03-11 13:12:10,229 - trainer - INFO -     val_accuracy   : 0.756174
2024-03-11 13:12:10,229 - trainer - INFO -     val_macro_f    : 0.566864
2024-03-11 13:13:22,166 - train - INFO - PretrainedBaseline(
  (model): DistilBertForSequenceClassification(
    (distilbert): DistilBertModel(
      (embeddings): Embeddings(
        (word_embeddings): Embedding(30522, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (transformer): Transformer(
        (layer): ModuleList(
          (0): TransformerBlock(
            (attention): MultiHeadSelfAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (q_lin): Linear(in_features=768, out_features=768, bias=True)
              (k_lin): Linear(in_features=768, out_features=768, bias=True)
              (v_lin): Linear(in_features=768, out_features=768, bias=True)
              (out_lin): Linear(in_features=768, out_features=768, bias=True)
            )
            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (ffn): FFN(
              (dropout): Dropout(p=0.1, inplace=False)
              (lin1): Linear(in_features=768, out_features=3072, bias=True)
              (lin2): Linear(in_features=3072, out_features=768, bias=True)
              (activation): GELUActivation()
            )
            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          )
        )
      )
    )
    (pre_classifier): Linear(in_features=768, out_features=768, bias=True)
    (classifier): Linear(in_features=768, out_features=15, bias=True)
    (dropout): Dropout(p=0.2, inplace=False)
  )
)
Trainable params: 31,525,647
Freeze params: 0
2024-03-11 13:19:24,644 - trainer - INFO -     epoch          : 1
2024-03-11 13:19:24,644 - trainer - INFO -     loss           : 0.862761
2024-03-11 13:19:24,644 - trainer - INFO -     accuracy       : 0.720659
2024-03-11 13:19:24,644 - trainer - INFO -     macro_f        : 0.492525
2024-03-11 13:19:24,644 - trainer - INFO -     val_loss       : 0.726055
2024-03-11 13:19:24,644 - trainer - INFO -     val_accuracy   : 0.7551
2024-03-11 13:19:24,644 - trainer - INFO -     val_macro_f    : 0.567194
2024-03-11 13:25:14,884 - trainer - INFO -     epoch          : 2
2024-03-11 13:25:14,884 - trainer - INFO -     loss           : 0.592407
2024-03-11 13:25:14,884 - trainer - INFO -     accuracy       : 0.800094
2024-03-11 13:25:14,884 - trainer - INFO -     macro_f        : 0.627752
2024-03-11 13:25:14,884 - trainer - INFO -     val_loss       : 0.758402
2024-03-11 13:25:14,884 - trainer - INFO -     val_accuracy   : 0.761697
2024-03-11 13:25:14,884 - trainer - INFO -     val_macro_f    : 0.561159
2024-03-11 13:31:09,708 - trainer - INFO -     epoch          : 3
2024-03-11 13:31:09,709 - trainer - INFO -     loss           : 0.452971
2024-03-11 13:31:09,709 - trainer - INFO -     accuracy       : 0.844198
2024-03-11 13:31:09,709 - trainer - INFO -     macro_f        : 0.707998
2024-03-11 13:31:09,709 - trainer - INFO -     val_loss       : 0.838679
2024-03-11 13:31:09,710 - trainer - INFO -     val_accuracy   : 0.753873
2024-03-11 13:31:09,710 - trainer - INFO -     val_macro_f    : 0.553949
2024-03-11 13:32:23,752 - train - INFO - PretrainedBaseline(
  (model): DistilBertForSequenceClassification(
    (distilbert): DistilBertModel(
      (embeddings): Embeddings(
        (word_embeddings): Embedding(30522, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (transformer): Transformer(
        (layer): ModuleList(
          (0): TransformerBlock(
            (attention): MultiHeadSelfAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (q_lin): Linear(in_features=768, out_features=768, bias=True)
              (k_lin): Linear(in_features=768, out_features=768, bias=True)
              (v_lin): Linear(in_features=768, out_features=768, bias=True)
              (out_lin): Linear(in_features=768, out_features=768, bias=True)
            )
            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (ffn): FFN(
              (dropout): Dropout(p=0.1, inplace=False)
              (lin1): Linear(in_features=768, out_features=3072, bias=True)
              (lin2): Linear(in_features=3072, out_features=768, bias=True)
              (activation): GELUActivation()
            )
            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          )
        )
      )
    )
    (pre_classifier): Linear(in_features=768, out_features=768, bias=True)
    (classifier): Linear(in_features=768, out_features=15, bias=True)
    (dropout): Dropout(p=0.2, inplace=False)
  )
)
Trainable params: 31,525,647
Freeze params: 0
2024-03-11 13:38:33,041 - trainer - INFO -     epoch          : 1
2024-03-11 13:38:33,045 - trainer - INFO -     loss           : 0.910993
2024-03-11 13:38:33,046 - trainer - INFO -     accuracy       : 0.70878
2024-03-11 13:38:33,046 - trainer - INFO -     macro_f        : 0.46422
2024-03-11 13:38:33,046 - trainer - INFO -     val_loss       : 0.732439
2024-03-11 13:38:33,046 - trainer - INFO -     val_accuracy   : 0.757862
2024-03-11 13:38:33,046 - trainer - INFO -     val_macro_f    : 0.562241
2024-03-11 13:44:43,577 - trainer - INFO -     epoch          : 2
2024-03-11 13:44:43,582 - trainer - INFO -     loss           : 0.627928
2024-03-11 13:44:43,582 - trainer - INFO -     accuracy       : 0.791446
2024-03-11 13:44:43,582 - trainer - INFO -     macro_f        : 0.607601
2024-03-11 13:44:43,582 - trainer - INFO -     val_loss       : 0.723947
2024-03-11 13:44:43,582 - trainer - INFO -     val_accuracy   : 0.76116
2024-03-11 13:44:43,582 - trainer - INFO -     val_macro_f    : 0.570438
2024-03-11 13:50:40,489 - trainer - INFO -     epoch          : 3
2024-03-11 13:50:40,489 - trainer - INFO -     loss           : 0.489243
2024-03-11 13:50:40,489 - trainer - INFO -     accuracy       : 0.832146
2024-03-11 13:50:40,489 - trainer - INFO -     macro_f        : 0.681748
2024-03-11 13:50:40,489 - trainer - INFO -     val_loss       : 0.810338
2024-03-11 13:50:40,490 - trainer - INFO -     val_accuracy   : 0.757171
2024-03-11 13:50:40,490 - trainer - INFO -     val_macro_f    : 0.54753
2024-03-21 22:07:27,134 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: D:\AI\model\roberta-base
2024-03-21 22:07:27,134 - sentence_transformers.SentenceTransformer - WARNING - No sentence-transformers model found with name D:\AI\model\roberta-base. Creating a new one with MEAN pooling.
2024-03-21 22:07:28,947 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda
2024-03-21 22:07:29,307 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: D:\AI\model\roberta-base
2024-03-21 22:07:29,307 - sentence_transformers.SentenceTransformer - WARNING - No sentence-transformers model found with name D:\AI\model\roberta-base. Creating a new one with MEAN pooling.
2024-03-21 22:07:29,760 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda
2024-03-21 22:07:29,948 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: D:\AI\model\roberta-base
2024-03-21 22:07:29,948 - sentence_transformers.SentenceTransformer - WARNING - No sentence-transformers model found with name D:\AI\model\roberta-base. Creating a new one with MEAN pooling.
2024-03-21 22:07:30,385 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda
2024-03-21 22:07:31,808 - train - INFO - PretrainedBaseline(
  (model): BertForSequenceClassification(
    (bert): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(30522, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (classifier): Linear(in_features=768, out_features=15, bias=True)
  )
)
Trainable params: 31,527,183
Freeze params: 0
2024-03-30 12:29:15,362 - train - INFO - PretrainedBaseline(
  (model): DistilBertForSequenceClassification(
    (distilbert): DistilBertModel(
      (embeddings): Embeddings(
        (word_embeddings): Embedding(30522, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (transformer): Transformer(
        (layer): ModuleList(
          (0): TransformerBlock(
            (attention): MultiHeadSelfAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (q_lin): Linear(in_features=768, out_features=768, bias=True)
              (k_lin): Linear(in_features=768, out_features=768, bias=True)
              (v_lin): Linear(in_features=768, out_features=768, bias=True)
              (out_lin): Linear(in_features=768, out_features=768, bias=True)
            )
            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (ffn): FFN(
              (dropout): Dropout(p=0.1, inplace=False)
              (lin1): Linear(in_features=768, out_features=3072, bias=True)
              (lin2): Linear(in_features=3072, out_features=768, bias=True)
              (activation): GELUActivation()
            )
            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          )
        )
      )
    )
    (pre_classifier): Linear(in_features=768, out_features=768, bias=True)
    (classifier): Linear(in_features=768, out_features=15, bias=True)
    (dropout): Dropout(p=0.2, inplace=False)
  )
)
Trainable params: 31,525,647
Freeze params: 0
2024-03-30 12:39:26,944 - trainer - INFO -     epoch          : 1
2024-03-30 12:39:26,944 - trainer - INFO -     loss           : 0.901298
2024-03-30 12:39:26,944 - trainer - INFO -     accuracy       : 0.712164
2024-03-30 12:39:26,944 - trainer - INFO -     macro_f        : 0.691492
2024-03-30 12:39:26,944 - trainer - INFO -     precision      : 0.708725
2024-03-30 12:39:26,944 - trainer - INFO -     recall         : 0.712164
2024-03-30 12:39:26,944 - trainer - INFO -     val_loss       : 0.741465
2024-03-30 12:39:26,944 - trainer - INFO -     val_accuracy   : 0.749271
2024-03-30 12:39:26,944 - trainer - INFO -     val_macro_f    : 0.750473
2024-03-30 12:39:26,947 - trainer - INFO -     val_precision  : 0.785119
2024-03-30 12:39:26,947 - trainer - INFO -     val_recall     : 0.749271
2024-03-30 12:39:26,947 - trainer - INFO -     test_loss      : 0.736973
2024-03-30 12:39:26,947 - trainer - INFO -     test_accuracy  : 0.755561
2024-03-30 12:39:26,947 - trainer - INFO -     test_macro_f   : 0.756362
2024-03-30 12:39:26,947 - trainer - INFO -     test_precision : 0.790258
2024-03-30 12:39:26,947 - trainer - INFO -     test_recall    : 0.755561
2024-03-30 12:49:46,684 - trainer - INFO -     epoch          : 2
2024-03-30 12:49:46,684 - trainer - INFO -     loss           : 0.653244
2024-03-30 12:49:46,684 - trainer - INFO -     accuracy       : 0.782778
2024-03-30 12:49:46,684 - trainer - INFO -     macro_f        : 0.775001
2024-03-30 12:49:46,684 - trainer - INFO -     precision      : 0.799786
2024-03-30 12:49:46,684 - trainer - INFO -     recall         : 0.782778
2024-03-30 12:49:46,684 - trainer - INFO -     val_loss       : 0.717846
2024-03-30 12:49:46,684 - trainer - INFO -     val_accuracy   : 0.761466
2024-03-30 12:49:46,684 - trainer - INFO -     val_macro_f    : 0.753796
2024-03-30 12:49:46,684 - trainer - INFO -     val_precision  : 0.781076
2024-03-30 12:49:46,684 - trainer - INFO -     val_recall     : 0.761466
2024-03-30 12:49:46,684 - trainer - INFO -     test_loss      : 0.721366
2024-03-30 12:49:46,684 - trainer - INFO -     test_accuracy  : 0.764918
2024-03-30 12:49:46,684 - trainer - INFO -     test_macro_f   : 0.755742
2024-03-30 12:49:46,684 - trainer - INFO -     test_precision : 0.775585
2024-03-30 12:49:46,684 - trainer - INFO -     test_recall    : 0.764918
2024-03-30 13:00:10,062 - trainer - INFO -     epoch          : 3
2024-03-30 13:00:10,062 - trainer - INFO -     loss           : 0.554863
2024-03-30 13:00:10,062 - trainer - INFO -     accuracy       : 0.810947
2024-03-30 13:00:10,062 - trainer - INFO -     macro_f        : 0.805711
2024-03-30 13:00:10,062 - trainer - INFO -     precision      : 0.83006
2024-03-30 13:00:10,062 - trainer - INFO -     recall         : 0.810947
2024-03-30 13:00:10,062 - trainer - INFO -     val_loss       : 0.708072
2024-03-30 13:00:10,062 - trainer - INFO -     val_accuracy   : 0.767909
2024-03-30 13:00:10,062 - trainer - INFO -     val_macro_f    : 0.767885
2024-03-30 13:00:10,062 - trainer - INFO -     val_precision  : 0.800344
2024-03-30 13:00:10,062 - trainer - INFO -     val_recall     : 0.767909
2024-03-30 13:00:10,062 - trainer - INFO -     test_loss      : 0.706505
2024-03-30 13:00:10,062 - trainer - INFO -     test_accuracy  : 0.763614
2024-03-30 13:00:10,062 - trainer - INFO -     test_macro_f   : 0.765003
2024-03-30 13:00:10,062 - trainer - INFO -     test_precision : 0.797962
2024-03-30 13:00:10,062 - trainer - INFO -     test_recall    : 0.763614
2024-03-30 13:01:44,881 - train - INFO - PretrainedBaseline(
  (model): DistilBertForSequenceClassification(
    (distilbert): DistilBertModel(
      (embeddings): Embeddings(
        (word_embeddings): Embedding(30522, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (transformer): Transformer(
        (layer): ModuleList(
          (0): TransformerBlock(
            (attention): MultiHeadSelfAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (q_lin): Linear(in_features=768, out_features=768, bias=True)
              (k_lin): Linear(in_features=768, out_features=768, bias=True)
              (v_lin): Linear(in_features=768, out_features=768, bias=True)
              (out_lin): Linear(in_features=768, out_features=768, bias=True)
            )
            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (ffn): FFN(
              (dropout): Dropout(p=0.1, inplace=False)
              (lin1): Linear(in_features=768, out_features=3072, bias=True)
              (lin2): Linear(in_features=3072, out_features=768, bias=True)
              (activation): GELUActivation()
            )
            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          )
        )
      )
    )
    (pre_classifier): Linear(in_features=768, out_features=768, bias=True)
    (classifier): Linear(in_features=768, out_features=15, bias=True)
    (dropout): Dropout(p=0.2, inplace=False)
  )
)
Trainable params: 31,525,647
Freeze params: 0
2024-03-30 13:11:46,388 - trainer - INFO -     epoch          : 1
2024-03-30 13:11:46,388 - trainer - INFO -     loss           : 0.930575
2024-03-30 13:11:46,388 - trainer - INFO -     accuracy       : 0.702931
2024-03-30 13:11:46,388 - trainer - INFO -     macro_f        : 0.679131
2024-03-30 13:11:46,388 - trainer - INFO -     precision      : 0.692625
2024-03-30 13:11:46,388 - trainer - INFO -     recall         : 0.702931
2024-03-30 13:11:46,388 - trainer - INFO -     val_loss       : 0.783161
2024-03-30 13:11:46,388 - trainer - INFO -     val_accuracy   : 0.748198
2024-03-30 13:11:46,388 - trainer - INFO -     val_macro_f    : 0.742871
2024-03-30 13:11:46,388 - trainer - INFO -     val_precision  : 0.769115
2024-03-30 13:11:46,388 - trainer - INFO -     val_recall     : 0.748198
2024-03-30 13:11:46,388 - trainer - INFO -     test_loss      : 0.778442
2024-03-30 13:11:46,388 - trainer - INFO -     test_accuracy  : 0.748965
2024-03-30 13:11:46,388 - trainer - INFO -     test_macro_f   : 0.743763
2024-03-30 13:11:46,388 - trainer - INFO -     test_precision : 0.769576
2024-03-30 13:11:46,388 - trainer - INFO -     test_recall    : 0.748965
2024-03-30 13:21:53,040 - trainer - INFO -     epoch          : 2
2024-03-30 13:21:53,040 - trainer - INFO -     loss           : 0.685742
2024-03-30 13:21:53,040 - trainer - INFO -     accuracy       : 0.772634
2024-03-30 13:21:53,040 - trainer - INFO -     macro_f        : 0.763939
2024-03-30 13:21:53,040 - trainer - INFO -     precision      : 0.788609
2024-03-30 13:21:53,040 - trainer - INFO -     recall         : 0.772634
2024-03-30 13:21:53,040 - trainer - INFO -     val_loss       : 0.736951
2024-03-30 13:21:53,040 - trainer - INFO -     val_accuracy   : 0.763154
2024-03-30 13:21:53,040 - trainer - INFO -     val_macro_f    : 0.754447
2024-03-30 13:21:53,040 - trainer - INFO -     val_precision  : 0.778512
2024-03-30 13:21:53,040 - trainer - INFO -     val_recall     : 0.763154
2024-03-30 13:21:53,040 - trainer - INFO -     test_loss      : 0.734822
2024-03-30 13:21:53,055 - trainer - INFO -     test_accuracy  : 0.762694
2024-03-30 13:21:53,055 - trainer - INFO -     test_macro_f   : 0.755053
2024-03-30 13:21:53,055 - trainer - INFO -     test_precision : 0.778816
2024-03-30 13:21:53,055 - trainer - INFO -     test_recall    : 0.762694
2024-03-30 13:32:00,472 - trainer - INFO -     epoch          : 3
2024-03-30 13:32:00,472 - trainer - INFO -     loss           : 0.588781
2024-03-30 13:32:00,472 - trainer - INFO -     accuracy       : 0.803105
2024-03-30 13:32:00,472 - trainer - INFO -     macro_f        : 0.79654
2024-03-30 13:32:00,472 - trainer - INFO -     precision      : 0.820951
2024-03-30 13:32:00,472 - trainer - INFO -     recall         : 0.803105
2024-03-30 13:32:00,472 - trainer - INFO -     val_loss       : 0.763328
2024-03-30 13:32:00,472 - trainer - INFO -     val_accuracy   : 0.759702
2024-03-30 13:32:00,472 - trainer - INFO -     val_macro_f    : 0.751905
2024-03-30 13:32:00,472 - trainer - INFO -     val_precision  : 0.776607
2024-03-30 13:32:00,472 - trainer - INFO -     val_recall     : 0.759702
2024-03-30 13:32:00,472 - trainer - INFO -     test_loss      : 0.758852
2024-03-30 13:32:00,472 - trainer - INFO -     test_accuracy  : 0.763231
2024-03-30 13:32:00,472 - trainer - INFO -     test_macro_f   : 0.755972
2024-03-30 13:32:00,472 - trainer - INFO -     test_precision : 0.779955
2024-03-30 13:32:00,472 - trainer - INFO -     test_recall    : 0.763231
2024-03-30 13:33:36,542 - train - INFO - PretrainedBaseline(
  (model): DistilBertForSequenceClassification(
    (distilbert): DistilBertModel(
      (embeddings): Embeddings(
        (word_embeddings): Embedding(30522, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (transformer): Transformer(
        (layer): ModuleList(
          (0): TransformerBlock(
            (attention): MultiHeadSelfAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (q_lin): Linear(in_features=768, out_features=768, bias=True)
              (k_lin): Linear(in_features=768, out_features=768, bias=True)
              (v_lin): Linear(in_features=768, out_features=768, bias=True)
              (out_lin): Linear(in_features=768, out_features=768, bias=True)
            )
            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (ffn): FFN(
              (dropout): Dropout(p=0.1, inplace=False)
              (lin1): Linear(in_features=768, out_features=3072, bias=True)
              (lin2): Linear(in_features=3072, out_features=768, bias=True)
              (activation): GELUActivation()
            )
            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          )
        )
      )
    )
    (pre_classifier): Linear(in_features=768, out_features=768, bias=True)
    (classifier): Linear(in_features=768, out_features=15, bias=True)
    (dropout): Dropout(p=0.2, inplace=False)
  )
)
Trainable params: 31,525,647
Freeze params: 0
2024-03-30 13:43:47,917 - trainer - INFO -     epoch          : 1
2024-03-30 13:43:47,917 - trainer - INFO -     loss           : 0.901888
2024-03-30 13:43:47,917 - trainer - INFO -     accuracy       : 0.710793
2024-03-30 13:43:47,917 - trainer - INFO -     macro_f        : 0.691462
2024-03-30 13:43:47,917 - trainer - INFO -     precision      : 0.710406
2024-03-30 13:43:47,917 - trainer - INFO -     recall         : 0.710793
2024-03-30 13:43:47,917 - trainer - INFO -     val_loss       : 0.782648
2024-03-30 13:43:47,917 - trainer - INFO -     val_accuracy   : 0.739684
2024-03-30 13:43:47,917 - trainer - INFO -     val_macro_f    : 0.744658
2024-03-30 13:43:47,917 - trainer - INFO -     val_precision  : 0.784507
2024-03-30 13:43:47,917 - trainer - INFO -     val_recall     : 0.739684
2024-03-30 13:43:47,917 - trainer - INFO -     test_loss      : 0.767966
2024-03-30 13:43:47,917 - trainer - INFO -     test_accuracy  : 0.74513
2024-03-30 13:43:47,917 - trainer - INFO -     test_macro_f   : 0.74939
2024-03-30 13:43:47,917 - trainer - INFO -     test_precision : 0.789292
2024-03-30 13:43:47,917 - trainer - INFO -     test_recall    : 0.74513
2024-03-30 13:54:00,497 - trainer - INFO -     epoch          : 2
2024-03-30 13:54:00,497 - trainer - INFO -     loss           : 0.655785
2024-03-30 13:54:00,497 - trainer - INFO -     accuracy       : 0.781388
2024-03-30 13:54:00,497 - trainer - INFO -     macro_f        : 0.773302
2024-03-30 13:54:00,497 - trainer - INFO -     precision      : 0.797514
2024-03-30 13:54:00,497 - trainer - INFO -     recall         : 0.781388
2024-03-30 13:54:00,497 - trainer - INFO -     val_loss       : 0.733336
2024-03-30 13:54:00,497 - trainer - INFO -     val_accuracy   : 0.760853
2024-03-30 13:54:00,497 - trainer - INFO -     val_macro_f    : 0.744931
2024-03-30 13:54:00,497 - trainer - INFO -     val_precision  : 0.766524
2024-03-30 13:54:00,497 - trainer - INFO -     val_recall     : 0.760853
2024-03-30 13:54:00,497 - trainer - INFO -     test_loss      : 0.731027
2024-03-30 13:54:00,497 - trainer - INFO -     test_accuracy  : 0.76116
2024-03-30 13:54:00,497 - trainer - INFO -     test_macro_f   : 0.746089
2024-03-30 13:54:00,497 - trainer - INFO -     test_precision : 0.766665
2024-03-30 13:54:00,497 - trainer - INFO -     test_recall    : 0.76116
2024-03-30 14:04:16,076 - trainer - INFO -     epoch          : 3
2024-03-30 14:04:16,076 - trainer - INFO -     loss           : 0.559586
2024-03-30 14:04:16,076 - trainer - INFO -     accuracy       : 0.809941
2024-03-30 14:04:16,076 - trainer - INFO -     macro_f        : 0.804318
2024-03-30 14:04:16,076 - trainer - INFO -     precision      : 0.827951
2024-03-30 14:04:16,076 - trainer - INFO -     recall         : 0.809941
2024-03-30 14:04:16,076 - trainer - INFO -     val_loss       : 0.743529
2024-03-30 14:04:16,076 - trainer - INFO -     val_accuracy   : 0.769213
2024-03-30 14:04:16,076 - trainer - INFO -     val_macro_f    : 0.759579
2024-03-30 14:04:16,076 - trainer - INFO -     val_precision  : 0.783285
2024-03-30 14:04:16,076 - trainer - INFO -     val_recall     : 0.769213
2024-03-30 14:04:16,076 - trainer - INFO -     test_loss      : 0.742843
2024-03-30 14:04:16,076 - trainer - INFO -     test_accuracy  : 0.768599
2024-03-30 14:04:16,076 - trainer - INFO -     test_macro_f   : 0.760482
2024-03-30 14:04:16,076 - trainer - INFO -     test_precision : 0.785663
2024-03-30 14:04:16,076 - trainer - INFO -     test_recall    : 0.768599
2024-03-30 14:05:55,228 - train - INFO - PretrainedBaseline(
  (model): DistilBertForSequenceClassification(
    (distilbert): DistilBertModel(
      (embeddings): Embeddings(
        (word_embeddings): Embedding(30522, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (transformer): Transformer(
        (layer): ModuleList(
          (0): TransformerBlock(
            (attention): MultiHeadSelfAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (q_lin): Linear(in_features=768, out_features=768, bias=True)
              (k_lin): Linear(in_features=768, out_features=768, bias=True)
              (v_lin): Linear(in_features=768, out_features=768, bias=True)
              (out_lin): Linear(in_features=768, out_features=768, bias=True)
            )
            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (ffn): FFN(
              (dropout): Dropout(p=0.1, inplace=False)
              (lin1): Linear(in_features=768, out_features=3072, bias=True)
              (lin2): Linear(in_features=3072, out_features=768, bias=True)
              (activation): GELUActivation()
            )
            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          )
        )
      )
    )
    (pre_classifier): Linear(in_features=768, out_features=768, bias=True)
    (classifier): Linear(in_features=768, out_features=15, bias=True)
    (dropout): Dropout(p=0.2, inplace=False)
  )
)
Trainable params: 31,525,647
Freeze params: 0
2024-03-30 14:16:06,846 - trainer - INFO -     epoch          : 1
2024-03-30 14:16:06,846 - trainer - INFO -     loss           : 0.87659
2024-03-30 14:16:06,846 - trainer - INFO -     accuracy       : 0.717073
2024-03-30 14:16:06,846 - trainer - INFO -     macro_f        : 0.698086
2024-03-30 14:16:06,846 - trainer - INFO -     precision      : 0.716727
2024-03-30 14:16:06,846 - trainer - INFO -     recall         : 0.717073
2024-03-30 14:16:06,846 - trainer - INFO -     val_loss       : 0.723553
2024-03-30 14:16:06,846 - trainer - INFO -     val_accuracy   : 0.757862
2024-03-30 14:16:06,846 - trainer - INFO -     val_macro_f    : 0.757209
2024-03-30 14:16:06,846 - trainer - INFO -     val_precision  : 0.791645
2024-03-30 14:16:06,846 - trainer - INFO -     val_recall     : 0.757862
2024-03-30 14:16:06,846 - trainer - INFO -     test_loss      : 0.720552
2024-03-30 14:16:06,846 - trainer - INFO -     test_accuracy  : 0.760163
2024-03-30 14:16:06,846 - trainer - INFO -     test_macro_f   : 0.760473
2024-03-30 14:16:06,846 - trainer - INFO -     test_precision : 0.793335
2024-03-30 14:16:06,846 - trainer - INFO -     test_recall    : 0.760163
2024-03-30 14:26:20,369 - trainer - INFO -     epoch          : 2
2024-03-30 14:26:20,369 - trainer - INFO -     loss           : 0.640358
2024-03-30 14:26:20,369 - trainer - INFO -     accuracy       : 0.785051
2024-03-30 14:26:20,369 - trainer - INFO -     macro_f        : 0.777567
2024-03-30 14:26:20,369 - trainer - INFO -     precision      : 0.80318
2024-03-30 14:26:20,369 - trainer - INFO -     recall         : 0.785051
2024-03-30 14:26:20,369 - trainer - INFO -     val_loss       : 0.719476
2024-03-30 14:26:20,369 - trainer - INFO -     val_accuracy   : 0.76231
2024-03-30 14:26:20,369 - trainer - INFO -     val_macro_f    : 0.744447
2024-03-30 14:26:20,369 - trainer - INFO -     val_precision  : 0.759996
2024-03-30 14:26:20,369 - trainer - INFO -     val_recall     : 0.76231
2024-03-30 14:26:20,369 - trainer - INFO -     test_loss      : 0.725023
2024-03-30 14:26:20,369 - trainer - INFO -     test_accuracy  : 0.763614
2024-03-30 14:26:20,369 - trainer - INFO -     test_macro_f   : 0.747001
2024-03-30 14:26:20,369 - trainer - INFO -     test_precision : 0.761989
2024-03-30 14:26:20,369 - trainer - INFO -     test_recall    : 0.763614
2024-03-30 14:36:32,731 - trainer - INFO -     epoch          : 3
2024-03-30 14:36:32,731 - trainer - INFO -     loss           : 0.543907
2024-03-30 14:36:32,731 - trainer - INFO -     accuracy       : 0.815156
2024-03-30 14:36:32,731 - trainer - INFO -     macro_f        : 0.809986
2024-03-30 14:36:32,731 - trainer - INFO -     precision      : 0.833876
2024-03-30 14:36:32,731 - trainer - INFO -     recall         : 0.815156
2024-03-30 14:36:32,731 - trainer - INFO -     val_loss       : 0.758218
2024-03-30 14:36:32,731 - trainer - INFO -     val_accuracy   : 0.760163
2024-03-30 14:36:32,731 - trainer - INFO -     val_macro_f    : 0.749262
2024-03-30 14:36:32,731 - trainer - INFO -     val_precision  : 0.77374
2024-03-30 14:36:32,731 - trainer - INFO -     val_recall     : 0.760163
2024-03-30 14:36:32,731 - trainer - INFO -     test_loss      : 0.746618
2024-03-30 14:36:32,731 - trainer - INFO -     test_accuracy  : 0.761083
2024-03-30 14:36:32,731 - trainer - INFO -     test_macro_f   : 0.750529
2024-03-30 14:36:32,731 - trainer - INFO -     test_precision : 0.772754
2024-03-30 14:36:32,731 - trainer - INFO -     test_recall    : 0.761083
2024-03-30 14:38:13,442 - train - INFO - PretrainedBaseline(
  (model): DistilBertForSequenceClassification(
    (distilbert): DistilBertModel(
      (embeddings): Embeddings(
        (word_embeddings): Embedding(30522, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (transformer): Transformer(
        (layer): ModuleList(
          (0): TransformerBlock(
            (attention): MultiHeadSelfAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (q_lin): Linear(in_features=768, out_features=768, bias=True)
              (k_lin): Linear(in_features=768, out_features=768, bias=True)
              (v_lin): Linear(in_features=768, out_features=768, bias=True)
              (out_lin): Linear(in_features=768, out_features=768, bias=True)
            )
            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (ffn): FFN(
              (dropout): Dropout(p=0.1, inplace=False)
              (lin1): Linear(in_features=768, out_features=3072, bias=True)
              (lin2): Linear(in_features=3072, out_features=768, bias=True)
              (activation): GELUActivation()
            )
            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          )
        )
      )
    )
    (pre_classifier): Linear(in_features=768, out_features=768, bias=True)
    (classifier): Linear(in_features=768, out_features=15, bias=True)
    (dropout): Dropout(p=0.2, inplace=False)
  )
)
Trainable params: 31,525,647
Freeze params: 0
2024-03-30 14:46:27,427 - train - INFO - PretrainedBaseline(
  (model): DistilBertForSequenceClassification(
    (distilbert): DistilBertModel(
      (embeddings): Embeddings(
        (word_embeddings): Embedding(30522, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (transformer): Transformer(
        (layer): ModuleList(
          (0): TransformerBlock(
            (attention): MultiHeadSelfAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (q_lin): Linear(in_features=768, out_features=768, bias=True)
              (k_lin): Linear(in_features=768, out_features=768, bias=True)
              (v_lin): Linear(in_features=768, out_features=768, bias=True)
              (out_lin): Linear(in_features=768, out_features=768, bias=True)
            )
            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (ffn): FFN(
              (dropout): Dropout(p=0.1, inplace=False)
              (lin1): Linear(in_features=768, out_features=3072, bias=True)
              (lin2): Linear(in_features=3072, out_features=768, bias=True)
              (activation): GELUActivation()
            )
            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          )
        )
      )
    )
    (pre_classifier): Linear(in_features=768, out_features=768, bias=True)
    (classifier): Linear(in_features=768, out_features=15, bias=True)
    (dropout): Dropout(p=0.2, inplace=False)
  )
)
Trainable params: 31,525,647
Freeze params: 0
2024-03-30 14:56:46,537 - trainer - INFO -     epoch          : 1
2024-03-30 14:56:46,537 - trainer - INFO -     loss           : 0.786625
2024-03-30 14:56:46,537 - trainer - INFO -     accuracy       : 0.739489
2024-03-30 14:56:46,537 - trainer - INFO -     macro_f        : 0.724906
2024-03-30 14:56:46,537 - trainer - INFO -     precision      : 0.745572
2024-03-30 14:56:46,537 - trainer - INFO -     recall         : 0.739489
2024-03-30 14:56:46,537 - trainer - INFO -     val_loss       : 0.641561
2024-03-30 14:56:46,537 - trainer - INFO -     val_accuracy   : 0.780641
2024-03-30 14:56:46,537 - trainer - INFO -     val_macro_f    : 0.775325
2024-03-30 14:56:46,537 - trainer - INFO -     val_precision  : 0.800589
2024-03-30 14:56:46,537 - trainer - INFO -     val_recall     : 0.780641
2024-03-30 14:56:46,537 - trainer - INFO -     test_loss      : 0.639125
2024-03-30 14:56:46,537 - trainer - INFO -     test_accuracy  : 0.780565
2024-03-30 14:56:46,537 - trainer - INFO -     test_macro_f   : 0.774153
2024-03-30 14:56:46,537 - trainer - INFO -     test_precision : 0.798182
2024-03-30 14:56:46,537 - trainer - INFO -     test_recall    : 0.780565
2024-03-30 15:07:10,188 - trainer - INFO -     epoch          : 2
2024-03-30 15:07:10,188 - trainer - INFO -     loss           : 0.530171
2024-03-30 15:07:10,188 - trainer - INFO -     accuracy       : 0.816556
2024-03-30 15:07:10,188 - trainer - INFO -     macro_f        : 0.812319
2024-03-30 15:07:10,188 - trainer - INFO -     precision      : 0.835844
2024-03-30 15:07:10,188 - trainer - INFO -     recall         : 0.816556
2024-03-30 15:07:10,188 - trainer - INFO -     val_loss       : 0.634187
2024-03-30 15:07:10,188 - trainer - INFO -     val_accuracy   : 0.782712
2024-03-30 15:07:10,188 - trainer - INFO -     val_macro_f    : 0.778719
2024-03-30 15:07:10,188 - trainer - INFO -     val_precision  : 0.806037
2024-03-30 15:07:10,188 - trainer - INFO -     val_recall     : 0.782712
2024-03-30 15:07:10,188 - trainer - INFO -     test_loss      : 0.62695
2024-03-30 15:07:10,188 - trainer - INFO -     test_accuracy  : 0.786394
2024-03-30 15:07:10,188 - trainer - INFO -     test_macro_f   : 0.780787
2024-03-30 15:07:10,188 - trainer - INFO -     test_precision : 0.803453
2024-03-30 15:07:10,188 - trainer - INFO -     test_recall    : 0.786394
2024-03-30 15:17:32,270 - trainer - INFO -     epoch          : 3
2024-03-30 15:17:32,270 - trainer - INFO -     loss           : 0.381884
2024-03-30 15:17:32,270 - trainer - INFO -     accuracy       : 0.868541
2024-03-30 15:17:32,270 - trainer - INFO -     macro_f        : 0.866196
2024-03-30 15:17:32,270 - trainer - INFO -     precision      : 0.88563
2024-03-30 15:17:32,270 - trainer - INFO -     recall         : 0.868541
2024-03-30 15:17:32,270 - trainer - INFO -     val_loss       : 0.696984
2024-03-30 15:17:32,270 - trainer - INFO -     val_accuracy   : 0.774812
2024-03-30 15:17:32,270 - trainer - INFO -     val_macro_f    : 0.777453
2024-03-30 15:17:32,270 - trainer - INFO -     val_precision  : 0.811158
2024-03-30 15:17:32,270 - trainer - INFO -     val_recall     : 0.774812
2024-03-30 15:17:32,270 - trainer - INFO -     test_loss      : 0.689213
2024-03-30 15:17:32,270 - trainer - INFO -     test_accuracy  : 0.77834
2024-03-30 15:17:32,270 - trainer - INFO -     test_macro_f   : 0.781635
2024-03-30 15:17:32,270 - trainer - INFO -     test_precision : 0.815555
2024-03-30 15:17:32,270 - trainer - INFO -     test_recall    : 0.77834
2024-03-30 15:19:07,380 - train - INFO - PretrainedBaseline(
  (model): DistilBertForSequenceClassification(
    (distilbert): DistilBertModel(
      (embeddings): Embeddings(
        (word_embeddings): Embedding(30522, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (transformer): Transformer(
        (layer): ModuleList(
          (0): TransformerBlock(
            (attention): MultiHeadSelfAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (q_lin): Linear(in_features=768, out_features=768, bias=True)
              (k_lin): Linear(in_features=768, out_features=768, bias=True)
              (v_lin): Linear(in_features=768, out_features=768, bias=True)
              (out_lin): Linear(in_features=768, out_features=768, bias=True)
            )
            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (ffn): FFN(
              (dropout): Dropout(p=0.1, inplace=False)
              (lin1): Linear(in_features=768, out_features=3072, bias=True)
              (lin2): Linear(in_features=3072, out_features=768, bias=True)
              (activation): GELUActivation()
            )
            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          )
        )
      )
    )
    (pre_classifier): Linear(in_features=768, out_features=768, bias=True)
    (classifier): Linear(in_features=768, out_features=15, bias=True)
    (dropout): Dropout(p=0.2, inplace=False)
  )
)
Trainable params: 31,525,647
Freeze params: 0
2024-03-30 15:29:11,694 - trainer - INFO -     epoch          : 1
2024-03-30 15:29:11,694 - trainer - INFO -     loss           : 0.780652
2024-03-30 15:29:11,694 - trainer - INFO -     accuracy       : 0.740985
2024-03-30 15:29:11,694 - trainer - INFO -     macro_f        : 0.726837
2024-03-30 15:29:11,694 - trainer - INFO -     precision      : 0.747817
2024-03-30 15:29:11,694 - trainer - INFO -     recall         : 0.740985
2024-03-30 15:29:11,694 - trainer - INFO -     val_loss       : 0.641644
2024-03-30 15:29:11,694 - trainer - INFO -     val_accuracy   : 0.77788
2024-03-30 15:29:11,694 - trainer - INFO -     val_macro_f    : 0.7782
2024-03-30 15:29:11,694 - trainer - INFO -     val_precision  : 0.81196
2024-03-30 15:29:11,694 - trainer - INFO -     val_recall     : 0.77788
2024-03-30 15:29:11,694 - trainer - INFO -     test_loss      : 0.633456
2024-03-30 15:29:11,694 - trainer - INFO -     test_accuracy  : 0.779184
2024-03-30 15:29:11,694 - trainer - INFO -     test_macro_f   : 0.779241
2024-03-30 15:29:11,694 - trainer - INFO -     test_precision : 0.809472
2024-03-30 15:29:11,694 - trainer - INFO -     test_recall    : 0.779184
2024-03-30 15:39:15,946 - trainer - INFO -     epoch          : 2
2024-03-30 15:39:15,946 - trainer - INFO -     loss           : 0.525977
2024-03-30 15:39:15,946 - trainer - INFO -     accuracy       : 0.819941
2024-03-30 15:39:15,946 - trainer - INFO -     macro_f        : 0.815631
2024-03-30 15:39:15,946 - trainer - INFO -     precision      : 0.838815
2024-03-30 15:39:15,946 - trainer - INFO -     recall         : 0.819941
2024-03-30 15:39:15,946 - trainer - INFO -     val_loss       : 0.632713
2024-03-30 15:39:15,946 - trainer - INFO -     val_accuracy   : 0.783632
2024-03-30 15:39:15,946 - trainer - INFO -     val_macro_f    : 0.784004
2024-03-30 15:39:15,946 - trainer - INFO -     val_precision  : 0.815982
2024-03-30 15:39:15,946 - trainer - INFO -     val_recall     : 0.783632
2024-03-30 15:39:15,946 - trainer - INFO -     test_loss      : 0.626024
2024-03-30 15:39:15,946 - trainer - INFO -     test_accuracy  : 0.78555
2024-03-30 15:39:15,946 - trainer - INFO -     test_macro_f   : 0.786453
2024-03-30 15:39:15,946 - trainer - INFO -     test_precision : 0.816265
2024-03-30 15:39:15,946 - trainer - INFO -     test_recall    : 0.78555
2024-03-30 15:49:21,331 - trainer - INFO -     epoch          : 3
2024-03-30 15:49:21,331 - trainer - INFO -     loss           : 0.376887
2024-03-30 15:49:21,331 - trainer - INFO -     accuracy       : 0.868541
2024-03-30 15:49:21,331 - trainer - INFO -     macro_f        : 0.86662
2024-03-30 15:49:21,331 - trainer - INFO -     precision      : 0.886593
2024-03-30 15:49:21,331 - trainer - INFO -     recall         : 0.868541
2024-03-30 15:49:21,331 - trainer - INFO -     val_loss       : 0.701454
2024-03-30 15:49:21,331 - trainer - INFO -     val_accuracy   : 0.779107
2024-03-30 15:49:21,331 - trainer - INFO -     val_macro_f    : 0.779784
2024-03-30 15:49:21,331 - trainer - INFO -     val_precision  : 0.81018
2024-03-30 15:49:21,331 - trainer - INFO -     val_recall     : 0.779107
2024-03-30 15:49:21,331 - trainer - INFO -     test_loss      : 0.686656
2024-03-30 15:49:21,331 - trainer - INFO -     test_accuracy  : 0.783709
2024-03-30 15:49:21,331 - trainer - INFO -     test_macro_f   : 0.78368
2024-03-30 15:49:21,331 - trainer - INFO -     test_precision : 0.813846
2024-03-30 15:49:21,331 - trainer - INFO -     test_recall    : 0.783709
2024-03-30 15:50:57,062 - train - INFO - PretrainedBaseline(
  (model): DistilBertForSequenceClassification(
    (distilbert): DistilBertModel(
      (embeddings): Embeddings(
        (word_embeddings): Embedding(30522, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (transformer): Transformer(
        (layer): ModuleList(
          (0): TransformerBlock(
            (attention): MultiHeadSelfAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (q_lin): Linear(in_features=768, out_features=768, bias=True)
              (k_lin): Linear(in_features=768, out_features=768, bias=True)
              (v_lin): Linear(in_features=768, out_features=768, bias=True)
              (out_lin): Linear(in_features=768, out_features=768, bias=True)
            )
            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (ffn): FFN(
              (dropout): Dropout(p=0.1, inplace=False)
              (lin1): Linear(in_features=768, out_features=3072, bias=True)
              (lin2): Linear(in_features=3072, out_features=768, bias=True)
              (activation): GELUActivation()
            )
            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          )
        )
      )
    )
    (pre_classifier): Linear(in_features=768, out_features=768, bias=True)
    (classifier): Linear(in_features=768, out_features=15, bias=True)
    (dropout): Dropout(p=0.2, inplace=False)
  )
)
Trainable params: 31,525,647
Freeze params: 0
2024-03-30 16:01:09,194 - trainer - INFO -     epoch          : 1
2024-03-30 16:01:09,194 - trainer - INFO -     loss           : 0.780846
2024-03-30 16:01:09,194 - trainer - INFO -     accuracy       : 0.740151
2024-03-30 16:01:09,194 - trainer - INFO -     macro_f        : 0.725859
2024-03-30 16:01:09,194 - trainer - INFO -     precision      : 0.746211
2024-03-30 16:01:09,194 - trainer - INFO -     recall         : 0.740151
2024-03-30 16:01:09,194 - trainer - INFO -     val_loss       : 0.638473
2024-03-30 16:01:09,194 - trainer - INFO -     val_accuracy   : 0.777727
2024-03-30 16:01:09,194 - trainer - INFO -     val_macro_f    : 0.775072
2024-03-30 16:01:09,194 - trainer - INFO -     val_precision  : 0.804353
2024-03-30 16:01:09,194 - trainer - INFO -     val_recall     : 0.777727
2024-03-30 16:01:09,194 - trainer - INFO -     test_loss      : 0.628978
2024-03-30 16:01:09,194 - trainer - INFO -     test_accuracy  : 0.783326
2024-03-30 16:01:09,194 - trainer - INFO -     test_macro_f   : 0.77949
2024-03-30 16:01:09,194 - trainer - INFO -     test_precision : 0.807892
2024-03-30 16:01:09,194 - trainer - INFO -     test_recall    : 0.783326
2024-03-30 16:11:23,949 - trainer - INFO -     epoch          : 2
2024-03-30 16:11:23,949 - trainer - INFO -     loss           : 0.527382
2024-03-30 16:11:23,949 - trainer - INFO -     accuracy       : 0.819049
2024-03-30 16:11:23,949 - trainer - INFO -     macro_f        : 0.815059
2024-03-30 16:11:23,949 - trainer - INFO -     precision      : 0.838476
2024-03-30 16:11:23,949 - trainer - INFO -     recall         : 0.819049
2024-03-30 16:11:23,949 - trainer - INFO -     val_loss       : 0.628062
2024-03-30 16:11:23,949 - trainer - INFO -     val_accuracy   : 0.78624
2024-03-30 16:11:23,949 - trainer - INFO -     val_macro_f    : 0.780442
2024-03-30 16:11:23,949 - trainer - INFO -     val_precision  : 0.80535
2024-03-30 16:11:23,949 - trainer - INFO -     val_recall     : 0.78624
2024-03-30 16:11:23,949 - trainer - INFO -     test_loss      : 0.62587
2024-03-30 16:11:23,949 - trainer - INFO -     test_accuracy  : 0.790229
2024-03-30 16:11:23,949 - trainer - INFO -     test_macro_f   : 0.785597
2024-03-30 16:11:23,949 - trainer - INFO -     test_precision : 0.811281
2024-03-30 16:11:23,949 - trainer - INFO -     test_recall    : 0.790229
2024-03-30 16:21:38,759 - trainer - INFO -     epoch          : 3
2024-03-30 16:21:38,759 - trainer - INFO -     loss           : 0.377041
2024-03-30 16:21:38,759 - trainer - INFO -     accuracy       : 0.869577
2024-03-30 16:21:38,759 - trainer - INFO -     macro_f        : 0.867918
2024-03-30 16:21:38,759 - trainer - INFO -     precision      : 0.887507
2024-03-30 16:21:38,759 - trainer - INFO -     recall         : 0.869577
2024-03-30 16:21:38,759 - trainer - INFO -     val_loss       : 0.691757
2024-03-30 16:21:38,759 - trainer - INFO -     val_accuracy   : 0.781868
2024-03-30 16:21:38,759 - trainer - INFO -     val_macro_f    : 0.778666
2024-03-30 16:21:38,759 - trainer - INFO -     val_precision  : 0.805789
2024-03-30 16:21:38,759 - trainer - INFO -     val_recall     : 0.781868
2024-03-30 16:21:38,759 - trainer - INFO -     test_loss      : 0.689359
2024-03-30 16:21:38,759 - trainer - INFO -     test_accuracy  : 0.785857
2024-03-30 16:21:38,759 - trainer - INFO -     test_macro_f   : 0.782693
2024-03-30 16:21:38,759 - trainer - INFO -     test_precision : 0.809906
2024-03-30 16:21:38,759 - trainer - INFO -     test_recall    : 0.785857
2024-03-30 16:23:16,957 - train - INFO - PretrainedBaseline(
  (model): DistilBertForSequenceClassification(
    (distilbert): DistilBertModel(
      (embeddings): Embeddings(
        (word_embeddings): Embedding(30522, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (transformer): Transformer(
        (layer): ModuleList(
          (0): TransformerBlock(
            (attention): MultiHeadSelfAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (q_lin): Linear(in_features=768, out_features=768, bias=True)
              (k_lin): Linear(in_features=768, out_features=768, bias=True)
              (v_lin): Linear(in_features=768, out_features=768, bias=True)
              (out_lin): Linear(in_features=768, out_features=768, bias=True)
            )
            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (ffn): FFN(
              (dropout): Dropout(p=0.1, inplace=False)
              (lin1): Linear(in_features=768, out_features=3072, bias=True)
              (lin2): Linear(in_features=3072, out_features=768, bias=True)
              (activation): GELUActivation()
            )
            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          )
        )
      )
    )
    (pre_classifier): Linear(in_features=768, out_features=768, bias=True)
    (classifier): Linear(in_features=768, out_features=15, bias=True)
    (dropout): Dropout(p=0.2, inplace=False)
  )
)
Trainable params: 31,525,647
Freeze params: 0
2024-03-30 16:33:28,186 - trainer - INFO -     epoch          : 1
2024-03-30 16:33:28,186 - trainer - INFO -     loss           : 0.776762
2024-03-30 16:33:28,186 - trainer - INFO -     accuracy       : 0.7418
2024-03-30 16:33:28,186 - trainer - INFO -     macro_f        : 0.726841
2024-03-30 16:33:28,186 - trainer - INFO -     precision      : 0.746631
2024-03-30 16:33:28,186 - trainer - INFO -     recall         : 0.7418
2024-03-30 16:33:28,186 - trainer - INFO -     val_loss       : 0.62947
2024-03-30 16:33:28,186 - trainer - INFO -     val_accuracy   : 0.778954
2024-03-30 16:33:28,186 - trainer - INFO -     val_macro_f    : 0.776574
2024-03-30 16:33:28,186 - trainer - INFO -     val_precision  : 0.804692
2024-03-30 16:33:28,186 - trainer - INFO -     val_recall     : 0.778954
2024-03-30 16:33:28,186 - trainer - INFO -     test_loss      : 0.629692
2024-03-30 16:33:28,186 - trainer - INFO -     test_accuracy  : 0.779798
2024-03-30 16:33:28,186 - trainer - INFO -     test_macro_f   : 0.778982
2024-03-30 16:33:28,186 - trainer - INFO -     test_precision : 0.808487
2024-03-30 16:33:28,186 - trainer - INFO -     test_recall    : 0.779798
2024-03-30 16:43:42,299 - trainer - INFO -     epoch          : 2
2024-03-30 16:43:42,299 - trainer - INFO -     loss           : 0.527046
2024-03-30 16:43:42,299 - trainer - INFO -     accuracy       : 0.817304
2024-03-30 16:43:42,299 - trainer - INFO -     macro_f        : 0.813296
2024-03-30 16:43:42,299 - trainer - INFO -     precision      : 0.837859
2024-03-30 16:43:42,299 - trainer - INFO -     recall         : 0.817304
2024-03-30 16:43:42,299 - trainer - INFO -     val_loss       : 0.633361
2024-03-30 16:43:42,299 - trainer - INFO -     val_accuracy   : 0.782635
2024-03-30 16:43:42,299 - trainer - INFO -     val_macro_f    : 0.771338
2024-03-30 16:43:42,299 - trainer - INFO -     val_precision  : 0.792256
2024-03-30 16:43:42,299 - trainer - INFO -     val_recall     : 0.782635
2024-03-30 16:43:42,299 - trainer - INFO -     test_loss      : 0.624485
2024-03-30 16:43:42,299 - trainer - INFO -     test_accuracy  : 0.790229
2024-03-30 16:43:42,299 - trainer - INFO -     test_macro_f   : 0.780124
2024-03-30 16:43:42,299 - trainer - INFO -     test_precision : 0.802087
2024-03-30 16:43:42,299 - trainer - INFO -     test_recall    : 0.790229
2024-03-30 16:53:55,960 - trainer - INFO -     epoch          : 3
2024-03-30 16:53:55,960 - trainer - INFO -     loss           : 0.37896
2024-03-30 16:53:55,960 - trainer - INFO -     accuracy       : 0.868225
2024-03-30 16:53:55,960 - trainer - INFO -     macro_f        : 0.865961
2024-03-30 16:53:55,960 - trainer - INFO -     precision      : 0.88546
2024-03-30 16:53:55,960 - trainer - INFO -     recall         : 0.868225
2024-03-30 16:53:55,960 - trainer - INFO -     val_loss       : 0.690954
2024-03-30 16:53:55,960 - trainer - INFO -     val_accuracy   : 0.782942
2024-03-30 16:53:55,960 - trainer - INFO -     val_macro_f    : 0.779364
2024-03-30 16:53:55,960 - trainer - INFO -     val_precision  : 0.805285
2024-03-30 16:53:55,960 - trainer - INFO -     val_recall     : 0.782942
2024-03-30 16:53:55,960 - trainer - INFO -     test_loss      : 0.685577
2024-03-30 16:53:55,960 - trainer - INFO -     test_accuracy  : 0.787237
2024-03-30 16:53:55,960 - trainer - INFO -     test_macro_f   : 0.785485
2024-03-30 16:53:55,960 - trainer - INFO -     test_precision : 0.811334
2024-03-30 16:53:55,960 - trainer - INFO -     test_recall    : 0.787237
2024-03-30 16:55:30,199 - train - INFO - PretrainedBaseline(
  (model): DistilBertForSequenceClassification(
    (distilbert): DistilBertModel(
      (embeddings): Embeddings(
        (word_embeddings): Embedding(30522, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (transformer): Transformer(
        (layer): ModuleList(
          (0): TransformerBlock(
            (attention): MultiHeadSelfAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (q_lin): Linear(in_features=768, out_features=768, bias=True)
              (k_lin): Linear(in_features=768, out_features=768, bias=True)
              (v_lin): Linear(in_features=768, out_features=768, bias=True)
              (out_lin): Linear(in_features=768, out_features=768, bias=True)
            )
            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (ffn): FFN(
              (dropout): Dropout(p=0.1, inplace=False)
              (lin1): Linear(in_features=768, out_features=3072, bias=True)
              (lin2): Linear(in_features=3072, out_features=768, bias=True)
              (activation): GELUActivation()
            )
            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          )
        )
      )
    )
    (pre_classifier): Linear(in_features=768, out_features=768, bias=True)
    (classifier): Linear(in_features=768, out_features=15, bias=True)
    (dropout): Dropout(p=0.2, inplace=False)
  )
)
Trainable params: 31,525,647
Freeze params: 0
2024-03-30 17:05:41,955 - trainer - INFO -     epoch          : 1
2024-03-30 17:05:42,830 - trainer - INFO -     loss           : 0.780214
2024-03-30 17:05:42,830 - trainer - INFO -     accuracy       : 0.740515
2024-03-30 17:05:42,830 - trainer - INFO -     macro_f        : 0.726336
2024-03-30 17:05:42,830 - trainer - INFO -     precision      : 0.747304
2024-03-30 17:05:42,830 - trainer - INFO -     recall         : 0.740515
2024-03-30 17:05:42,830 - trainer - INFO -     val_loss       : 0.630766
2024-03-30 17:05:42,830 - trainer - INFO -     val_accuracy   : 0.781715
2024-03-30 17:05:42,830 - trainer - INFO -     val_macro_f    : 0.774334
2024-03-30 17:05:42,830 - trainer - INFO -     val_precision  : 0.799769
2024-03-30 17:05:42,830 - trainer - INFO -     val_recall     : 0.781715
2024-03-30 17:05:42,830 - trainer - INFO -     test_loss      : 0.632928
2024-03-30 17:05:42,830 - trainer - INFO -     test_accuracy  : 0.779721
2024-03-30 17:05:42,830 - trainer - INFO -     test_macro_f   : 0.771699
2024-03-30 17:05:42,830 - trainer - INFO -     test_precision : 0.794065
2024-03-30 17:05:42,830 - trainer - INFO -     test_recall    : 0.779721
2024-03-30 17:15:57,591 - trainer - INFO -     epoch          : 2
2024-03-30 17:15:57,591 - trainer - INFO -     loss           : 0.528058
2024-03-30 17:15:57,591 - trainer - INFO -     accuracy       : 0.817697
2024-03-30 17:15:57,591 - trainer - INFO -     macro_f        : 0.813608
2024-03-30 17:15:57,591 - trainer - INFO -     precision      : 0.837299
2024-03-30 17:15:57,591 - trainer - INFO -     recall         : 0.817697
2024-03-30 17:15:57,591 - trainer - INFO -     val_loss       : 0.625092
2024-03-30 17:15:57,591 - trainer - INFO -     val_accuracy   : 0.789845
2024-03-30 17:15:57,591 - trainer - INFO -     val_macro_f    : 0.786992
2024-03-30 17:15:57,591 - trainer - INFO -     val_precision  : 0.815218
2024-03-30 17:15:57,591 - trainer - INFO -     val_recall     : 0.789845
2024-03-30 17:15:57,591 - trainer - INFO -     test_loss      : 0.624577
2024-03-30 17:15:57,591 - trainer - INFO -     test_accuracy  : 0.789538
2024-03-30 17:15:57,591 - trainer - INFO -     test_macro_f   : 0.785832
2024-03-30 17:15:57,591 - trainer - INFO -     test_precision : 0.811041
2024-03-30 17:15:57,591 - trainer - INFO -     test_recall    : 0.789538
2024-03-30 17:26:12,512 - trainer - INFO -     epoch          : 3
2024-03-30 17:26:12,512 - trainer - INFO -     loss           : 0.379197
2024-03-30 17:26:12,512 - trainer - INFO -     accuracy       : 0.868465
2024-03-30 17:26:12,512 - trainer - INFO -     macro_f        : 0.866727
2024-03-30 17:26:12,512 - trainer - INFO -     precision      : 0.887164
2024-03-30 17:26:12,512 - trainer - INFO -     recall         : 0.868465
2024-03-30 17:26:12,512 - trainer - INFO -     val_loss       : 0.685994
2024-03-30 17:26:12,512 - trainer - INFO -     val_accuracy   : 0.780028
2024-03-30 17:26:12,512 - trainer - INFO -     val_macro_f    : 0.778356
2024-03-30 17:26:12,512 - trainer - INFO -     val_precision  : 0.806294
2024-03-30 17:26:12,512 - trainer - INFO -     val_recall     : 0.780028
2024-03-30 17:26:12,512 - trainer - INFO -     test_loss      : 0.676808
2024-03-30 17:26:12,512 - trainer - INFO -     test_accuracy  : 0.786777
2024-03-30 17:26:12,512 - trainer - INFO -     test_macro_f   : 0.785385
2024-03-30 17:26:12,512 - trainer - INFO -     test_precision : 0.814277
2024-03-30 17:26:12,512 - trainer - INFO -     test_recall    : 0.786777
2024-03-30 17:33:35,357 - train - INFO - PretrainedBaseline(
  (model): DistilBertForSequenceClassification(
    (distilbert): DistilBertModel(
      (embeddings): Embeddings(
        (word_embeddings): Embedding(30522, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (transformer): Transformer(
        (layer): ModuleList(
          (0): TransformerBlock(
            (attention): MultiHeadSelfAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (q_lin): Linear(in_features=768, out_features=768, bias=True)
              (k_lin): Linear(in_features=768, out_features=768, bias=True)
              (v_lin): Linear(in_features=768, out_features=768, bias=True)
              (out_lin): Linear(in_features=768, out_features=768, bias=True)
            )
            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (ffn): FFN(
              (dropout): Dropout(p=0.1, inplace=False)
              (lin1): Linear(in_features=768, out_features=3072, bias=True)
              (lin2): Linear(in_features=3072, out_features=768, bias=True)
              (activation): GELUActivation()
            )
            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          )
        )
      )
    )
    (pre_classifier): Linear(in_features=768, out_features=768, bias=True)
    (classifier): Linear(in_features=768, out_features=15, bias=True)
    (dropout): Dropout(p=0.2, inplace=False)
  )
)
Trainable params: 31,525,647
Freeze params: 0
2024-03-30 17:53:56,371 - trainer - INFO -     epoch          : 1
2024-03-30 17:53:56,371 - trainer - INFO -     loss           : 0.735253
2024-03-30 17:53:56,371 - trainer - INFO -     accuracy       : 0.751261
2024-03-30 17:53:56,371 - trainer - INFO -     macro_f        : 0.738707
2024-03-30 17:53:56,371 - trainer - INFO -     precision      : 0.760265
2024-03-30 17:53:56,371 - trainer - INFO -     recall         : 0.751261
2024-03-30 17:53:56,371 - trainer - INFO -     val_loss       : 0.592058
2024-03-30 17:53:56,371 - trainer - INFO -     val_accuracy   : 0.794447
2024-03-30 17:53:56,371 - trainer - INFO -     val_macro_f    : 0.78885
2024-03-30 17:53:56,371 - trainer - INFO -     val_precision  : 0.812754
2024-03-30 17:53:56,371 - trainer - INFO -     val_recall     : 0.794447
2024-03-30 17:53:56,371 - trainer - INFO -     test_loss      : 0.589255
2024-03-30 17:53:56,371 - trainer - INFO -     test_accuracy  : 0.794524
2024-03-30 17:53:56,371 - trainer - INFO -     test_macro_f   : 0.791459
2024-03-30 17:53:56,371 - trainer - INFO -     test_precision : 0.816513
2024-03-30 17:53:56,371 - trainer - INFO -     test_recall    : 0.794524
2024-03-30 18:14:27,544 - trainer - INFO -     epoch          : 2
2024-03-30 18:14:27,544 - trainer - INFO -     loss           : 0.490617
2024-03-30 18:14:27,544 - trainer - INFO -     accuracy       : 0.82922
2024-03-30 18:14:27,544 - trainer - INFO -     macro_f        : 0.825566
2024-03-30 18:14:27,544 - trainer - INFO -     precision      : 0.847931
2024-03-30 18:14:27,544 - trainer - INFO -     recall         : 0.82922
2024-03-30 18:14:27,544 - trainer - INFO -     val_loss       : 0.586907
2024-03-30 18:14:27,544 - trainer - INFO -     val_accuracy   : 0.798052
2024-03-30 18:14:27,544 - trainer - INFO -     val_macro_f    : 0.797896
2024-03-30 18:14:27,544 - trainer - INFO -     val_precision  : 0.826597
2024-03-30 18:14:27,544 - trainer - INFO -     val_recall     : 0.798052
2024-03-30 18:14:27,544 - trainer - INFO -     test_loss      : 0.581322
2024-03-30 18:14:27,544 - trainer - INFO -     test_accuracy  : 0.800583
2024-03-30 18:14:27,544 - trainer - INFO -     test_macro_f   : 0.798402
2024-03-30 18:14:27,544 - trainer - INFO -     test_precision : 0.821981
2024-03-30 18:14:27,544 - trainer - INFO -     test_recall    : 0.800583
2024-03-30 18:34:57,860 - trainer - INFO -     epoch          : 3
2024-03-30 18:34:57,860 - trainer - INFO -     loss           : 0.344023
2024-03-30 18:34:57,860 - trainer - INFO -     accuracy       : 0.879653
2024-03-30 18:34:57,860 - trainer - INFO -     macro_f        : 0.878622
2024-03-30 18:34:57,860 - trainer - INFO -     precision      : 0.898022
2024-03-30 18:34:57,860 - trainer - INFO -     recall         : 0.879653
2024-03-30 18:34:57,860 - trainer - INFO -     val_loss       : 0.661601
2024-03-30 18:34:57,860 - trainer - INFO -     val_accuracy   : 0.791839
2024-03-30 18:34:57,860 - trainer - INFO -     val_macro_f    : 0.793398
2024-03-30 18:34:57,860 - trainer - INFO -     val_precision  : 0.824356
2024-03-30 18:34:57,860 - trainer - INFO -     val_recall     : 0.791839
2024-03-30 18:34:57,860 - trainer - INFO -     test_loss      : 0.660283
2024-03-30 18:34:57,860 - trainer - INFO -     test_accuracy  : 0.791532
2024-03-30 18:34:57,860 - trainer - INFO -     test_macro_f   : 0.795332
2024-03-30 18:34:57,860 - trainer - INFO -     test_precision : 0.828612
2024-03-30 18:34:57,860 - trainer - INFO -     test_recall    : 0.791532
2024-03-30 18:37:42,313 - train - INFO - PretrainedBaseline(
  (model): DistilBertForSequenceClassification(
    (distilbert): DistilBertModel(
      (embeddings): Embeddings(
        (word_embeddings): Embedding(30522, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (transformer): Transformer(
        (layer): ModuleList(
          (0): TransformerBlock(
            (attention): MultiHeadSelfAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (q_lin): Linear(in_features=768, out_features=768, bias=True)
              (k_lin): Linear(in_features=768, out_features=768, bias=True)
              (v_lin): Linear(in_features=768, out_features=768, bias=True)
              (out_lin): Linear(in_features=768, out_features=768, bias=True)
            )
            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (ffn): FFN(
              (dropout): Dropout(p=0.1, inplace=False)
              (lin1): Linear(in_features=768, out_features=3072, bias=True)
              (lin2): Linear(in_features=3072, out_features=768, bias=True)
              (activation): GELUActivation()
            )
            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          )
        )
      )
    )
    (pre_classifier): Linear(in_features=768, out_features=768, bias=True)
    (classifier): Linear(in_features=768, out_features=15, bias=True)
    (dropout): Dropout(p=0.2, inplace=False)
  )
)
Trainable params: 31,525,647
Freeze params: 0
2024-03-30 18:57:57,046 - trainer - INFO -     epoch          : 1
2024-03-30 18:57:57,046 - trainer - INFO -     loss           : 0.732274
2024-03-30 18:57:57,046 - trainer - INFO -     accuracy       : 0.752941
2024-03-30 18:57:57,046 - trainer - INFO -     macro_f        : 0.741075
2024-03-30 18:57:57,062 - trainer - INFO -     precision      : 0.763367
2024-03-30 18:57:57,062 - trainer - INFO -     recall         : 0.752941
2024-03-30 18:57:57,062 - trainer - INFO -     val_loss       : 0.59688
2024-03-30 18:57:57,062 - trainer - INFO -     val_accuracy   : 0.786087
2024-03-30 18:57:57,062 - trainer - INFO -     val_macro_f    : 0.788239
2024-03-30 18:57:57,062 - trainer - INFO -     val_precision  : 0.822984
2024-03-30 18:57:57,062 - trainer - INFO -     val_recall     : 0.786087
2024-03-30 18:57:57,062 - trainer - INFO -     test_loss      : 0.595805
2024-03-30 18:57:57,062 - trainer - INFO -     test_accuracy  : 0.790919
2024-03-30 18:57:57,062 - trainer - INFO -     test_macro_f   : 0.793774
2024-03-30 18:57:57,062 - trainer - INFO -     test_precision : 0.827081
2024-03-30 18:57:57,062 - trainer - INFO -     test_recall    : 0.790919
2024-03-30 19:18:11,397 - trainer - INFO -     epoch          : 2
2024-03-30 19:18:11,397 - trainer - INFO -     loss           : 0.491268
2024-03-30 19:18:11,397 - trainer - INFO -     accuracy       : 0.828388
2024-03-30 19:18:11,397 - trainer - INFO -     macro_f        : 0.825201
2024-03-30 19:18:11,397 - trainer - INFO -     precision      : 0.84862
2024-03-30 19:18:11,397 - trainer - INFO -     recall         : 0.828388
2024-03-30 19:18:11,397 - trainer - INFO -     val_loss       : 0.582834
2024-03-30 19:18:11,397 - trainer - INFO -     val_accuracy   : 0.799739
2024-03-30 19:18:11,397 - trainer - INFO -     val_macro_f    : 0.797644
2024-03-30 19:18:11,397 - trainer - INFO -     val_precision  : 0.824611
2024-03-30 19:18:11,397 - trainer - INFO -     val_recall     : 0.799739
2024-03-30 19:18:11,397 - trainer - INFO -     test_loss      : 0.572054
2024-03-30 19:18:11,397 - trainer - INFO -     test_accuracy  : 0.801733
2024-03-30 19:18:11,397 - trainer - INFO -     test_macro_f   : 0.801654
2024-03-30 19:18:11,397 - trainer - INFO -     test_precision : 0.828929
2024-03-30 19:18:11,397 - trainer - INFO -     test_recall    : 0.801733
2024-03-30 19:38:27,117 - trainer - INFO -     epoch          : 3
2024-03-30 19:38:27,117 - trainer - INFO -     loss           : 0.344222
2024-03-30 19:38:27,117 - trainer - INFO -     accuracy       : 0.879798
2024-03-30 19:38:27,133 - trainer - INFO -     macro_f        : 0.878391
2024-03-30 19:38:27,133 - trainer - INFO -     precision      : 0.897425
2024-03-30 19:38:27,133 - trainer - INFO -     recall         : 0.879798
2024-03-30 19:38:27,133 - trainer - INFO -     val_loss       : 0.645806
2024-03-30 19:38:27,133 - trainer - INFO -     val_accuracy   : 0.792376
2024-03-30 19:38:27,133 - trainer - INFO -     val_macro_f    : 0.79337
2024-03-30 19:38:27,133 - trainer - INFO -     val_precision  : 0.822872
2024-03-30 19:38:27,133 - trainer - INFO -     val_recall     : 0.792376
2024-03-30 19:38:27,133 - trainer - INFO -     test_loss      : 0.639825
2024-03-30 19:38:27,133 - trainer - INFO -     test_accuracy  : 0.79322
2024-03-30 19:38:27,133 - trainer - INFO -     test_macro_f   : 0.794319
2024-03-30 19:38:27,133 - trainer - INFO -     test_precision : 0.824065
2024-03-30 19:38:27,133 - trainer - INFO -     test_recall    : 0.79322
2024-03-30 19:41:10,430 - train - INFO - PretrainedBaseline(
  (model): DistilBertForSequenceClassification(
    (distilbert): DistilBertModel(
      (embeddings): Embeddings(
        (word_embeddings): Embedding(30522, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (transformer): Transformer(
        (layer): ModuleList(
          (0): TransformerBlock(
            (attention): MultiHeadSelfAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (q_lin): Linear(in_features=768, out_features=768, bias=True)
              (k_lin): Linear(in_features=768, out_features=768, bias=True)
              (v_lin): Linear(in_features=768, out_features=768, bias=True)
              (out_lin): Linear(in_features=768, out_features=768, bias=True)
            )
            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (ffn): FFN(
              (dropout): Dropout(p=0.1, inplace=False)
              (lin1): Linear(in_features=768, out_features=3072, bias=True)
              (lin2): Linear(in_features=3072, out_features=768, bias=True)
              (activation): GELUActivation()
            )
            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          )
        )
      )
    )
    (pre_classifier): Linear(in_features=768, out_features=768, bias=True)
    (classifier): Linear(in_features=768, out_features=15, bias=True)
    (dropout): Dropout(p=0.2, inplace=False)
  )
)
Trainable params: 31,525,647
Freeze params: 0
2024-03-30 20:01:29,761 - trainer - INFO -     epoch          : 1
2024-03-30 20:01:29,761 - trainer - INFO -     loss           : 0.73395
2024-03-30 20:01:29,761 - trainer - INFO -     accuracy       : 0.754101
2024-03-30 20:01:29,761 - trainer - INFO -     macro_f        : 0.742045
2024-03-30 20:01:29,761 - trainer - INFO -     precision      : 0.764307
2024-03-30 20:01:29,761 - trainer - INFO -     recall         : 0.754101
2024-03-30 20:01:29,761 - trainer - INFO -     val_loss       : 0.590264
2024-03-30 20:01:29,761 - trainer - INFO -     val_accuracy   : 0.791456
2024-03-30 20:01:29,761 - trainer - INFO -     val_macro_f    : 0.790598
2024-03-30 20:01:29,761 - trainer - INFO -     val_precision  : 0.821399
2024-03-30 20:01:29,761 - trainer - INFO -     val_recall     : 0.791456
2024-03-30 20:01:29,761 - trainer - INFO -     test_loss      : 0.582885
2024-03-30 20:01:29,761 - trainer - INFO -     test_accuracy  : 0.795674
2024-03-30 20:01:29,761 - trainer - INFO -     test_macro_f   : 0.793493
2024-03-30 20:01:29,761 - trainer - INFO -     test_precision : 0.820623
2024-03-30 20:01:29,761 - trainer - INFO -     test_recall    : 0.795674
2024-03-30 20:21:56,882 - trainer - INFO -     epoch          : 2
2024-03-30 20:21:56,882 - trainer - INFO -     loss           : 0.489107
2024-03-30 20:21:56,882 - trainer - INFO -     accuracy       : 0.831638
2024-03-30 20:21:56,882 - trainer - INFO -     macro_f        : 0.828325
2024-03-30 20:21:56,882 - trainer - INFO -     precision      : 0.851536
2024-03-30 20:21:56,882 - trainer - INFO -     recall         : 0.831638
2024-03-30 20:21:56,882 - trainer - INFO -     val_loss       : 0.569552
2024-03-30 20:21:56,882 - trainer - INFO -     val_accuracy   : 0.799893
2024-03-30 20:21:56,882 - trainer - INFO -     val_macro_f    : 0.794336
2024-03-30 20:21:56,882 - trainer - INFO -     val_precision  : 0.819295
2024-03-30 20:21:56,882 - trainer - INFO -     val_recall     : 0.799893
2024-03-30 20:21:56,882 - trainer - INFO -     test_loss      : 0.568679
2024-03-30 20:21:56,882 - trainer - INFO -     test_accuracy  : 0.802117
2024-03-30 20:21:56,882 - trainer - INFO -     test_macro_f   : 0.796904
2024-03-30 20:21:56,882 - trainer - INFO -     test_precision : 0.82034
2024-03-30 20:21:56,882 - trainer - INFO -     test_recall    : 0.802117
2024-03-30 20:42:26,645 - trainer - INFO -     epoch          : 3
2024-03-30 20:42:26,645 - trainer - INFO -     loss           : 0.341474
2024-03-30 20:42:26,645 - trainer - INFO -     accuracy       : 0.880469
2024-03-30 20:42:26,645 - trainer - INFO -     macro_f        : 0.879009
2024-03-30 20:42:26,645 - trainer - INFO -     precision      : 0.897971
2024-03-30 20:42:26,645 - trainer - INFO -     recall         : 0.880469
2024-03-30 20:42:26,645 - trainer - INFO -     val_loss       : 0.640541
2024-03-30 20:42:26,645 - trainer - INFO -     val_accuracy   : 0.794754
2024-03-30 20:42:26,645 - trainer - INFO -     val_macro_f    : 0.792665
2024-03-30 20:42:26,645 - trainer - INFO -     val_precision  : 0.817504
2024-03-30 20:42:26,645 - trainer - INFO -     val_recall     : 0.794754
2024-03-30 20:42:26,645 - trainer - INFO -     test_loss      : 0.634865
2024-03-30 20:42:26,645 - trainer - INFO -     test_accuracy  : 0.80158
2024-03-30 20:42:26,645 - trainer - INFO -     test_macro_f   : 0.802026
2024-03-30 20:42:26,645 - trainer - INFO -     test_precision : 0.830377
2024-03-30 20:42:26,645 - trainer - INFO -     test_recall    : 0.80158
2024-03-30 20:45:14,321 - train - INFO - PretrainedBaseline(
  (model): DistilBertForSequenceClassification(
    (distilbert): DistilBertModel(
      (embeddings): Embeddings(
        (word_embeddings): Embedding(30522, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (transformer): Transformer(
        (layer): ModuleList(
          (0): TransformerBlock(
            (attention): MultiHeadSelfAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (q_lin): Linear(in_features=768, out_features=768, bias=True)
              (k_lin): Linear(in_features=768, out_features=768, bias=True)
              (v_lin): Linear(in_features=768, out_features=768, bias=True)
              (out_lin): Linear(in_features=768, out_features=768, bias=True)
            )
            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (ffn): FFN(
              (dropout): Dropout(p=0.1, inplace=False)
              (lin1): Linear(in_features=768, out_features=3072, bias=True)
              (lin2): Linear(in_features=3072, out_features=768, bias=True)
              (activation): GELUActivation()
            )
            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          )
        )
      )
    )
    (pre_classifier): Linear(in_features=768, out_features=768, bias=True)
    (classifier): Linear(in_features=768, out_features=15, bias=True)
    (dropout): Dropout(p=0.2, inplace=False)
  )
)
Trainable params: 31,525,647
Freeze params: 0
2024-03-30 21:05:36,723 - trainer - INFO -     epoch          : 1
2024-03-30 21:05:37,582 - trainer - INFO -     loss           : 0.727913
2024-03-30 21:05:37,582 - trainer - INFO -     accuracy       : 0.754197
2024-03-30 21:05:37,582 - trainer - INFO -     macro_f        : 0.741725
2024-03-30 21:05:37,582 - trainer - INFO -     precision      : 0.76331
2024-03-30 21:05:37,582 - trainer - INFO -     recall         : 0.754197
2024-03-30 21:05:37,582 - trainer - INFO -     val_loss       : 0.580466
2024-03-30 21:05:37,582 - trainer - INFO -     val_accuracy   : 0.791993
2024-03-30 21:05:37,582 - trainer - INFO -     val_macro_f    : 0.790815
2024-03-30 21:05:37,582 - trainer - INFO -     val_precision  : 0.821174
2024-03-30 21:05:37,582 - trainer - INFO -     val_recall     : 0.791993
2024-03-30 21:05:37,582 - trainer - INFO -     test_loss      : 0.582182
2024-03-30 21:05:37,582 - trainer - INFO -     test_accuracy  : 0.795291
2024-03-30 21:05:37,582 - trainer - INFO -     test_macro_f   : 0.794464
2024-03-30 21:05:37,582 - trainer - INFO -     test_precision : 0.822454
2024-03-30 21:05:37,582 - trainer - INFO -     test_recall    : 0.795291
2024-03-30 21:25:57,904 - trainer - INFO -     epoch          : 2
2024-03-30 21:25:57,904 - trainer - INFO -     loss           : 0.486827
2024-03-30 21:25:57,904 - trainer - INFO -     accuracy       : 0.830746
2024-03-30 21:25:57,904 - trainer - INFO -     macro_f        : 0.827727
2024-03-30 21:25:57,904 - trainer - INFO -     precision      : 0.851458
2024-03-30 21:25:57,904 - trainer - INFO -     recall         : 0.830746
2024-03-30 21:25:57,904 - trainer - INFO -     val_loss       : 0.581175
2024-03-30 21:25:57,904 - trainer - INFO -     val_accuracy   : 0.798819
2024-03-30 21:25:57,904 - trainer - INFO -     val_macro_f    : 0.789542
2024-03-30 21:25:57,904 - trainer - INFO -     val_precision  : 0.810954
2024-03-30 21:25:57,904 - trainer - INFO -     val_recall     : 0.798819
2024-03-30 21:25:57,904 - trainer - INFO -     test_loss      : 0.577936
2024-03-30 21:25:57,904 - trainer - INFO -     test_accuracy  : 0.808253
2024-03-30 21:25:57,904 - trainer - INFO -     test_macro_f   : 0.799918
2024-03-30 21:25:57,904 - trainer - INFO -     test_precision : 0.820236
2024-03-30 21:25:57,904 - trainer - INFO -     test_recall    : 0.808253
2024-03-30 21:46:21,130 - trainer - INFO -     epoch          : 3
2024-03-30 21:46:21,130 - trainer - INFO -     loss           : 0.33978
2024-03-30 21:46:21,130 - trainer - INFO -     accuracy       : 0.881178
2024-03-30 21:46:21,130 - trainer - INFO -     macro_f        : 0.879453
2024-03-30 21:46:21,130 - trainer - INFO -     precision      : 0.897697
2024-03-30 21:46:21,130 - trainer - INFO -     recall         : 0.881178
2024-03-30 21:46:21,130 - trainer - INFO -     val_loss       : 0.643284
2024-03-30 21:46:21,130 - trainer - INFO -     val_accuracy   : 0.797668
2024-03-30 21:46:21,130 - trainer - INFO -     val_macro_f    : 0.795403
2024-03-30 21:46:21,130 - trainer - INFO -     val_precision  : 0.822525
2024-03-30 21:46:21,130 - trainer - INFO -     val_recall     : 0.797668
2024-03-30 21:46:21,130 - trainer - INFO -     test_loss      : 0.64489
2024-03-30 21:46:21,130 - trainer - INFO -     test_accuracy  : 0.797668
2024-03-30 21:46:21,146 - trainer - INFO -     test_macro_f   : 0.796395
2024-03-30 21:46:21,146 - trainer - INFO -     test_precision : 0.821546
2024-03-30 21:46:21,146 - trainer - INFO -     test_recall    : 0.797668
2024-03-30 21:49:07,089 - train - INFO - PretrainedBaseline(
  (model): DistilBertForSequenceClassification(
    (distilbert): DistilBertModel(
      (embeddings): Embeddings(
        (word_embeddings): Embedding(30522, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (transformer): Transformer(
        (layer): ModuleList(
          (0): TransformerBlock(
            (attention): MultiHeadSelfAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (q_lin): Linear(in_features=768, out_features=768, bias=True)
              (k_lin): Linear(in_features=768, out_features=768, bias=True)
              (v_lin): Linear(in_features=768, out_features=768, bias=True)
              (out_lin): Linear(in_features=768, out_features=768, bias=True)
            )
            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (ffn): FFN(
              (dropout): Dropout(p=0.1, inplace=False)
              (lin1): Linear(in_features=768, out_features=3072, bias=True)
              (lin2): Linear(in_features=3072, out_features=768, bias=True)
              (activation): GELUActivation()
            )
            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          )
        )
      )
    )
    (pre_classifier): Linear(in_features=768, out_features=768, bias=True)
    (classifier): Linear(in_features=768, out_features=15, bias=True)
    (dropout): Dropout(p=0.2, inplace=False)
  )
)
Trainable params: 31,525,647
Freeze params: 0
2024-03-30 22:09:31,234 - trainer - INFO -     epoch          : 1
2024-03-30 22:09:31,234 - trainer - INFO -     loss           : 0.731863
2024-03-30 22:09:31,234 - trainer - INFO -     accuracy       : 0.753277
2024-03-30 22:09:31,234 - trainer - INFO -     macro_f        : 0.74093
2024-03-30 22:09:31,234 - trainer - INFO -     precision      : 0.762851
2024-03-30 22:09:31,234 - trainer - INFO -     recall         : 0.753277
2024-03-30 22:09:31,234 - trainer - INFO -     val_loss       : 0.590956
2024-03-30 22:09:31,234 - trainer - INFO -     val_accuracy   : 0.79253
2024-03-30 22:09:31,234 - trainer - INFO -     val_macro_f    : 0.782547
2024-03-30 22:09:31,234 - trainer - INFO -     val_precision  : 0.804916
2024-03-30 22:09:31,234 - trainer - INFO -     val_recall     : 0.79253
2024-03-30 22:09:31,234 - trainer - INFO -     test_loss      : 0.595661
2024-03-30 22:09:31,234 - trainer - INFO -     test_accuracy  : 0.792069
2024-03-30 22:09:31,234 - trainer - INFO -     test_macro_f   : 0.781375
2024-03-30 22:09:31,234 - trainer - INFO -     test_precision : 0.802272
2024-03-30 22:09:31,234 - trainer - INFO -     test_recall    : 0.792069
2024-03-30 22:29:58,560 - trainer - INFO -     epoch          : 2
2024-03-30 22:29:58,560 - trainer - INFO -     loss           : 0.492859
2024-03-30 22:29:58,560 - trainer - INFO -     accuracy       : 0.828714
2024-03-30 22:29:58,560 - trainer - INFO -     macro_f        : 0.82545
2024-03-30 22:29:58,560 - trainer - INFO -     precision      : 0.848223
2024-03-30 22:29:58,560 - trainer - INFO -     recall         : 0.828714
2024-03-30 22:29:58,560 - trainer - INFO -     val_loss       : 0.578156
2024-03-30 22:29:58,560 - trainer - INFO -     val_accuracy   : 0.803574
2024-03-30 22:29:58,560 - trainer - INFO -     val_macro_f    : 0.799781
2024-03-30 22:29:58,560 - trainer - INFO -     val_precision  : 0.825058
2024-03-30 22:29:58,560 - trainer - INFO -     val_recall     : 0.803574
2024-03-30 22:29:58,560 - trainer - INFO -     test_loss      : 0.580476
2024-03-30 22:29:58,560 - trainer - INFO -     test_accuracy  : 0.805952
2024-03-30 22:29:58,560 - trainer - INFO -     test_macro_f   : 0.802477
2024-03-30 22:29:58,560 - trainer - INFO -     test_precision : 0.825135
2024-03-30 22:29:58,560 - trainer - INFO -     test_recall    : 0.805952
2024-03-30 22:50:35,126 - trainer - INFO -     epoch          : 3
2024-03-30 22:50:35,126 - trainer - INFO -     loss           : 0.344751
2024-03-30 22:50:35,126 - trainer - INFO -     accuracy       : 0.879203
2024-03-30 22:50:35,126 - trainer - INFO -     macro_f        : 0.87822
2024-03-30 22:50:35,126 - trainer - INFO -     precision      : 0.898058
2024-03-30 22:50:35,126 - trainer - INFO -     recall         : 0.879203
2024-03-30 22:50:35,126 - trainer - INFO -     val_loss       : 0.655294
2024-03-30 22:50:35,126 - trainer - INFO -     val_accuracy   : 0.790459
2024-03-30 22:50:35,126 - trainer - INFO -     val_macro_f    : 0.790467
2024-03-30 22:50:35,142 - trainer - INFO -     val_precision  : 0.819572
2024-03-30 22:50:35,142 - trainer - INFO -     val_recall     : 0.790459
2024-03-30 22:50:35,142 - trainer - INFO -     test_loss      : 0.652703
2024-03-30 22:50:35,142 - trainer - INFO -     test_accuracy  : 0.795444
2024-03-30 22:50:35,142 - trainer - INFO -     test_macro_f   : 0.794994
2024-03-30 22:50:35,142 - trainer - INFO -     test_precision : 0.823737
2024-03-30 22:50:35,142 - trainer - INFO -     test_recall    : 0.795444
2024-03-31 21:47:32,982 - train - INFO - PretrainedBaseline(
  (model): BertForSequenceClassification(
    (bert): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(30522, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (classifier): Linear(in_features=768, out_features=15, bias=True)
  )
)
Trainable params: 31,527,183
Freeze params: 0
2024-03-31 21:48:04,323 - train - INFO - PretrainedBaseline(
  (model): BertForSequenceClassification(
    (bert): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(30522, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (classifier): Linear(in_features=768, out_features=15, bias=True)
  )
)
Trainable params: 31,527,183
Freeze params: 0
2024-03-31 21:48:30,089 - train - INFO - PretrainedBaseline(
  (model): BertForSequenceClassification(
    (bert): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(30522, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (classifier): Linear(in_features=768, out_features=15, bias=True)
  )
)
Trainable params: 31,527,183
Freeze params: 0
2024-03-31 21:58:53,963 - trainer - INFO -     epoch          : 1
2024-03-31 21:58:53,963 - trainer - INFO -     loss           : 0.968096
2024-03-31 21:58:53,963 - trainer - INFO -     accuracy       : 0.69016
2024-03-31 21:58:53,963 - trainer - INFO -     macro_f        : 0.667128
2024-03-31 21:58:53,963 - trainer - INFO -     precision      : 0.682725
2024-03-31 21:58:53,963 - trainer - INFO -     recall         : 0.69016
2024-03-31 21:58:53,963 - trainer - INFO -     val_loss       : 0.766663
2024-03-31 21:58:53,963 - trainer - INFO -     val_accuracy   : 0.748888
2024-03-31 21:58:53,963 - trainer - INFO -     val_macro_f    : 0.745478
2024-03-31 21:58:53,963 - trainer - INFO -     val_precision  : 0.774269
2024-03-31 21:58:53,963 - trainer - INFO -     val_recall     : 0.748888
2024-03-31 21:58:53,963 - trainer - INFO -     test_loss      : 0.758476
2024-03-31 21:58:53,963 - trainer - INFO -     test_accuracy  : 0.750575
2024-03-31 21:58:53,963 - trainer - INFO -     test_macro_f   : 0.74822
2024-03-31 21:58:53,963 - trainer - INFO -     test_precision : 0.775113
2024-03-31 21:58:53,963 - trainer - INFO -     test_recall    : 0.750575
2024-03-31 22:09:19,030 - trainer - INFO -     epoch          : 2
2024-03-31 22:09:19,030 - trainer - INFO -     loss           : 0.683755
2024-03-31 22:09:19,030 - trainer - INFO -     accuracy       : 0.771867
2024-03-31 22:09:19,030 - trainer - INFO -     macro_f        : 0.762457
2024-03-31 22:09:19,030 - trainer - INFO -     precision      : 0.786272
2024-03-31 22:09:19,030 - trainer - INFO -     recall         : 0.771867
2024-03-31 22:09:19,030 - trainer - INFO -     val_loss       : 0.70945
2024-03-31 22:09:19,030 - trainer - INFO -     val_accuracy   : 0.758092
2024-03-31 22:09:19,030 - trainer - INFO -     val_macro_f    : 0.741231
2024-03-31 22:09:19,030 - trainer - INFO -     val_precision  : 0.759837
2024-03-31 22:09:19,030 - trainer - INFO -     val_recall     : 0.758092
2024-03-31 22:09:19,030 - trainer - INFO -     test_loss      : 0.702222
2024-03-31 22:09:19,030 - trainer - INFO -     test_accuracy  : 0.758705
2024-03-31 22:09:19,030 - trainer - INFO -     test_macro_f   : 0.742274
2024-03-31 22:09:19,045 - trainer - INFO -     test_precision : 0.757751
2024-03-31 22:09:19,045 - trainer - INFO -     test_recall    : 0.758705
2024-03-31 22:19:48,301 - trainer - INFO -     epoch          : 3
2024-03-31 22:19:48,301 - trainer - INFO -     loss           : 0.579627
2024-03-31 22:19:48,301 - trainer - INFO -     accuracy       : 0.801264
2024-03-31 22:19:48,301 - trainer - INFO -     macro_f        : 0.794441
2024-03-31 22:19:48,301 - trainer - INFO -     precision      : 0.81846
2024-03-31 22:19:48,301 - trainer - INFO -     recall         : 0.801264
2024-03-31 22:19:48,301 - trainer - INFO -     val_loss       : 0.715217
2024-03-31 22:19:48,301 - trainer - INFO -     val_accuracy   : 0.76208
2024-03-31 22:19:48,301 - trainer - INFO -     val_macro_f    : 0.749219
2024-03-31 22:19:48,301 - trainer - INFO -     val_precision  : 0.77095
2024-03-31 22:19:48,301 - trainer - INFO -     val_recall     : 0.76208
2024-03-31 22:19:48,301 - trainer - INFO -     test_loss      : 0.708368
2024-03-31 22:19:48,301 - trainer - INFO -     test_accuracy  : 0.758245
2024-03-31 22:19:48,301 - trainer - INFO -     test_macro_f   : 0.746635
2024-03-31 22:19:48,301 - trainer - INFO -     test_precision : 0.77126
2024-03-31 22:19:48,301 - trainer - INFO -     test_recall    : 0.758245
2024-03-31 22:21:27,656 - train - INFO - PretrainedBaseline(
  (model): BertForSequenceClassification(
    (bert): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(30522, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (classifier): Linear(in_features=768, out_features=15, bias=True)
  )
)
Trainable params: 31,527,183
Freeze params: 0
2024-03-31 22:32:00,472 - trainer - INFO -     epoch          : 1
2024-03-31 22:32:01,328 - trainer - INFO -     loss           : 1.085069
2024-03-31 22:32:01,343 - trainer - INFO -     accuracy       : 0.660591
2024-03-31 22:32:01,344 - trainer - INFO -     macro_f        : 0.631433
2024-03-31 22:32:01,344 - trainer - INFO -     precision      : 0.643382
2024-03-31 22:32:01,345 - trainer - INFO -     recall         : 0.660591
2024-03-31 22:32:01,346 - trainer - INFO -     val_loss       : 0.951368
2024-03-31 22:32:01,346 - trainer - INFO -     val_accuracy   : 0.696272
2024-03-31 22:32:01,346 - trainer - INFO -     val_macro_f    : 0.6885
2024-03-31 22:32:01,346 - trainer - INFO -     val_precision  : 0.715452
2024-03-31 22:32:01,346 - trainer - INFO -     val_recall     : 0.696272
2024-03-31 22:32:01,346 - trainer - INFO -     test_loss      : 0.951783
2024-03-31 22:32:01,346 - trainer - INFO -     test_accuracy  : 0.698113
2024-03-31 22:32:01,346 - trainer - INFO -     test_macro_f   : 0.689048
2024-03-31 22:32:01,346 - trainer - INFO -     test_precision : 0.713384
2024-03-31 22:32:01,346 - trainer - INFO -     test_recall    : 0.698113
2024-03-31 22:42:20,736 - trainer - INFO -     epoch          : 2
2024-03-31 22:42:20,736 - trainer - INFO -     loss           : 0.958626
2024-03-31 22:42:20,736 - trainer - INFO -     accuracy       : 0.694129
2024-03-31 22:42:20,736 - trainer - INFO -     macro_f        : 0.672786
2024-03-31 22:42:20,736 - trainer - INFO -     precision      : 0.689956
2024-03-31 22:42:20,736 - trainer - INFO -     recall         : 0.694129
2024-03-31 22:42:20,736 - trainer - INFO -     val_loss       : 0.93104
2024-03-31 22:42:20,736 - trainer - INFO -     val_accuracy   : 0.701488
2024-03-31 22:42:20,736 - trainer - INFO -     val_macro_f    : 0.693159
2024-03-31 22:42:20,736 - trainer - INFO -     val_precision  : 0.7232
2024-03-31 22:42:20,736 - trainer - INFO -     val_recall     : 0.701488
2024-03-31 22:42:20,736 - trainer - INFO -     test_loss      : 0.944234
2024-03-31 22:42:20,736 - trainer - INFO -     test_accuracy  : 0.695045
2024-03-31 22:42:20,736 - trainer - INFO -     test_macro_f   : 0.685463
2024-03-31 22:42:20,736 - trainer - INFO -     test_precision : 0.712491
2024-03-31 22:42:20,736 - trainer - INFO -     test_recall    : 0.695045
2024-03-31 22:45:50,950 - train - INFO - PretrainedBaseline(
  (model): BertForSequenceClassification(
    (bert): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(30522, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (classifier): Linear(in_features=768, out_features=15, bias=True)
  )
)
Trainable params: 31,527,183
Freeze params: 0
2024-03-31 23:02:27,177 - trainer - INFO -     epoch          : 1
2024-03-31 23:02:27,177 - trainer - INFO -     loss           : 0.875312
2024-03-31 23:02:27,177 - trainer - INFO -     accuracy       : 0.714379
2024-03-31 23:02:27,177 - trainer - INFO -     macro_f        : 0.695221
2024-03-31 23:02:27,177 - trainer - INFO -     precision      : 0.713927
2024-03-31 23:02:27,177 - trainer - INFO -     recall         : 0.714379
2024-03-31 23:02:27,177 - trainer - INFO -     val_loss       : 0.705725
2024-03-31 23:02:27,177 - trainer - INFO -     val_accuracy   : 0.758552
2024-03-31 23:02:27,177 - trainer - INFO -     val_macro_f    : 0.758612
2024-03-31 23:02:27,177 - trainer - INFO -     val_precision  : 0.794082
2024-03-31 23:02:27,177 - trainer - INFO -     val_recall     : 0.758552
2024-03-31 23:02:27,177 - trainer - INFO -     test_loss      : 0.694614
2024-03-31 23:02:27,177 - trainer - INFO -     test_accuracy  : 0.762847
2024-03-31 23:02:27,177 - trainer - INFO -     test_macro_f   : 0.763938
2024-03-31 23:02:27,193 - trainer - INFO -     test_precision : 0.799857
2024-03-31 23:02:27,193 - trainer - INFO -     test_recall    : 0.762847
2024-04-07 15:41:57,254 - train - INFO - PretrainedBaseline(
  (model): XLNetForSequenceClassification(
    (transformer): XLNetModel(
      (word_embedding): Embedding(32000, 768)
      (layer): ModuleList(
        (0): XLNetLayer(
          (rel_attn): XLNetRelativeAttention(
            (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (ff): XLNetFeedForward(
            (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (layer_1): Linear(in_features=768, out_features=3072, bias=True)
            (layer_2): Linear(in_features=3072, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (activation_function): GELUActivation()
          )
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (sequence_summary): SequenceSummary(
      (summary): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
      (first_dropout): Identity()
      (last_dropout): Dropout(p=0.1, inplace=False)
    )
    (logits_proj): Linear(in_features=768, out_features=15, bias=True)
  )
)
Trainable params: 32,857,359
Freeze params: 0
2024-04-07 15:51:48,687 - trainer - INFO -     epoch          : 1
2024-04-07 15:51:48,687 - trainer - INFO -     loss           : 0.793223
2024-04-07 15:51:48,687 - trainer - INFO -     accuracy       : 0.737092
2024-04-07 15:51:48,687 - trainer - INFO -     macro_f        : 0.720515
2024-04-07 15:51:48,687 - trainer - INFO -     precision      : 0.73884
2024-04-07 15:51:48,687 - trainer - INFO -     recall         : 0.737092
2024-04-07 15:51:48,687 - trainer - INFO -     val_loss       : 0.657343
2024-04-07 15:51:48,687 - trainer - INFO -     val_accuracy   : 0.772434
2024-04-07 15:51:48,687 - trainer - INFO -     val_macro_f    : 0.768147
2024-04-07 15:51:48,687 - trainer - INFO -     val_precision  : 0.794322
2024-04-07 15:51:48,687 - trainer - INFO -     val_recall     : 0.772434
2024-04-07 15:51:48,687 - trainer - INFO -     test_loss      : 0.65084
2024-04-07 15:51:48,687 - trainer - INFO -     test_accuracy  : 0.778264
2024-04-07 15:51:48,687 - trainer - INFO -     test_macro_f   : 0.775423
2024-04-07 15:51:48,687 - trainer - INFO -     test_precision : 0.801558
2024-04-07 15:51:48,687 - trainer - INFO -     test_recall    : 0.778264
2024-04-07 16:01:44,203 - trainer - INFO -     epoch          : 2
2024-04-07 16:01:44,203 - trainer - INFO -     loss           : 0.564185
2024-04-07 16:01:44,203 - trainer - INFO -     accuracy       : 0.807064
2024-04-07 16:01:44,203 - trainer - INFO -     macro_f        : 0.801044
2024-04-07 16:01:44,203 - trainer - INFO -     precision      : 0.823798
2024-04-07 16:01:44,203 - trainer - INFO -     recall         : 0.807064
2024-04-07 16:01:44,203 - trainer - INFO -     val_loss       : 0.627859
2024-04-07 16:01:44,203 - trainer - INFO -     val_accuracy   : 0.784169
2024-04-07 16:01:44,203 - trainer - INFO -     val_macro_f    : 0.780788
2024-04-07 16:01:44,203 - trainer - INFO -     val_precision  : 0.807018
2024-04-07 16:01:44,203 - trainer - INFO -     val_recall     : 0.784169
2024-04-07 16:01:44,219 - trainer - INFO -     test_loss      : 0.62032
2024-04-07 16:01:44,219 - trainer - INFO -     test_accuracy  : 0.790075
2024-04-07 16:01:44,219 - trainer - INFO -     test_macro_f   : 0.785467
2024-04-07 16:01:44,219 - trainer - INFO -     test_precision : 0.807683
2024-04-07 16:01:44,219 - trainer - INFO -     test_recall    : 0.790075
2024-04-07 16:11:40,694 - trainer - INFO -     epoch          : 3
2024-04-07 16:11:40,694 - trainer - INFO -     loss           : 0.441405
2024-04-07 16:11:40,694 - trainer - INFO -     accuracy       : 0.847707
2024-04-07 16:11:40,694 - trainer - INFO -     macro_f        : 0.843636
2024-04-07 16:11:40,694 - trainer - INFO -     precision      : 0.864304
2024-04-07 16:11:40,694 - trainer - INFO -     recall         : 0.847707
2024-04-07 16:11:40,694 - trainer - INFO -     val_loss       : 0.652428
2024-04-07 16:11:40,694 - trainer - INFO -     val_accuracy   : 0.784093
2024-04-07 16:11:40,694 - trainer - INFO -     val_macro_f    : 0.783527
2024-04-07 16:11:40,694 - trainer - INFO -     val_precision  : 0.812566
2024-04-07 16:11:40,710 - trainer - INFO -     val_recall     : 0.784093
2024-04-07 16:11:40,710 - trainer - INFO -     test_loss      : 0.643235
2024-04-07 16:11:40,710 - trainer - INFO -     test_accuracy  : 0.790996
2024-04-07 16:11:40,710 - trainer - INFO -     test_macro_f   : 0.789222
2024-04-07 16:11:40,710 - trainer - INFO -     test_precision : 0.815722
2024-04-07 16:11:40,710 - trainer - INFO -     test_recall    : 0.790996
2024-04-07 16:13:47,933 - train - INFO - PretrainedBaseline(
  (model): XLNetForSequenceClassification(
    (transformer): XLNetModel(
      (word_embedding): Embedding(32000, 768)
      (layer): ModuleList(
        (0): XLNetLayer(
          (rel_attn): XLNetRelativeAttention(
            (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (ff): XLNetFeedForward(
            (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (layer_1): Linear(in_features=768, out_features=3072, bias=True)
            (layer_2): Linear(in_features=3072, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (activation_function): GELUActivation()
          )
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (sequence_summary): SequenceSummary(
      (summary): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
      (first_dropout): Identity()
      (last_dropout): Dropout(p=0.1, inplace=False)
    )
    (logits_proj): Linear(in_features=768, out_features=15, bias=True)
  )
)
Trainable params: 32,857,359
Freeze params: 0
2024-04-07 16:23:54,784 - trainer - INFO -     epoch          : 1
2024-04-07 16:23:54,784 - trainer - INFO -     loss           : 0.795575
2024-04-07 16:23:54,784 - trainer - INFO -     accuracy       : 0.736028
2024-04-07 16:23:54,784 - trainer - INFO -     macro_f        : 0.718683
2024-04-07 16:23:54,784 - trainer - INFO -     precision      : 0.736712
2024-04-07 16:23:54,784 - trainer - INFO -     recall         : 0.736028
2024-04-07 16:23:54,784 - trainer - INFO -     val_loss       : 0.658179
2024-04-07 16:23:54,784 - trainer - INFO -     val_accuracy   : 0.775042
2024-04-07 16:23:54,784 - trainer - INFO -     val_macro_f    : 0.770069
2024-04-07 16:23:54,784 - trainer - INFO -     val_precision  : 0.796333
2024-04-07 16:23:54,784 - trainer - INFO -     val_recall     : 0.775042
2024-04-07 16:23:54,784 - trainer - INFO -     test_loss      : 0.649912
2024-04-07 16:23:54,784 - trainer - INFO -     test_accuracy  : 0.779184
2024-04-07 16:23:54,784 - trainer - INFO -     test_macro_f   : 0.775836
2024-04-07 16:23:54,784 - trainer - INFO -     test_precision : 0.802881
2024-04-07 16:23:54,784 - trainer - INFO -     test_recall    : 0.779184
2024-04-07 16:33:56,182 - trainer - INFO -     epoch          : 2
2024-04-07 16:33:56,182 - trainer - INFO -     loss           : 0.561643
2024-04-07 16:33:56,182 - trainer - INFO -     accuracy       : 0.808742
2024-04-07 16:33:56,182 - trainer - INFO -     macro_f        : 0.80263
2024-04-07 16:33:56,182 - trainer - INFO -     precision      : 0.825179
2024-04-07 16:33:56,182 - trainer - INFO -     recall         : 0.808742
2024-04-07 16:33:56,182 - trainer - INFO -     val_loss       : 0.636502
2024-04-07 16:33:56,182 - trainer - INFO -     val_accuracy   : 0.783863
2024-04-07 16:33:56,182 - trainer - INFO -     val_macro_f    : 0.779877
2024-04-07 16:33:56,182 - trainer - INFO -     val_precision  : 0.806005
2024-04-07 16:33:56,182 - trainer - INFO -     val_recall     : 0.783863
2024-04-07 16:33:56,182 - trainer - INFO -     test_loss      : 0.627956
2024-04-07 16:33:56,182 - trainer - INFO -     test_accuracy  : 0.791226
2024-04-07 16:33:56,182 - trainer - INFO -     test_macro_f   : 0.788807
2024-04-07 16:33:56,198 - trainer - INFO -     test_precision : 0.815206
2024-04-07 16:33:56,198 - trainer - INFO -     test_recall    : 0.791226
2024-04-07 16:44:09,038 - trainer - INFO -     epoch          : 3
2024-04-07 16:44:09,038 - trainer - INFO -     loss           : 0.438329
2024-04-07 16:44:09,045 - trainer - INFO -     accuracy       : 0.84857
2024-04-07 16:44:09,046 - trainer - INFO -     macro_f        : 0.844749
2024-04-07 16:44:09,046 - trainer - INFO -     precision      : 0.865491
2024-04-07 16:44:09,046 - trainer - INFO -     recall         : 0.84857
2024-04-07 16:44:09,046 - trainer - INFO -     val_loss       : 0.668073
2024-04-07 16:44:09,047 - trainer - INFO -     val_accuracy   : 0.784706
2024-04-07 16:44:09,047 - trainer - INFO -     val_macro_f    : 0.784818
2024-04-07 16:44:09,047 - trainer - INFO -     val_precision  : 0.814386
2024-04-07 16:44:09,047 - trainer - INFO -     val_recall     : 0.784706
2024-04-07 16:44:09,048 - trainer - INFO -     test_loss      : 0.654901
2024-04-07 16:44:09,048 - trainer - INFO -     test_accuracy  : 0.791456
2024-04-07 16:44:09,048 - trainer - INFO -     test_macro_f   : 0.792095
2024-04-07 16:44:09,048 - trainer - INFO -     test_precision : 0.82132
2024-04-07 16:44:09,048 - trainer - INFO -     test_recall    : 0.791456
2024-04-07 16:46:21,791 - train - INFO - PretrainedBaseline(
  (model): XLNetForSequenceClassification(
    (transformer): XLNetModel(
      (word_embedding): Embedding(32000, 768)
      (layer): ModuleList(
        (0): XLNetLayer(
          (rel_attn): XLNetRelativeAttention(
            (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (ff): XLNetFeedForward(
            (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (layer_1): Linear(in_features=768, out_features=3072, bias=True)
            (layer_2): Linear(in_features=3072, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (activation_function): GELUActivation()
          )
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (sequence_summary): SequenceSummary(
      (summary): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
      (first_dropout): Identity()
      (last_dropout): Dropout(p=0.1, inplace=False)
    )
    (logits_proj): Linear(in_features=768, out_features=15, bias=True)
  )
)
Trainable params: 32,857,359
Freeze params: 0
2024-04-07 16:56:48,700 - trainer - INFO -     epoch          : 1
2024-04-07 16:56:48,700 - trainer - INFO -     loss           : 0.792884
2024-04-07 16:56:48,700 - trainer - INFO -     accuracy       : 0.736124
2024-04-07 16:56:48,700 - trainer - INFO -     macro_f        : 0.720057
2024-04-07 16:56:48,700 - trainer - INFO -     precision      : 0.738432
2024-04-07 16:56:48,700 - trainer - INFO -     recall         : 0.736124
2024-04-07 16:56:48,700 - trainer - INFO -     val_loss       : 0.66642
2024-04-07 16:56:48,700 - trainer - INFO -     val_accuracy   : 0.767909
2024-04-07 16:56:48,700 - trainer - INFO -     val_macro_f    : 0.764891
2024-04-07 16:56:48,700 - trainer - INFO -     val_precision  : 0.79681
2024-04-07 16:56:48,700 - trainer - INFO -     val_recall     : 0.767909
2024-04-07 16:56:48,700 - trainer - INFO -     test_loss      : 0.654193
2024-04-07 16:56:48,700 - trainer - INFO -     test_accuracy  : 0.774735
2024-04-07 16:56:48,700 - trainer - INFO -     test_macro_f   : 0.771718
2024-04-07 16:56:48,700 - trainer - INFO -     test_precision : 0.800459
2024-04-07 16:56:48,700 - trainer - INFO -     test_recall    : 0.774735
2024-04-07 17:07:04,041 - trainer - INFO -     epoch          : 2
2024-04-07 17:07:04,041 - trainer - INFO -     loss           : 0.564561
2024-04-07 17:07:04,041 - trainer - INFO -     accuracy       : 0.807333
2024-04-07 17:07:04,041 - trainer - INFO -     macro_f        : 0.801411
2024-04-07 17:07:04,041 - trainer - INFO -     precision      : 0.824935
2024-04-07 17:07:04,041 - trainer - INFO -     recall         : 0.807333
2024-04-07 17:07:04,041 - trainer - INFO -     val_loss       : 0.625026
2024-04-07 17:07:04,041 - trainer - INFO -     val_accuracy   : 0.783249
2024-04-07 17:07:04,041 - trainer - INFO -     val_macro_f    : 0.774115
2024-04-07 17:07:04,041 - trainer - INFO -     val_precision  : 0.797378
2024-04-07 17:07:04,056 - trainer - INFO -     val_recall     : 0.783249
2024-04-07 17:07:04,056 - trainer - INFO -     test_loss      : 0.624635
2024-04-07 17:07:04,056 - trainer - INFO -     test_accuracy  : 0.787621
2024-04-07 17:07:04,056 - trainer - INFO -     test_macro_f   : 0.780164
2024-04-07 17:07:04,056 - trainer - INFO -     test_precision : 0.80423
2024-04-07 17:07:04,056 - trainer - INFO -     test_recall    : 0.787621
2024-04-07 17:17:27,493 - trainer - INFO -     epoch          : 3
2024-04-07 17:17:27,494 - trainer - INFO -     loss           : 0.439213
2024-04-07 17:17:27,494 - trainer - INFO -     accuracy       : 0.849308
2024-04-07 17:17:27,494 - trainer - INFO -     macro_f        : 0.845491
2024-04-07 17:17:27,494 - trainer - INFO -     precision      : 0.866188
2024-04-07 17:17:27,495 - trainer - INFO -     recall         : 0.849308
2024-04-07 17:17:27,495 - trainer - INFO -     val_loss       : 0.663432
2024-04-07 17:17:27,495 - trainer - INFO -     val_accuracy   : 0.783863
2024-04-07 17:17:27,495 - trainer - INFO -     val_macro_f    : 0.782576
2024-04-07 17:17:27,496 - trainer - INFO -     val_precision  : 0.810407
2024-04-07 17:17:27,496 - trainer - INFO -     val_recall     : 0.783863
2024-04-07 17:17:27,496 - trainer - INFO -     test_loss      : 0.654934
2024-04-07 17:17:27,496 - trainer - INFO -     test_accuracy  : 0.789615
2024-04-07 17:17:27,497 - trainer - INFO -     test_macro_f   : 0.788197
2024-04-07 17:17:27,497 - trainer - INFO -     test_precision : 0.816753
2024-04-07 17:17:27,497 - trainer - INFO -     test_recall    : 0.789615
2024-04-07 17:19:41,108 - train - INFO - PretrainedBaseline(
  (model): XLNetForSequenceClassification(
    (transformer): XLNetModel(
      (word_embedding): Embedding(32000, 768)
      (layer): ModuleList(
        (0): XLNetLayer(
          (rel_attn): XLNetRelativeAttention(
            (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (ff): XLNetFeedForward(
            (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (layer_1): Linear(in_features=768, out_features=3072, bias=True)
            (layer_2): Linear(in_features=3072, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (activation_function): GELUActivation()
          )
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (sequence_summary): SequenceSummary(
      (summary): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
      (first_dropout): Identity()
      (last_dropout): Dropout(p=0.1, inplace=False)
    )
    (logits_proj): Linear(in_features=768, out_features=15, bias=True)
  )
)
Trainable params: 32,857,359
Freeze params: 0
2024-04-07 17:30:02,624 - trainer - INFO -     epoch          : 1
2024-04-07 17:30:02,624 - trainer - INFO -     loss           : 0.795533
2024-04-07 17:30:02,624 - trainer - INFO -     accuracy       : 0.734724
2024-04-07 17:30:02,624 - trainer - INFO -     macro_f        : 0.717845
2024-04-07 17:30:02,624 - trainer - INFO -     precision      : 0.73594
2024-04-07 17:30:02,624 - trainer - INFO -     recall         : 0.734724
2024-04-07 17:30:02,624 - trainer - INFO -     val_loss       : 0.647247
2024-04-07 17:30:02,624 - trainer - INFO -     val_accuracy   : 0.776499
2024-04-07 17:30:02,624 - trainer - INFO -     val_macro_f    : 0.774243
2024-04-07 17:30:02,624 - trainer - INFO -     val_precision  : 0.803182
2024-04-07 17:30:02,624 - trainer - INFO -     val_recall     : 0.776499
2024-04-07 17:30:02,624 - trainer - INFO -     test_loss      : 0.641714
2024-04-07 17:30:02,624 - trainer - INFO -     test_accuracy  : 0.778264
2024-04-07 17:30:02,624 - trainer - INFO -     test_macro_f   : 0.776774
2024-04-07 17:30:02,624 - trainer - INFO -     test_precision : 0.803895
2024-04-07 17:30:02,624 - trainer - INFO -     test_recall    : 0.778264
2024-04-07 17:40:09,282 - trainer - INFO -     epoch          : 2
2024-04-07 17:40:09,282 - trainer - INFO -     loss           : 0.56306
2024-04-07 17:40:09,282 - trainer - INFO -     accuracy       : 0.807218
2024-04-07 17:40:09,282 - trainer - INFO -     macro_f        : 0.800835
2024-04-07 17:40:09,282 - trainer - INFO -     precision      : 0.824205
2024-04-07 17:40:09,282 - trainer - INFO -     recall         : 0.807218
2024-04-07 17:40:09,282 - trainer - INFO -     val_loss       : 0.637115
2024-04-07 17:40:09,282 - trainer - INFO -     val_accuracy   : 0.783786
2024-04-07 17:40:09,282 - trainer - INFO -     val_macro_f    : 0.772048
2024-04-07 17:40:09,282 - trainer - INFO -     val_precision  : 0.791976
2024-04-07 17:40:09,282 - trainer - INFO -     val_recall     : 0.783786
2024-04-07 17:40:09,282 - trainer - INFO -     test_loss      : 0.630087
2024-04-07 17:40:09,298 - trainer - INFO -     test_accuracy  : 0.790305
2024-04-07 17:40:09,298 - trainer - INFO -     test_macro_f   : 0.779407
2024-04-07 17:40:09,298 - trainer - INFO -     test_precision : 0.798469
2024-04-07 17:40:09,298 - trainer - INFO -     test_recall    : 0.790305
2024-04-07 17:50:01,962 - trainer - INFO -     epoch          : 3
2024-04-07 17:50:01,962 - trainer - INFO -     loss           : 0.438809
2024-04-07 17:50:01,962 - trainer - INFO -     accuracy       : 0.848177
2024-04-07 17:50:01,962 - trainer - INFO -     macro_f        : 0.844096
2024-04-07 17:50:01,962 - trainer - INFO -     precision      : 0.864217
2024-04-07 17:50:01,962 - trainer - INFO -     recall         : 0.848177
2024-04-07 17:50:01,962 - trainer - INFO -     val_loss       : 0.656868
2024-04-07 17:50:01,962 - trainer - INFO -     val_accuracy   : 0.785397
2024-04-07 17:50:01,962 - trainer - INFO -     val_macro_f    : 0.778981
2024-04-07 17:50:01,962 - trainer - INFO -     val_precision  : 0.804701
2024-04-07 17:50:01,962 - trainer - INFO -     val_recall     : 0.785397
2024-04-07 17:50:01,962 - trainer - INFO -     test_loss      : 0.651431
2024-04-07 17:50:01,962 - trainer - INFO -     test_accuracy  : 0.790305
2024-04-07 17:50:01,962 - trainer - INFO -     test_macro_f   : 0.782788
2024-04-07 17:50:01,962 - trainer - INFO -     test_precision : 0.803807
2024-04-07 17:50:01,962 - trainer - INFO -     test_recall    : 0.790305
2024-04-07 17:52:07,434 - train - INFO - PretrainedBaseline(
  (model): XLNetForSequenceClassification(
    (transformer): XLNetModel(
      (word_embedding): Embedding(32000, 768)
      (layer): ModuleList(
        (0): XLNetLayer(
          (rel_attn): XLNetRelativeAttention(
            (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (ff): XLNetFeedForward(
            (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (layer_1): Linear(in_features=768, out_features=3072, bias=True)
            (layer_2): Linear(in_features=3072, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (activation_function): GELUActivation()
          )
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (sequence_summary): SequenceSummary(
      (summary): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
      (first_dropout): Identity()
      (last_dropout): Dropout(p=0.1, inplace=False)
    )
    (logits_proj): Linear(in_features=768, out_features=15, bias=True)
  )
)
Trainable params: 32,857,359
Freeze params: 0
2024-04-07 18:02:02,518 - trainer - INFO -     epoch          : 1
2024-04-07 18:02:02,531 - trainer - INFO -     loss           : 0.79411
2024-04-07 18:02:02,531 - trainer - INFO -     accuracy       : 0.736632
2024-04-07 18:02:02,531 - trainer - INFO -     macro_f        : 0.719684
2024-04-07 18:02:02,531 - trainer - INFO -     precision      : 0.737704
2024-04-07 18:02:02,532 - trainer - INFO -     recall         : 0.736632
2024-04-07 18:02:02,532 - trainer - INFO -     val_loss       : 0.64665
2024-04-07 18:02:02,533 - trainer - INFO -     val_accuracy   : 0.778724
2024-04-07 18:02:02,533 - trainer - INFO -     val_macro_f    : 0.771544
2024-04-07 18:02:02,533 - trainer - INFO -     val_precision  : 0.796178
2024-04-07 18:02:02,533 - trainer - INFO -     val_recall     : 0.778724
2024-04-07 18:02:02,533 - trainer - INFO -     test_loss      : 0.644172
2024-04-07 18:02:02,533 - trainer - INFO -     test_accuracy  : 0.778877
2024-04-07 18:02:02,533 - trainer - INFO -     test_macro_f   : 0.771962
2024-04-07 18:02:02,533 - trainer - INFO -     test_precision : 0.794362
2024-04-07 18:02:02,533 - trainer - INFO -     test_recall    : 0.778877
2024-04-07 18:11:15,030 - train - INFO - PretrainedBaseline(
  (model): XLNetForSequenceClassification(
    (transformer): XLNetModel(
      (word_embedding): Embedding(32000, 768)
      (layer): ModuleList(
        (0): XLNetLayer(
          (rel_attn): XLNetRelativeAttention(
            (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (ff): XLNetFeedForward(
            (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (layer_1): Linear(in_features=768, out_features=3072, bias=True)
            (layer_2): Linear(in_features=3072, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (activation_function): GELUActivation()
          )
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (sequence_summary): SequenceSummary(
      (summary): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
      (first_dropout): Identity()
      (last_dropout): Dropout(p=0.1, inplace=False)
    )
    (logits_proj): Linear(in_features=768, out_features=15, bias=True)
  )
)
Trainable params: 32,857,359
Freeze params: 0
2024-04-07 18:37:13,265 - trainer - INFO -     epoch          : 1
2024-04-07 18:37:13,265 - trainer - INFO -     loss           : 0.751269
2024-04-07 18:37:13,265 - trainer - INFO -     accuracy       : 0.747984
2024-04-07 18:37:13,265 - trainer - INFO -     macro_f        : 0.733461
2024-04-07 18:37:13,265 - trainer - INFO -     precision      : 0.753103
2024-04-07 18:37:13,265 - trainer - INFO -     recall         : 0.747984
2024-04-07 18:37:13,265 - trainer - INFO -     val_loss       : 0.613662
2024-04-07 18:37:13,265 - trainer - INFO -     val_accuracy   : 0.784169
2024-04-07 18:37:13,265 - trainer - INFO -     val_macro_f    : 0.777852
2024-04-07 18:37:13,265 - trainer - INFO -     val_precision  : 0.803201
2024-04-07 18:37:13,265 - trainer - INFO -     val_recall     : 0.784169
2024-04-07 18:37:13,265 - trainer - INFO -     test_loss      : 0.605976
2024-04-07 18:37:13,265 - trainer - INFO -     test_accuracy  : 0.790919
2024-04-07 18:37:13,265 - trainer - INFO -     test_macro_f   : 0.785871
2024-04-07 18:37:13,265 - trainer - INFO -     test_precision : 0.808935
2024-04-07 18:37:13,265 - trainer - INFO -     test_recall    : 0.790919
2024-04-07 19:03:07,304 - trainer - INFO -     epoch          : 2
2024-04-07 19:03:07,304 - trainer - INFO -     loss           : 0.52393
2024-04-07 19:03:07,304 - trainer - INFO -     accuracy       : 0.818474
2024-04-07 19:03:07,304 - trainer - INFO -     macro_f        : 0.813562
2024-04-07 19:03:07,304 - trainer - INFO -     precision      : 0.836318
2024-04-07 19:03:07,304 - trainer - INFO -     recall         : 0.818474
2024-04-07 19:03:07,304 - trainer - INFO -     val_loss       : 0.579077
2024-04-07 19:03:07,304 - trainer - INFO -     val_accuracy   : 0.799893
2024-04-07 19:03:07,304 - trainer - INFO -     val_macro_f    : 0.796643
2024-04-07 19:03:07,304 - trainer - INFO -     val_precision  : 0.822392
2024-04-07 19:03:07,304 - trainer - INFO -     val_recall     : 0.799893
2024-04-07 19:03:07,304 - trainer - INFO -     test_loss      : 0.571022
2024-04-07 19:03:07,304 - trainer - INFO -     test_accuracy  : 0.806412
2024-04-07 19:03:07,304 - trainer - INFO -     test_macro_f   : 0.803192
2024-04-07 19:03:07,304 - trainer - INFO -     test_precision : 0.826466
2024-04-07 19:03:07,304 - trainer - INFO -     test_recall    : 0.806412
2024-04-07 19:29:41,832 - trainer - INFO -     epoch          : 3
2024-04-07 19:29:41,832 - trainer - INFO -     loss           : 0.403585
2024-04-07 19:29:41,832 - trainer - INFO -     accuracy       : 0.860008
2024-04-07 19:29:41,832 - trainer - INFO -     macro_f        : 0.857257
2024-04-07 19:29:41,832 - trainer - INFO -     precision      : 0.877396
2024-04-07 19:29:41,832 - trainer - INFO -     recall         : 0.860008
2024-04-07 19:29:41,832 - trainer - INFO -     val_loss       : 0.614406
2024-04-07 19:29:41,832 - trainer - INFO -     val_accuracy   : 0.796595
2024-04-07 19:29:41,848 - trainer - INFO -     val_macro_f    : 0.795879
2024-04-07 19:29:41,848 - trainer - INFO -     val_precision  : 0.823537
2024-04-07 19:29:41,848 - trainer - INFO -     val_recall     : 0.796595
2024-04-07 19:29:41,848 - trainer - INFO -     test_loss      : 0.600908
2024-04-07 19:29:41,848 - trainer - INFO -     test_accuracy  : 0.803958
2024-04-07 19:29:41,848 - trainer - INFO -     test_macro_f   : 0.804435
2024-04-07 19:29:41,848 - trainer - INFO -     test_precision : 0.832858
2024-04-07 19:29:41,848 - trainer - INFO -     test_recall    : 0.803958
2024-04-07 19:33:09,206 - train - INFO - PretrainedBaseline(
  (model): XLNetForSequenceClassification(
    (transformer): XLNetModel(
      (word_embedding): Embedding(32000, 768)
      (layer): ModuleList(
        (0): XLNetLayer(
          (rel_attn): XLNetRelativeAttention(
            (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (ff): XLNetFeedForward(
            (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (layer_1): Linear(in_features=768, out_features=3072, bias=True)
            (layer_2): Linear(in_features=3072, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (activation_function): GELUActivation()
          )
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (sequence_summary): SequenceSummary(
      (summary): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
      (first_dropout): Identity()
      (last_dropout): Dropout(p=0.1, inplace=False)
    )
    (logits_proj): Linear(in_features=768, out_features=15, bias=True)
  )
)
Trainable params: 32,857,359
Freeze params: 0
2024-04-07 19:59:10,318 - trainer - INFO -     epoch          : 1
2024-04-07 19:59:10,318 - trainer - INFO -     loss           : 0.749638
2024-04-07 19:59:10,318 - trainer - INFO -     accuracy       : 0.74808
2024-04-07 19:59:10,318 - trainer - INFO -     macro_f        : 0.733321
2024-04-07 19:59:10,318 - trainer - INFO -     precision      : 0.752744
2024-04-07 19:59:10,318 - trainer - INFO -     recall         : 0.74808
2024-04-07 19:59:10,318 - trainer - INFO -     val_loss       : 0.614875
2024-04-07 19:59:10,318 - trainer - INFO -     val_accuracy   : 0.784936
2024-04-07 19:59:10,318 - trainer - INFO -     val_macro_f    : 0.782825
2024-04-07 19:59:10,318 - trainer - INFO -     val_precision  : 0.812785
2024-04-07 19:59:10,318 - trainer - INFO -     val_recall     : 0.784936
2024-04-07 19:59:10,318 - trainer - INFO -     test_loss      : 0.60849
2024-04-07 19:59:10,318 - trainer - INFO -     test_accuracy  : 0.787851
2024-04-07 19:59:10,333 - trainer - INFO -     test_macro_f   : 0.786753
2024-04-07 19:59:10,333 - trainer - INFO -     test_precision : 0.816877
2024-04-07 19:59:10,333 - trainer - INFO -     test_recall    : 0.787851
2024-04-07 20:25:11,086 - trainer - INFO -     epoch          : 2
2024-04-07 20:25:11,086 - trainer - INFO -     loss           : 0.523641
2024-04-07 20:25:11,086 - trainer - INFO -     accuracy       : 0.819461
2024-04-07 20:25:11,086 - trainer - INFO -     macro_f        : 0.814582
2024-04-07 20:25:11,086 - trainer - INFO -     precision      : 0.837155
2024-04-07 20:25:11,086 - trainer - INFO -     recall         : 0.819461
2024-04-07 20:25:11,086 - trainer - INFO -     val_loss       : 0.581875
2024-04-07 20:25:11,086 - trainer - INFO -     val_accuracy   : 0.798435
2024-04-07 20:25:11,086 - trainer - INFO -     val_macro_f    : 0.795161
2024-04-07 20:25:11,086 - trainer - INFO -     val_precision  : 0.821689
2024-04-07 20:25:11,086 - trainer - INFO -     val_recall     : 0.798435
2024-04-07 20:25:11,086 - trainer - INFO -     test_loss      : 0.57177
2024-04-07 20:25:11,086 - trainer - INFO -     test_accuracy  : 0.806182
2024-04-07 20:25:11,086 - trainer - INFO -     test_macro_f   : 0.803844
2024-04-07 20:25:11,086 - trainer - INFO -     test_precision : 0.829314
2024-04-07 20:25:11,086 - trainer - INFO -     test_recall    : 0.806182
2024-04-07 20:51:06,298 - trainer - INFO -     epoch          : 3
2024-04-07 20:51:06,298 - trainer - INFO -     loss           : 0.400841
2024-04-07 20:51:06,298 - trainer - INFO -     accuracy       : 0.860612
2024-04-07 20:51:06,298 - trainer - INFO -     macro_f        : 0.857892
2024-04-07 20:51:06,298 - trainer - INFO -     precision      : 0.878186
2024-04-07 20:51:06,298 - trainer - INFO -     recall         : 0.860612
2024-04-07 20:51:06,298 - trainer - INFO -     val_loss       : 0.618127
2024-04-07 20:51:06,298 - trainer - INFO -     val_accuracy   : 0.797055
2024-04-07 20:51:06,313 - trainer - INFO -     val_macro_f    : 0.798954
2024-04-07 20:51:06,313 - trainer - INFO -     val_precision  : 0.828923
2024-04-07 20:51:06,313 - trainer - INFO -     val_recall     : 0.797055
2024-04-07 20:51:06,313 - trainer - INFO -     test_loss      : 0.605769
2024-04-07 20:51:06,313 - trainer - INFO -     test_accuracy  : 0.804571
2024-04-07 20:51:06,313 - trainer - INFO -     test_macro_f   : 0.805777
2024-04-07 20:51:06,313 - trainer - INFO -     test_precision : 0.834321
2024-04-07 20:51:06,313 - trainer - INFO -     test_recall    : 0.804571
2024-04-07 20:54:34,538 - train - INFO - PretrainedBaseline(
  (model): XLNetForSequenceClassification(
    (transformer): XLNetModel(
      (word_embedding): Embedding(32000, 768)
      (layer): ModuleList(
        (0): XLNetLayer(
          (rel_attn): XLNetRelativeAttention(
            (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (ff): XLNetFeedForward(
            (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (layer_1): Linear(in_features=768, out_features=3072, bias=True)
            (layer_2): Linear(in_features=3072, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (activation_function): GELUActivation()
          )
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (sequence_summary): SequenceSummary(
      (summary): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
      (first_dropout): Identity()
      (last_dropout): Dropout(p=0.1, inplace=False)
    )
    (logits_proj): Linear(in_features=768, out_features=15, bias=True)
  )
)
Trainable params: 32,857,359
Freeze params: 0
2024-04-07 21:21:13,621 - trainer - INFO -     epoch          : 1
2024-04-07 21:21:13,621 - trainer - INFO -     loss           : 0.751842
2024-04-07 21:21:13,636 - trainer - INFO -     accuracy       : 0.746814
2024-04-07 21:21:13,636 - trainer - INFO -     macro_f        : 0.731991
2024-04-07 21:21:13,636 - trainer - INFO -     precision      : 0.750134
2024-04-07 21:21:13,636 - trainer - INFO -     recall         : 0.746814
2024-04-07 21:21:13,636 - trainer - INFO -     val_loss       : 0.616922
2024-04-07 21:21:13,636 - trainer - INFO -     val_accuracy   : 0.782789
2024-04-07 21:21:13,636 - trainer - INFO -     val_macro_f    : 0.782434
2024-04-07 21:21:13,636 - trainer - INFO -     val_precision  : 0.815817
2024-04-07 21:21:13,636 - trainer - INFO -     val_recall     : 0.782789
2024-04-07 21:21:13,636 - trainer - INFO -     test_loss      : 0.602184
2024-04-07 21:21:13,636 - trainer - INFO -     test_accuracy  : 0.791456
2024-04-07 21:21:13,636 - trainer - INFO -     test_macro_f   : 0.791227
2024-04-07 21:21:13,636 - trainer - INFO -     test_precision : 0.821605
2024-04-07 21:21:13,636 - trainer - INFO -     test_recall    : 0.791456
2024-04-07 21:25:01,829 - train - INFO - PretrainedBaseline(
  (model): BertForSequenceClassification(
    (bert): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(30522, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (classifier): Linear(in_features=768, out_features=15, bias=True)
  )
)
Trainable params: 31,527,183
Freeze params: 0
2024-04-07 21:41:49,205 - trainer - INFO -     epoch          : 1
2024-04-07 21:41:49,205 - trainer - INFO -     loss           : 0.758295
2024-04-07 21:41:49,205 - trainer - INFO -     accuracy       : 0.74553
2024-04-07 21:41:49,205 - trainer - INFO -     macro_f        : 0.730965
2024-04-07 21:41:49,205 - trainer - INFO -     precision      : 0.750856
2024-04-07 21:41:49,205 - trainer - INFO -     recall         : 0.74553
2024-04-07 21:41:49,205 - trainer - INFO -     val_loss       : 0.606952
2024-04-07 21:41:49,205 - trainer - INFO -     val_accuracy   : 0.785703
2024-04-07 21:41:49,205 - trainer - INFO -     val_macro_f    : 0.776355
2024-04-07 21:41:49,205 - trainer - INFO -     val_precision  : 0.796898
2024-04-07 21:41:49,205 - trainer - INFO -     val_recall     : 0.785703
2024-04-07 21:41:49,205 - trainer - INFO -     test_loss      : 0.6044
2024-04-07 21:41:49,205 - trainer - INFO -     test_accuracy  : 0.791839
2024-04-07 21:41:49,205 - trainer - INFO -     test_macro_f   : 0.784608
2024-04-07 21:41:49,205 - trainer - INFO -     test_precision : 0.807117
2024-04-07 21:41:49,205 - trainer - INFO -     test_recall    : 0.791839
2024-04-07 21:58:28,917 - trainer - INFO -     epoch          : 2
2024-04-07 21:58:28,917 - trainer - INFO -     loss           : 0.513233
2024-04-07 21:58:28,932 - trainer - INFO -     accuracy       : 0.82159
2024-04-07 21:58:28,932 - trainer - INFO -     macro_f        : 0.817489
2024-04-07 21:58:28,932 - trainer - INFO -     precision      : 0.840975
2024-04-07 21:58:28,932 - trainer - INFO -     recall         : 0.82159
2024-04-07 21:58:28,932 - trainer - INFO -     val_loss       : 0.579785
2024-04-07 21:58:28,932 - trainer - INFO -     val_accuracy   : 0.80043
2024-04-07 21:58:28,932 - trainer - INFO -     val_macro_f    : 0.789277
2024-04-07 21:58:28,932 - trainer - INFO -     val_precision  : 0.810735
2024-04-07 21:58:28,932 - trainer - INFO -     val_recall     : 0.80043
2024-04-07 21:58:28,932 - trainer - INFO -     test_loss      : 0.57751
2024-04-07 21:58:28,932 - trainer - INFO -     test_accuracy  : 0.8025
2024-04-07 21:58:28,932 - trainer - INFO -     test_macro_f   : 0.790194
2024-04-07 21:58:28,932 - trainer - INFO -     test_precision : 0.807642
2024-04-07 21:58:28,932 - trainer - INFO -     test_recall    : 0.8025
2024-04-07 22:15:07,469 - trainer - INFO -     epoch          : 3
2024-04-07 22:15:07,469 - trainer - INFO -     loss           : 0.377987
2024-04-07 22:15:07,469 - trainer - INFO -     accuracy       : 0.867151
2024-04-07 22:15:07,469 - trainer - INFO -     macro_f        : 0.865299
2024-04-07 22:15:07,469 - trainer - INFO -     precision      : 0.885739
2024-04-07 22:15:07,469 - trainer - INFO -     recall         : 0.867151
2024-04-07 22:15:07,469 - trainer - INFO -     val_loss       : 0.631254
2024-04-07 22:15:07,469 - trainer - INFO -     val_accuracy   : 0.793066
2024-04-07 22:15:07,469 - trainer - INFO -     val_macro_f    : 0.78418
2024-04-07 22:15:07,469 - trainer - INFO -     val_precision  : 0.804883
2024-04-07 22:15:07,469 - trainer - INFO -     val_recall     : 0.793066
2024-04-07 22:15:07,469 - trainer - INFO -     test_loss      : 0.631019
2024-04-07 22:15:07,469 - trainer - INFO -     test_accuracy  : 0.800583
2024-04-07 22:15:07,469 - trainer - INFO -     test_macro_f   : 0.793904
2024-04-07 22:15:07,469 - trainer - INFO -     test_precision : 0.817441
2024-04-07 22:15:07,469 - trainer - INFO -     test_recall    : 0.800583
2024-04-07 22:17:21,282 - train - INFO - PretrainedBaseline(
  (model): BertForSequenceClassification(
    (bert): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(30522, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (classifier): Linear(in_features=768, out_features=15, bias=True)
  )
)
Trainable params: 31,527,183
Freeze params: 0
2024-04-07 22:34:09,538 - trainer - INFO -     epoch          : 1
2024-04-07 22:34:09,538 - trainer - INFO -     loss           : 0.759282
2024-04-07 22:34:09,538 - trainer - INFO -     accuracy       : 0.745923
2024-04-07 22:34:09,538 - trainer - INFO -     macro_f        : 0.73008
2024-04-07 22:34:09,538 - trainer - INFO -     precision      : 0.748341
2024-04-07 22:34:09,538 - trainer - INFO -     recall         : 0.745923
2024-04-07 22:34:09,538 - trainer - INFO -     val_loss       : 0.614344
2024-04-07 22:34:09,538 - trainer - INFO -     val_accuracy   : 0.779874
2024-04-07 22:34:09,538 - trainer - INFO -     val_macro_f    : 0.772293
2024-04-07 22:34:09,538 - trainer - INFO -     val_precision  : 0.797058
2024-04-07 22:34:09,538 - trainer - INFO -     val_recall     : 0.779874
2024-04-07 22:34:09,538 - trainer - INFO -     test_loss      : 0.609162
2024-04-07 22:34:09,538 - trainer - INFO -     test_accuracy  : 0.786854
2024-04-07 22:34:09,538 - trainer - INFO -     test_macro_f   : 0.779305
2024-04-07 22:34:09,538 - trainer - INFO -     test_precision : 0.802531
2024-04-07 22:34:09,538 - trainer - INFO -     test_recall    : 0.786854
2024-04-07 22:50:50,101 - trainer - INFO -     epoch          : 2
2024-04-07 22:50:50,101 - trainer - INFO -     loss           : 0.512417
2024-04-07 22:50:50,101 - trainer - INFO -     accuracy       : 0.822549
2024-04-07 22:50:50,101 - trainer - INFO -     macro_f        : 0.818193
2024-04-07 22:50:50,101 - trainer - INFO -     precision      : 0.84151
2024-04-07 22:50:50,101 - trainer - INFO -     recall         : 0.822549
2024-04-07 22:50:50,101 - trainer - INFO -     val_loss       : 0.586205
2024-04-07 22:50:50,101 - trainer - INFO -     val_accuracy   : 0.79368
2024-04-07 22:50:50,101 - trainer - INFO -     val_macro_f    : 0.793727
2024-04-07 22:50:50,101 - trainer - INFO -     val_precision  : 0.821215
2024-04-07 22:50:50,101 - trainer - INFO -     val_recall     : 0.79368
2024-04-07 22:50:50,101 - trainer - INFO -     test_loss      : 0.577897
2024-04-07 22:50:50,101 - trainer - INFO -     test_accuracy  : 0.799969
2024-04-07 22:50:50,101 - trainer - INFO -     test_macro_f   : 0.800421
2024-04-07 22:50:50,101 - trainer - INFO -     test_precision : 0.829446
2024-04-07 22:50:50,101 - trainer - INFO -     test_recall    : 0.799969
2024-04-07 23:07:31,307 - trainer - INFO -     epoch          : 3
2024-04-07 23:07:31,307 - trainer - INFO -     loss           : 0.380282
2024-04-07 23:07:31,307 - trainer - INFO -     accuracy       : 0.867583
2024-04-07 23:07:31,307 - trainer - INFO -     macro_f        : 0.86613
2024-04-07 23:07:31,307 - trainer - INFO -     precision      : 0.88654
2024-04-07 23:07:31,307 - trainer - INFO -     recall         : 0.867583
2024-04-07 23:07:31,307 - trainer - INFO -     val_loss       : 0.640968
2024-04-07 23:07:31,307 - trainer - INFO -     val_accuracy   : 0.788771
2024-04-07 23:07:31,307 - trainer - INFO -     val_macro_f    : 0.786194
2024-04-07 23:07:31,307 - trainer - INFO -     val_precision  : 0.81478
2024-04-07 23:07:31,307 - trainer - INFO -     val_recall     : 0.788771
2024-04-07 23:07:31,307 - trainer - INFO -     test_loss      : 0.628304
2024-04-07 23:07:31,307 - trainer - INFO -     test_accuracy  : 0.795904
2024-04-07 23:07:31,307 - trainer - INFO -     test_macro_f   : 0.794681
2024-04-07 23:07:31,307 - trainer - INFO -     test_precision : 0.822646
2024-04-07 23:07:31,307 - trainer - INFO -     test_recall    : 0.795904
2024-04-07 23:09:45,353 - train - INFO - PretrainedBaseline(
  (model): BertForSequenceClassification(
    (bert): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(30522, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (classifier): Linear(in_features=768, out_features=15, bias=True)
  )
)
Trainable params: 31,527,183
Freeze params: 0
2024-04-07 23:26:31,668 - trainer - INFO -     epoch          : 1
2024-04-07 23:26:31,668 - trainer - INFO -     loss           : 0.763926
2024-04-07 23:26:31,668 - trainer - INFO -     accuracy       : 0.743344
2024-04-07 23:26:31,668 - trainer - INFO -     macro_f        : 0.727358
2024-04-07 23:26:31,668 - trainer - INFO -     precision      : 0.746876
2024-04-07 23:26:31,668 - trainer - INFO -     recall         : 0.743344
2024-04-07 23:26:31,668 - trainer - INFO -     val_loss       : 0.60567
2024-04-07 23:26:31,668 - trainer - INFO -     val_accuracy   : 0.788541
2024-04-07 23:26:31,668 - trainer - INFO -     val_macro_f    : 0.785982
2024-04-07 23:26:31,668 - trainer - INFO -     val_precision  : 0.813588
2024-04-07 23:26:31,668 - trainer - INFO -     val_recall     : 0.788541
2024-04-07 23:26:31,668 - trainer - INFO -     test_loss      : 0.608132
2024-04-07 23:26:31,668 - trainer - INFO -     test_accuracy  : 0.791686
2024-04-07 23:26:31,668 - trainer - INFO -     test_macro_f   : 0.788588
2024-04-07 23:26:31,668 - trainer - INFO -     test_precision : 0.813478
2024-04-07 23:26:31,668 - trainer - INFO -     test_recall    : 0.791686
2024-04-07 23:43:12,670 - trainer - INFO -     epoch          : 2
2024-04-07 23:43:12,670 - trainer - INFO -     loss           : 0.515733
2024-04-07 23:43:12,670 - trainer - INFO -     accuracy       : 0.820928
2024-04-07 23:43:12,670 - trainer - INFO -     macro_f        : 0.816286
2024-04-07 23:43:12,670 - trainer - INFO -     precision      : 0.838756
2024-04-07 23:43:12,686 - trainer - INFO -     recall         : 0.820928
2024-04-07 23:43:12,686 - trainer - INFO -     val_loss       : 0.580633
2024-04-07 23:43:12,686 - trainer - INFO -     val_accuracy   : 0.797285
2024-04-07 23:43:12,686 - trainer - INFO -     val_macro_f    : 0.793885
2024-04-07 23:43:12,686 - trainer - INFO -     val_precision  : 0.818094
2024-04-07 23:43:12,686 - trainer - INFO -     val_recall     : 0.797285
2024-04-07 23:43:12,686 - trainer - INFO -     test_loss      : 0.585109
2024-04-07 23:43:12,686 - trainer - INFO -     test_accuracy  : 0.798282
2024-04-07 23:43:12,686 - trainer - INFO -     test_macro_f   : 0.796358
2024-04-07 23:43:12,686 - trainer - INFO -     test_precision : 0.821958
2024-04-07 23:43:12,686 - trainer - INFO -     test_recall    : 0.798282
2024-04-07 23:59:58,097 - trainer - INFO -     epoch          : 3
2024-04-07 23:59:58,097 - trainer - INFO -     loss           : 0.382002
2024-04-07 23:59:58,097 - trainer - INFO -     accuracy       : 0.866509
2024-04-07 23:59:58,097 - trainer - INFO -     macro_f        : 0.864255
2024-04-07 23:59:58,097 - trainer - INFO -     precision      : 0.884149
2024-04-07 23:59:58,097 - trainer - INFO -     recall         : 0.866509
2024-04-07 23:59:58,113 - trainer - INFO -     val_loss       : 0.655769
2024-04-07 23:59:58,113 - trainer - INFO -     val_accuracy   : 0.789692
2024-04-07 23:59:58,113 - trainer - INFO -     val_macro_f    : 0.78724
2024-04-07 23:59:58,113 - trainer - INFO -     val_precision  : 0.812617
2024-04-07 23:59:58,113 - trainer - INFO -     val_recall     : 0.789692
2024-04-07 23:59:58,113 - trainer - INFO -     test_loss      : 0.648405
2024-04-07 23:59:58,113 - trainer - INFO -     test_accuracy  : 0.79276
2024-04-07 23:59:58,113 - trainer - INFO -     test_macro_f   : 0.793133
2024-04-07 23:59:58,113 - trainer - INFO -     test_precision : 0.821562
2024-04-07 23:59:58,113 - trainer - INFO -     test_recall    : 0.79276
2024-04-08 00:02:14,122 - train - INFO - PretrainedBaseline(
  (model): BertForSequenceClassification(
    (bert): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(30522, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (classifier): Linear(in_features=768, out_features=15, bias=True)
  )
)
Trainable params: 31,527,183
Freeze params: 0
2024-04-08 00:19:04,978 - trainer - INFO -     epoch          : 1
2024-04-08 00:19:05,842 - trainer - INFO -     loss           : 0.756926
2024-04-08 00:19:05,842 - trainer - INFO -     accuracy       : 0.746306
2024-04-08 00:19:05,843 - trainer - INFO -     macro_f        : 0.731315
2024-04-08 00:19:05,843 - trainer - INFO -     precision      : 0.751894
2024-04-08 00:19:05,844 - trainer - INFO -     recall         : 0.746306
2024-04-08 00:19:05,844 - trainer - INFO -     val_loss       : 0.610709
2024-04-08 00:19:05,844 - trainer - INFO -     val_accuracy   : 0.785243
2024-04-08 00:19:05,844 - trainer - INFO -     val_macro_f    : 0.775696
2024-04-08 00:19:05,845 - trainer - INFO -     val_precision  : 0.796079
2024-04-08 00:19:05,845 - trainer - INFO -     val_recall     : 0.785243
2024-04-08 00:19:05,845 - trainer - INFO -     test_loss      : 0.599477
2024-04-08 00:19:05,846 - trainer - INFO -     test_accuracy  : 0.793297
2024-04-08 00:19:05,846 - trainer - INFO -     test_macro_f   : 0.784632
2024-04-08 00:19:05,846 - trainer - INFO -     test_precision : 0.806257
2024-04-08 00:19:05,846 - trainer - INFO -     test_recall    : 0.793297
2024-04-08 00:35:48,216 - trainer - INFO -     epoch          : 2
2024-04-08 00:35:48,216 - trainer - INFO -     loss           : 0.512776
2024-04-08 00:35:48,217 - trainer - INFO -     accuracy       : 0.822165
2024-04-08 00:35:48,217 - trainer - INFO -     macro_f        : 0.817792
2024-04-08 00:35:48,217 - trainer - INFO -     precision      : 0.840872
2024-04-08 00:35:48,217 - trainer - INFO -     recall         : 0.822165
2024-04-08 00:35:48,218 - trainer - INFO -     val_loss       : 0.586834
2024-04-08 00:35:48,218 - trainer - INFO -     val_accuracy   : 0.798435
2024-04-08 00:35:48,218 - trainer - INFO -     val_macro_f    : 0.790772
2024-04-08 00:35:48,219 - trainer - INFO -     val_precision  : 0.813618
2024-04-08 00:35:48,219 - trainer - INFO -     val_recall     : 0.798435
2024-04-08 00:35:48,219 - trainer - INFO -     test_loss      : 0.58419
2024-04-08 00:35:48,220 - trainer - INFO -     test_accuracy  : 0.800046
2024-04-08 00:35:48,220 - trainer - INFO -     test_macro_f   : 0.793463
2024-04-08 00:35:48,220 - trainer - INFO -     test_precision : 0.815809
2024-04-08 00:35:48,220 - trainer - INFO -     test_recall    : 0.800046
2024-04-08 00:52:37,022 - trainer - INFO -     epoch          : 3
2024-04-08 00:52:37,024 - trainer - INFO -     loss           : 0.379349
2024-04-08 00:52:37,024 - trainer - INFO -     accuracy       : 0.867659
2024-04-08 00:52:37,024 - trainer - INFO -     macro_f        : 0.865349
2024-04-08 00:52:37,024 - trainer - INFO -     precision      : 0.884716
2024-04-08 00:52:37,024 - trainer - INFO -     recall         : 0.867659
2024-04-08 00:52:37,024 - trainer - INFO -     val_loss       : 0.639774
2024-04-08 00:52:37,024 - trainer - INFO -     val_accuracy   : 0.78601
2024-04-08 00:52:37,024 - trainer - INFO -     val_macro_f    : 0.789035
2024-04-08 00:52:37,024 - trainer - INFO -     val_precision  : 0.822234
2024-04-08 00:52:37,024 - trainer - INFO -     val_recall     : 0.78601
2024-04-08 00:52:37,024 - trainer - INFO -     test_loss      : 0.631283
2024-04-08 00:52:37,024 - trainer - INFO -     test_accuracy  : 0.792146
2024-04-08 00:52:37,024 - trainer - INFO -     test_macro_f   : 0.795661
2024-04-08 00:52:37,024 - trainer - INFO -     test_precision : 0.827639
2024-04-08 00:52:37,024 - trainer - INFO -     test_recall    : 0.792146
2024-04-08 00:54:51,904 - train - INFO - PretrainedBaseline(
  (model): BertForSequenceClassification(
    (bert): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(30522, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (classifier): Linear(in_features=768, out_features=15, bias=True)
  )
)
Trainable params: 31,527,183
Freeze params: 0
2024-04-08 01:11:36,647 - trainer - INFO -     epoch          : 1
2024-04-08 01:11:36,647 - trainer - INFO -     loss           : 0.755483
2024-04-08 01:11:36,647 - trainer - INFO -     accuracy       : 0.745271
2024-04-08 01:11:36,647 - trainer - INFO -     macro_f        : 0.731156
2024-04-08 01:11:36,647 - trainer - INFO -     precision      : 0.75141
2024-04-08 01:11:36,647 - trainer - INFO -     recall         : 0.745271
2024-04-08 01:11:36,647 - trainer - INFO -     val_loss       : 0.605228
2024-04-08 01:11:36,647 - trainer - INFO -     val_accuracy   : 0.787544
2024-04-08 01:11:36,647 - trainer - INFO -     val_macro_f    : 0.775244
2024-04-08 01:11:36,647 - trainer - INFO -     val_precision  : 0.795522
2024-04-08 01:11:36,647 - trainer - INFO -     val_recall     : 0.787544
2024-04-08 01:11:36,647 - trainer - INFO -     test_loss      : 0.604755
2024-04-08 01:11:36,647 - trainer - INFO -     test_accuracy  : 0.793833
2024-04-08 01:11:36,647 - trainer - INFO -     test_macro_f   : 0.782952
2024-04-08 01:11:36,647 - trainer - INFO -     test_precision : 0.806579
2024-04-08 01:11:36,647 - trainer - INFO -     test_recall    : 0.793833
2024-04-08 01:28:21,750 - trainer - INFO -     epoch          : 2
2024-04-08 01:28:21,750 - trainer - INFO -     loss           : 0.513851
2024-04-08 01:28:21,750 - trainer - INFO -     accuracy       : 0.821782
2024-04-08 01:28:21,750 - trainer - INFO -     macro_f        : 0.81799
2024-04-08 01:28:21,750 - trainer - INFO -     precision      : 0.841193
2024-04-08 01:28:21,750 - trainer - INFO -     recall         : 0.821782
2024-04-08 01:28:21,750 - trainer - INFO -     val_loss       : 0.583639
2024-04-08 01:28:21,750 - trainer - INFO -     val_accuracy   : 0.796364
2024-04-08 01:28:21,750 - trainer - INFO -     val_macro_f    : 0.790252
2024-04-08 01:28:21,750 - trainer - INFO -     val_precision  : 0.813259
2024-04-08 01:28:21,750 - trainer - INFO -     val_recall     : 0.796364
2024-04-08 01:28:21,750 - trainer - INFO -     test_loss      : 0.57988
2024-04-08 01:28:21,750 - trainer - INFO -     test_accuracy  : 0.802961
2024-04-08 01:28:21,750 - trainer - INFO -     test_macro_f   : 0.797879
2024-04-08 01:28:21,750 - trainer - INFO -     test_precision : 0.819788
2024-04-08 01:28:21,750 - trainer - INFO -     test_recall    : 0.802961
2024-04-08 01:45:05,954 - trainer - INFO -     epoch          : 3
2024-04-08 01:45:05,954 - trainer - INFO -     loss           : 0.378379
2024-04-08 01:45:05,954 - trainer - INFO -     accuracy       : 0.867611
2024-04-08 01:45:05,954 - trainer - INFO -     macro_f        : 0.865797
2024-04-08 01:45:05,969 - trainer - INFO -     precision      : 0.885936
2024-04-08 01:45:05,969 - trainer - INFO -     recall         : 0.867611
2024-04-08 01:45:05,969 - trainer - INFO -     val_loss       : 0.621695
2024-04-08 01:45:05,969 - trainer - INFO -     val_accuracy   : 0.797975
2024-04-08 01:45:05,969 - trainer - INFO -     val_macro_f    : 0.797768
2024-04-08 01:45:05,969 - trainer - INFO -     val_precision  : 0.827381
2024-04-08 01:45:05,969 - trainer - INFO -     val_recall     : 0.797975
2024-04-08 01:45:05,969 - trainer - INFO -     test_loss      : 0.621264
2024-04-08 01:45:05,969 - trainer - INFO -     test_accuracy  : 0.798435
2024-04-08 01:45:05,969 - trainer - INFO -     test_macro_f   : 0.797897
2024-04-08 01:45:05,969 - trainer - INFO -     test_precision : 0.826511
2024-04-08 01:45:05,969 - trainer - INFO -     test_recall    : 0.798435
2024-04-08 01:49:53,540 - train - INFO - PretrainedBaseline(
  (model): RobertaForSequenceClassification(
    (roberta): RobertaModel(
      (embeddings): RobertaEmbeddings(
        (word_embeddings): Embedding(50265, 768, padding_idx=0)
        (position_embeddings): Embedding(514, 768, padding_idx=0)
        (token_type_embeddings): Embedding(1, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): RobertaEncoder(
        (layer): ModuleList(
          (0): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
    )
    (classifier): RobertaClassificationHead(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (dropout): Dropout(p=0.1, inplace=False)
      (out_proj): Linear(in_features=768, out_features=15, bias=True)
    )
  )
)
Trainable params: 46,690,575
Freeze params: 0
2024-04-08 02:07:12,536 - trainer - INFO -     epoch          : 1
2024-04-08 02:07:12,536 - trainer - INFO -     loss           : 0.724416
2024-04-08 02:07:12,536 - trainer - INFO -     accuracy       : 0.75646
2024-04-08 02:07:12,536 - trainer - INFO -     macro_f        : 0.743322
2024-04-08 02:07:12,536 - trainer - INFO -     precision      : 0.764297
2024-04-08 02:07:12,536 - trainer - INFO -     recall         : 0.75646
2024-04-08 02:07:12,536 - trainer - INFO -     val_loss       : 0.599159
2024-04-08 02:07:12,536 - trainer - INFO -     val_accuracy   : 0.788464
2024-04-08 02:07:12,536 - trainer - INFO -     val_macro_f    : 0.782773
2024-04-08 02:07:12,536 - trainer - INFO -     val_precision  : 0.807719
2024-04-08 02:07:12,536 - trainer - INFO -     val_recall     : 0.788464
2024-04-08 02:07:12,536 - trainer - INFO -     test_loss      : 0.598877
2024-04-08 02:07:12,536 - trainer - INFO -     test_accuracy  : 0.791763
2024-04-08 02:07:12,536 - trainer - INFO -     test_macro_f   : 0.786402
2024-04-08 02:07:12,536 - trainer - INFO -     test_precision : 0.809749
2024-04-08 02:07:12,536 - trainer - INFO -     test_recall    : 0.791763
2024-04-08 02:24:24,754 - trainer - INFO -     epoch          : 2
2024-04-08 02:24:24,754 - trainer - INFO -     loss           : 0.533392
2024-04-08 02:24:24,754 - trainer - INFO -     accuracy       : 0.813143
2024-04-08 02:24:24,754 - trainer - INFO -     macro_f        : 0.80775
2024-04-08 02:24:24,754 - trainer - INFO -     precision      : 0.831427
2024-04-08 02:24:24,754 - trainer - INFO -     recall         : 0.813143
2024-04-08 02:24:24,754 - trainer - INFO -     val_loss       : 0.543503
2024-04-08 02:24:24,754 - trainer - INFO -     val_accuracy   : 0.803574
2024-04-08 02:24:24,754 - trainer - INFO -     val_macro_f    : 0.802238
2024-04-08 02:24:24,754 - trainer - INFO -     val_precision  : 0.829504
2024-04-08 02:24:24,754 - trainer - INFO -     val_recall     : 0.803574
2024-04-08 02:24:24,754 - trainer - INFO -     test_loss      : 0.546719
2024-04-08 02:24:24,754 - trainer - INFO -     test_accuracy  : 0.80856
2024-04-08 02:24:24,754 - trainer - INFO -     test_macro_f   : 0.805652
2024-04-08 02:24:24,754 - trainer - INFO -     test_precision : 0.82825
2024-04-08 02:24:24,754 - trainer - INFO -     test_recall    : 0.80856
2024-04-08 02:41:36,530 - trainer - INFO -     epoch          : 3
2024-04-08 02:41:36,530 - trainer - INFO -     loss           : 0.422613
2024-04-08 02:41:36,530 - trainer - INFO -     accuracy       : 0.851581
2024-04-08 02:41:36,530 - trainer - INFO -     macro_f        : 0.84795
2024-04-08 02:41:36,530 - trainer - INFO -     precision      : 0.868615
2024-04-08 02:41:36,530 - trainer - INFO -     recall         : 0.851581
2024-04-08 02:41:36,530 - trainer - INFO -     val_loss       : 0.557589
2024-04-08 02:41:36,530 - trainer - INFO -     val_accuracy   : 0.804955
2024-04-08 02:41:36,530 - trainer - INFO -     val_macro_f    : 0.80515
2024-04-08 02:41:36,530 - trainer - INFO -     val_precision  : 0.835363
2024-04-08 02:41:36,530 - trainer - INFO -     val_recall     : 0.804955
2024-04-08 02:41:36,530 - trainer - INFO -     test_loss      : 0.558573
2024-04-08 02:41:36,530 - trainer - INFO -     test_accuracy  : 0.80925
2024-04-08 02:41:36,530 - trainer - INFO -     test_macro_f   : 0.811627
2024-04-08 02:41:36,530 - trainer - INFO -     test_precision : 0.840605
2024-04-08 02:41:36,530 - trainer - INFO -     test_recall    : 0.80925
2024-04-08 02:43:50,818 - train - INFO - PretrainedBaseline(
  (model): RobertaForSequenceClassification(
    (roberta): RobertaModel(
      (embeddings): RobertaEmbeddings(
        (word_embeddings): Embedding(50265, 768, padding_idx=0)
        (position_embeddings): Embedding(514, 768, padding_idx=0)
        (token_type_embeddings): Embedding(1, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): RobertaEncoder(
        (layer): ModuleList(
          (0): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
    )
    (classifier): RobertaClassificationHead(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (dropout): Dropout(p=0.1, inplace=False)
      (out_proj): Linear(in_features=768, out_features=15, bias=True)
    )
  )
)
Trainable params: 46,690,575
Freeze params: 0
2024-04-08 03:01:07,920 - trainer - INFO -     epoch          : 1
2024-04-08 03:01:07,920 - trainer - INFO -     loss           : 0.722514
2024-04-08 03:01:07,920 - trainer - INFO -     accuracy       : 0.755587
2024-04-08 03:01:07,920 - trainer - INFO -     macro_f        : 0.742829
2024-04-08 03:01:07,920 - trainer - INFO -     precision      : 0.764425
2024-04-08 03:01:07,920 - trainer - INFO -     recall         : 0.755587
2024-04-08 03:01:07,920 - trainer - INFO -     val_loss       : 0.596011
2024-04-08 03:01:07,920 - trainer - INFO -     val_accuracy   : 0.786087
2024-04-08 03:01:07,920 - trainer - INFO -     val_macro_f    : 0.78585
2024-04-08 03:01:07,920 - trainer - INFO -     val_precision  : 0.817001
2024-04-08 03:01:07,920 - trainer - INFO -     val_recall     : 0.786087
2024-04-08 03:01:07,920 - trainer - INFO -     test_loss      : 0.598424
2024-04-08 03:01:07,920 - trainer - INFO -     test_accuracy  : 0.792836
2024-04-08 03:01:07,920 - trainer - INFO -     test_macro_f   : 0.793583
2024-04-08 03:01:07,920 - trainer - INFO -     test_precision : 0.824558
2024-04-08 03:01:07,920 - trainer - INFO -     test_recall    : 0.792836
2024-04-08 03:18:19,960 - trainer - INFO -     epoch          : 2
2024-04-08 03:18:19,960 - trainer - INFO -     loss           : 0.531963
2024-04-08 03:18:19,960 - trainer - INFO -     accuracy       : 0.813987
2024-04-08 03:18:19,960 - trainer - INFO -     macro_f        : 0.808956
2024-04-08 03:18:19,960 - trainer - INFO -     precision      : 0.831939
2024-04-08 03:18:19,960 - trainer - INFO -     recall         : 0.813987
2024-04-08 03:18:19,960 - trainer - INFO -     val_loss       : 0.55789
2024-04-08 03:18:19,960 - trainer - INFO -     val_accuracy   : 0.798359
2024-04-08 03:18:19,960 - trainer - INFO -     val_macro_f    : 0.797713
2024-04-08 03:18:19,960 - trainer - INFO -     val_precision  : 0.827627
2024-04-08 03:18:19,960 - trainer - INFO -     val_recall     : 0.798359
2024-04-08 03:18:19,960 - trainer - INFO -     test_loss      : 0.555858
2024-04-08 03:18:19,960 - trainer - INFO -     test_accuracy  : 0.807179
2024-04-08 03:18:19,960 - trainer - INFO -     test_macro_f   : 0.806822
2024-04-08 03:18:19,960 - trainer - INFO -     test_precision : 0.835818
2024-04-08 03:18:19,960 - trainer - INFO -     test_recall    : 0.807179
2024-04-08 03:35:28,664 - trainer - INFO -     epoch          : 3
2024-04-08 03:35:28,664 - trainer - INFO -     loss           : 0.421732
2024-04-08 03:35:28,664 - trainer - INFO -     accuracy       : 0.851456
2024-04-08 03:35:28,664 - trainer - INFO -     macro_f        : 0.84836
2024-04-08 03:35:28,664 - trainer - INFO -     precision      : 0.869486
2024-04-08 03:35:28,664 - trainer - INFO -     recall         : 0.851456
2024-04-08 03:35:28,664 - trainer - INFO -     val_loss       : 0.55743
2024-04-08 03:35:28,664 - trainer - INFO -     val_accuracy   : 0.806719
2024-04-08 03:35:28,664 - trainer - INFO -     val_macro_f    : 0.805093
2024-04-08 03:35:28,664 - trainer - INFO -     val_precision  : 0.831141
2024-04-08 03:35:28,664 - trainer - INFO -     val_recall     : 0.806719
2024-04-08 03:35:28,664 - trainer - INFO -     test_loss      : 0.561085
2024-04-08 03:35:28,664 - trainer - INFO -     test_accuracy  : 0.814619
2024-04-08 03:35:28,664 - trainer - INFO -     test_macro_f   : 0.813346
2024-04-08 03:35:28,664 - trainer - INFO -     test_precision : 0.839371
2024-04-08 03:35:28,664 - trainer - INFO -     test_recall    : 0.814619
2024-04-08 03:37:42,793 - train - INFO - PretrainedBaseline(
  (model): RobertaForSequenceClassification(
    (roberta): RobertaModel(
      (embeddings): RobertaEmbeddings(
        (word_embeddings): Embedding(50265, 768, padding_idx=0)
        (position_embeddings): Embedding(514, 768, padding_idx=0)
        (token_type_embeddings): Embedding(1, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): RobertaEncoder(
        (layer): ModuleList(
          (0): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
    )
    (classifier): RobertaClassificationHead(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (dropout): Dropout(p=0.1, inplace=False)
      (out_proj): Linear(in_features=768, out_features=15, bias=True)
    )
  )
)
Trainable params: 46,690,575
Freeze params: 0
2024-04-08 03:54:54,193 - trainer - INFO -     epoch          : 1
2024-04-08 03:54:54,193 - trainer - INFO -     loss           : 0.72495
2024-04-08 03:54:54,193 - trainer - INFO -     accuracy       : 0.75622
2024-04-08 03:54:54,193 - trainer - INFO -     macro_f        : 0.743419
2024-04-08 03:54:54,193 - trainer - INFO -     precision      : 0.765003
2024-04-08 03:54:54,193 - trainer - INFO -     recall         : 0.75622
2024-04-08 03:54:54,193 - trainer - INFO -     val_loss       : 0.592866
2024-04-08 03:54:54,193 - trainer - INFO -     val_accuracy   : 0.787007
2024-04-08 03:54:54,193 - trainer - INFO -     val_macro_f    : 0.787928
2024-04-08 03:54:54,193 - trainer - INFO -     val_precision  : 0.820558
2024-04-08 03:54:54,193 - trainer - INFO -     val_recall     : 0.787007
2024-04-08 03:54:54,193 - trainer - INFO -     test_loss      : 0.591257
2024-04-08 03:54:54,193 - trainer - INFO -     test_accuracy  : 0.794294
2024-04-08 03:54:54,193 - trainer - INFO -     test_macro_f   : 0.794993
2024-04-08 03:54:54,193 - trainer - INFO -     test_precision : 0.82599
2024-04-08 03:54:54,193 - trainer - INFO -     test_recall    : 0.794294
2024-04-08 04:12:08,217 - trainer - INFO -     epoch          : 2
2024-04-08 04:12:08,217 - trainer - INFO -     loss           : 0.531219
2024-04-08 04:12:08,217 - trainer - INFO -     accuracy       : 0.814159
2024-04-08 04:12:08,217 - trainer - INFO -     macro_f        : 0.808884
2024-04-08 04:12:08,217 - trainer - INFO -     precision      : 0.831854
2024-04-08 04:12:08,217 - trainer - INFO -     recall         : 0.814159
2024-04-08 04:12:08,217 - trainer - INFO -     val_loss       : 0.541157
2024-04-08 04:12:08,217 - trainer - INFO -     val_accuracy   : 0.808636
2024-04-08 04:12:08,217 - trainer - INFO -     val_macro_f    : 0.803407
2024-04-08 04:12:08,217 - trainer - INFO -     val_precision  : 0.827685
2024-04-08 04:12:08,217 - trainer - INFO -     val_recall     : 0.808636
2024-04-08 04:12:08,217 - trainer - INFO -     test_loss      : 0.5465
2024-04-08 04:12:08,217 - trainer - INFO -     test_accuracy  : 0.810017
2024-04-08 04:12:08,217 - trainer - INFO -     test_macro_f   : 0.806211
2024-04-08 04:12:08,217 - trainer - INFO -     test_precision : 0.830409
2024-04-08 04:12:08,217 - trainer - INFO -     test_recall    : 0.810017
2024-04-08 04:29:20,851 - trainer - INFO -     epoch          : 3
2024-04-08 04:29:20,851 - trainer - INFO -     loss           : 0.421726
2024-04-08 04:29:20,851 - trainer - INFO -     accuracy       : 0.85206
2024-04-08 04:29:20,851 - trainer - INFO -     macro_f        : 0.848888
2024-04-08 04:29:20,851 - trainer - INFO -     precision      : 0.869582
2024-04-08 04:29:20,851 - trainer - INFO -     recall         : 0.85206
2024-04-08 04:29:20,851 - trainer - INFO -     val_loss       : 0.55719
2024-04-08 04:29:20,851 - trainer - INFO -     val_accuracy   : 0.810784
2024-04-08 04:29:20,851 - trainer - INFO -     val_macro_f    : 0.807874
2024-04-08 04:29:20,851 - trainer - INFO -     val_precision  : 0.832976
2024-04-08 04:29:20,851 - trainer - INFO -     val_recall     : 0.810784
2024-04-08 04:29:20,851 - trainer - INFO -     test_loss      : 0.566789
2024-04-08 04:29:20,851 - trainer - INFO -     test_accuracy  : 0.811014
2024-04-08 04:29:20,851 - trainer - INFO -     test_macro_f   : 0.807443
2024-04-08 04:29:20,851 - trainer - INFO -     test_precision : 0.831903
2024-04-08 04:29:20,851 - trainer - INFO -     test_recall    : 0.811014
2024-04-08 04:31:36,051 - train - INFO - PretrainedBaseline(
  (model): RobertaForSequenceClassification(
    (roberta): RobertaModel(
      (embeddings): RobertaEmbeddings(
        (word_embeddings): Embedding(50265, 768, padding_idx=0)
        (position_embeddings): Embedding(514, 768, padding_idx=0)
        (token_type_embeddings): Embedding(1, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): RobertaEncoder(
        (layer): ModuleList(
          (0): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
    )
    (classifier): RobertaClassificationHead(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (dropout): Dropout(p=0.1, inplace=False)
      (out_proj): Linear(in_features=768, out_features=15, bias=True)
    )
  )
)
Trainable params: 46,690,575
Freeze params: 0
2024-04-08 04:48:46,361 - trainer - INFO -     epoch          : 1
2024-04-08 04:48:46,361 - trainer - INFO -     loss           : 0.725817
2024-04-08 04:48:46,361 - trainer - INFO -     accuracy       : 0.754629
2024-04-08 04:48:46,361 - trainer - INFO -     macro_f        : 0.7419
2024-04-08 04:48:46,361 - trainer - INFO -     precision      : 0.76274
2024-04-08 04:48:46,361 - trainer - INFO -     recall         : 0.754629
2024-04-08 04:48:46,361 - trainer - INFO -     val_loss       : 0.586292
2024-04-08 04:48:46,361 - trainer - INFO -     val_accuracy   : 0.794294
2024-04-08 04:48:46,361 - trainer - INFO -     val_macro_f    : 0.794471
2024-04-08 04:48:46,361 - trainer - INFO -     val_precision  : 0.825371
2024-04-08 04:48:46,361 - trainer - INFO -     val_recall     : 0.794294
2024-04-08 04:48:46,361 - trainer - INFO -     test_loss      : 0.591612
2024-04-08 04:48:46,361 - trainer - INFO -     test_accuracy  : 0.796364
2024-04-08 04:48:46,361 - trainer - INFO -     test_macro_f   : 0.796806
2024-04-08 04:48:46,361 - trainer - INFO -     test_precision : 0.826598
2024-04-08 04:48:46,361 - trainer - INFO -     test_recall    : 0.796364
2024-04-08 05:05:56,202 - trainer - INFO -     epoch          : 2
2024-04-08 05:05:56,202 - trainer - INFO -     loss           : 0.53063
2024-04-08 05:05:56,202 - trainer - INFO -     accuracy       : 0.815425
2024-04-08 05:05:56,202 - trainer - INFO -     macro_f        : 0.810673
2024-04-08 05:05:56,202 - trainer - INFO -     precision      : 0.834542
2024-04-08 05:05:56,202 - trainer - INFO -     recall         : 0.815425
2024-04-08 05:05:56,202 - trainer - INFO -     val_loss       : 0.557951
2024-04-08 05:05:56,202 - trainer - INFO -     val_accuracy   : 0.800966
2024-04-08 05:05:56,202 - trainer - INFO -     val_macro_f    : 0.78879
2024-04-08 05:05:56,202 - trainer - INFO -     val_precision  : 0.808303
2024-04-08 05:05:56,202 - trainer - INFO -     val_recall     : 0.800966
2024-04-08 05:05:56,202 - trainer - INFO -     test_loss      : 0.559947
2024-04-08 05:05:56,202 - trainer - INFO -     test_accuracy  : 0.806949
2024-04-08 05:05:56,202 - trainer - INFO -     test_macro_f   : 0.795456
2024-04-08 05:05:56,202 - trainer - INFO -     test_precision : 0.812596
2024-04-08 05:05:56,202 - trainer - INFO -     test_recall    : 0.806949
2024-04-08 05:23:10,067 - trainer - INFO -     epoch          : 3
2024-04-08 05:23:10,067 - trainer - INFO -     loss           : 0.420587
2024-04-08 05:23:10,067 - trainer - INFO -     accuracy       : 0.852041
2024-04-08 05:23:10,067 - trainer - INFO -     macro_f        : 0.848725
2024-04-08 05:23:10,067 - trainer - INFO -     precision      : 0.869478
2024-04-08 05:23:10,069 - trainer - INFO -     recall         : 0.852041
2024-04-08 05:23:10,069 - trainer - INFO -     val_loss       : 0.557537
2024-04-08 05:23:10,069 - trainer - INFO -     val_accuracy   : 0.811091
2024-04-08 05:23:10,069 - trainer - INFO -     val_macro_f    : 0.804553
2024-04-08 05:23:10,069 - trainer - INFO -     val_precision  : 0.827066
2024-04-08 05:23:10,069 - trainer - INFO -     val_recall     : 0.811091
2024-04-08 05:23:10,069 - trainer - INFO -     test_loss      : 0.561388
2024-04-08 05:23:10,069 - trainer - INFO -     test_accuracy  : 0.815923
2024-04-08 05:23:10,069 - trainer - INFO -     test_macro_f   : 0.809584
2024-04-08 05:23:10,069 - trainer - INFO -     test_precision : 0.831003
2024-04-08 05:23:10,069 - trainer - INFO -     test_recall    : 0.815923
2024-04-08 05:25:23,564 - train - INFO - PretrainedBaseline(
  (model): RobertaForSequenceClassification(
    (roberta): RobertaModel(
      (embeddings): RobertaEmbeddings(
        (word_embeddings): Embedding(50265, 768, padding_idx=0)
        (position_embeddings): Embedding(514, 768, padding_idx=0)
        (token_type_embeddings): Embedding(1, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): RobertaEncoder(
        (layer): ModuleList(
          (0): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
    )
    (classifier): RobertaClassificationHead(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (dropout): Dropout(p=0.1, inplace=False)
      (out_proj): Linear(in_features=768, out_features=15, bias=True)
    )
  )
)
Trainable params: 46,690,575
Freeze params: 0
2024-04-08 05:42:34,129 - trainer - INFO -     epoch          : 1
2024-04-08 05:42:34,129 - trainer - INFO -     loss           : 0.723023
2024-04-08 05:42:34,129 - trainer - INFO -     accuracy       : 0.755913
2024-04-08 05:42:34,129 - trainer - INFO -     macro_f        : 0.742448
2024-04-08 05:42:34,129 - trainer - INFO -     precision      : 0.763496
2024-04-08 05:42:34,129 - trainer - INFO -     recall         : 0.755913
2024-04-08 05:42:34,129 - trainer - INFO -     val_loss       : 0.594274
2024-04-08 05:42:34,129 - trainer - INFO -     val_accuracy   : 0.791149
2024-04-08 05:42:34,129 - trainer - INFO -     val_macro_f    : 0.782136
2024-04-08 05:42:34,129 - trainer - INFO -     val_precision  : 0.806563
2024-04-08 05:42:34,129 - trainer - INFO -     val_recall     : 0.791149
2024-04-08 05:42:34,129 - trainer - INFO -     test_loss      : 0.597052
2024-04-08 05:42:34,129 - trainer - INFO -     test_accuracy  : 0.791149
2024-04-08 05:42:34,129 - trainer - INFO -     test_macro_f   : 0.782014
2024-04-08 05:42:34,129 - trainer - INFO -     test_precision : 0.803156
2024-04-08 05:42:34,129 - trainer - INFO -     test_recall    : 0.791149
2024-04-08 05:59:43,499 - trainer - INFO -     epoch          : 2
2024-04-08 05:59:43,499 - trainer - INFO -     loss           : 0.530587
2024-04-08 05:59:43,499 - trainer - INFO -     accuracy       : 0.814562
2024-04-08 05:59:43,499 - trainer - INFO -     macro_f        : 0.808995
2024-04-08 05:59:43,499 - trainer - INFO -     precision      : 0.831558
2024-04-08 05:59:43,499 - trainer - INFO -     recall         : 0.814562
2024-04-08 05:59:43,499 - trainer - INFO -     val_loss       : 0.540894
2024-04-08 05:59:43,499 - trainer - INFO -     val_accuracy   : 0.810094
2024-04-08 05:59:43,499 - trainer - INFO -     val_macro_f    : 0.804877
2024-04-08 05:59:43,499 - trainer - INFO -     val_precision  : 0.828435
2024-04-08 05:59:43,499 - trainer - INFO -     val_recall     : 0.810094
2024-04-08 05:59:43,499 - trainer - INFO -     test_loss      : 0.54634
2024-04-08 05:59:43,499 - trainer - INFO -     test_accuracy  : 0.812088
2024-04-08 05:59:43,499 - trainer - INFO -     test_macro_f   : 0.808236
2024-04-08 05:59:43,499 - trainer - INFO -     test_precision : 0.831662
2024-04-08 05:59:43,499 - trainer - INFO -     test_recall    : 0.812088
2024-04-08 06:16:56,427 - trainer - INFO -     epoch          : 3
2024-04-08 06:16:56,427 - trainer - INFO -     loss           : 0.421146
2024-04-08 06:16:56,427 - trainer - INFO -     accuracy       : 0.852961
2024-04-08 06:16:56,427 - trainer - INFO -     macro_f        : 0.849537
2024-04-08 06:16:56,427 - trainer - INFO -     precision      : 0.869962
2024-04-08 06:16:56,427 - trainer - INFO -     recall         : 0.852961
2024-04-08 06:16:56,427 - trainer - INFO -     val_loss       : 0.55952
2024-04-08 06:16:56,427 - trainer - INFO -     val_accuracy   : 0.806182
2024-04-08 06:16:56,427 - trainer - INFO -     val_macro_f    : 0.80596
2024-04-08 06:16:56,427 - trainer - INFO -     val_precision  : 0.834486
2024-04-08 06:16:56,427 - trainer - INFO -     val_recall     : 0.806182
2024-04-08 06:16:56,427 - trainer - INFO -     test_loss      : 0.564322
2024-04-08 06:16:56,427 - trainer - INFO -     test_accuracy  : 0.813929
2024-04-08 06:16:56,427 - trainer - INFO -     test_macro_f   : 0.814193
2024-04-08 06:16:56,427 - trainer - INFO -     test_precision : 0.842382
2024-04-08 06:16:56,427 - trainer - INFO -     test_recall    : 0.813929
2024-05-01 22:41:23,285 - train - INFO - PretrainedBaseline(
  (model): RobertaForSequenceClassification(
    (roberta): RobertaModel(
      (embeddings): RobertaEmbeddings(
        (word_embeddings): Embedding(50265, 768, padding_idx=0)
        (position_embeddings): Embedding(514, 768, padding_idx=0)
        (token_type_embeddings): Embedding(1, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): RobertaEncoder(
        (layer): ModuleList(
          (0): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
    )
    (classifier): RobertaClassificationHead(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (dropout): Dropout(p=0.1, inplace=False)
      (out_proj): Linear(in_features=768, out_features=15, bias=True)
    )
  )
)
Trainable params: 46,690,575
Freeze params: 0
2024-05-01 22:58:29,507 - trainer - INFO -     epoch          : 1
2024-05-01 22:58:29,507 - trainer - INFO -     loss           : 0.723023
2024-05-01 22:58:29,507 - trainer - INFO -     accuracy       : 0.755913
2024-05-01 22:58:29,522 - trainer - INFO -     macro_f        : 0.742448
2024-05-01 22:58:29,522 - trainer - INFO -     precision      : 0.763496
2024-05-01 22:58:29,522 - trainer - INFO -     recall         : 0.755913
2024-05-01 22:58:29,522 - trainer - INFO -     val_loss       : 0.594274
2024-05-01 22:58:29,522 - trainer - INFO -     val_accuracy   : 0.791149
2024-05-01 22:58:29,522 - trainer - INFO -     val_macro_f    : 0.782136
2024-05-01 22:58:29,522 - trainer - INFO -     val_precision  : 0.806563
2024-05-01 22:58:29,522 - trainer - INFO -     val_recall     : 0.791149
2024-05-01 22:58:29,522 - trainer - INFO -     test_loss      : 0.597052
2024-05-01 22:58:29,522 - trainer - INFO -     test_accuracy  : 0.791149
2024-05-01 22:58:29,522 - trainer - INFO -     test_macro_f   : 0.782014
2024-05-01 22:58:29,522 - trainer - INFO -     test_precision : 0.803156
2024-05-01 22:58:29,522 - trainer - INFO -     test_recall    : 0.791149
2024-05-01 23:15:39,451 - trainer - INFO -     epoch          : 2
2024-05-01 23:15:39,451 - trainer - INFO -     loss           : 0.530587
2024-05-01 23:15:39,451 - trainer - INFO -     accuracy       : 0.814562
2024-05-01 23:15:39,451 - trainer - INFO -     macro_f        : 0.808995
2024-05-01 23:15:39,451 - trainer - INFO -     precision      : 0.831558
2024-05-01 23:15:39,451 - trainer - INFO -     recall         : 0.814562
2024-05-01 23:15:39,451 - trainer - INFO -     val_loss       : 0.540894
2024-05-01 23:15:39,451 - trainer - INFO -     val_accuracy   : 0.810094
2024-05-01 23:15:39,451 - trainer - INFO -     val_macro_f    : 0.804877
2024-05-01 23:15:39,451 - trainer - INFO -     val_precision  : 0.828435
2024-05-01 23:15:39,451 - trainer - INFO -     val_recall     : 0.810094
2024-05-01 23:15:39,451 - trainer - INFO -     test_loss      : 0.54634
2024-05-01 23:15:39,451 - trainer - INFO -     test_accuracy  : 0.812088
2024-05-01 23:15:39,451 - trainer - INFO -     test_macro_f   : 0.808236
2024-05-01 23:15:39,451 - trainer - INFO -     test_precision : 0.831662
2024-05-01 23:15:39,451 - trainer - INFO -     test_recall    : 0.812088
2024-05-01 23:32:48,062 - trainer - INFO -     epoch          : 3
2024-05-01 23:32:48,062 - trainer - INFO -     loss           : 0.421146
2024-05-01 23:32:48,062 - trainer - INFO -     accuracy       : 0.852961
2024-05-01 23:32:48,062 - trainer - INFO -     macro_f        : 0.849537
2024-05-01 23:32:48,062 - trainer - INFO -     precision      : 0.869962
2024-05-01 23:32:48,062 - trainer - INFO -     recall         : 0.852961
2024-05-01 23:32:48,062 - trainer - INFO -     val_loss       : 0.55952
2024-05-01 23:32:48,062 - trainer - INFO -     val_accuracy   : 0.806182
2024-05-01 23:32:48,062 - trainer - INFO -     val_macro_f    : 0.80596
2024-05-01 23:32:48,062 - trainer - INFO -     val_precision  : 0.834486
2024-05-01 23:32:48,062 - trainer - INFO -     val_recall     : 0.806182
2024-05-01 23:32:48,062 - trainer - INFO -     test_loss      : 0.564322
2024-05-01 23:32:48,062 - trainer - INFO -     test_accuracy  : 0.813929
2024-05-01 23:32:48,062 - trainer - INFO -     test_macro_f   : 0.814193
2024-05-01 23:32:48,062 - trainer - INFO -     test_precision : 0.842382
2024-05-01 23:32:48,062 - trainer - INFO -     test_recall    : 0.813929
2024-05-01 23:34:56,589 - train - INFO - PretrainedBaseline(
  (model): RobertaForSequenceClassification(
    (roberta): RobertaModel(
      (embeddings): RobertaEmbeddings(
        (word_embeddings): Embedding(50265, 768, padding_idx=0)
        (position_embeddings): Embedding(514, 768, padding_idx=0)
        (token_type_embeddings): Embedding(1, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): RobertaEncoder(
        (layer): ModuleList(
          (0): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
    )
    (classifier): RobertaClassificationHead(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (dropout): Dropout(p=0.1, inplace=False)
      (out_proj): Linear(in_features=768, out_features=15, bias=True)
    )
  )
)
Trainable params: 46,690,575
Freeze params: 0
2024-05-01 23:39:04,944 - train - INFO - PretrainedBaseline(
  (model): RobertaForSequenceClassification(
    (roberta): RobertaModel(
      (embeddings): RobertaEmbeddings(
        (word_embeddings): Embedding(50265, 768, padding_idx=0)
        (position_embeddings): Embedding(514, 768, padding_idx=0)
        (token_type_embeddings): Embedding(1, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): RobertaEncoder(
        (layer): ModuleList(
          (0): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
    )
    (classifier): RobertaClassificationHead(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (dropout): Dropout(p=0.1, inplace=False)
      (out_proj): Linear(in_features=768, out_features=15, bias=True)
    )
  )
)
Trainable params: 46,690,575
Freeze params: 0
2024-05-01 23:56:11,320 - trainer - INFO -     epoch          : 1
2024-05-01 23:56:11,320 - trainer - INFO -     loss           : 0.726696
2024-05-01 23:56:11,320 - trainer - INFO -     accuracy       : 0.754533
2024-05-01 23:56:11,320 - trainer - INFO -     macro_f        : 0.741514
2024-05-01 23:56:11,320 - trainer - INFO -     precision      : 0.762361
2024-05-01 23:56:11,320 - trainer - INFO -     recall         : 0.754533
2024-05-01 23:56:11,320 - trainer - INFO -     val_loss       : 0.59657
2024-05-01 23:56:11,320 - trainer - INFO -     val_accuracy   : 0.787237
2024-05-01 23:56:11,320 - trainer - INFO -     val_macro_f    : 0.785655
2024-05-01 23:56:11,320 - trainer - INFO -     val_precision  : 0.817185
2024-05-01 23:56:11,320 - trainer - INFO -     val_recall     : 0.787237
2024-05-01 23:56:11,320 - trainer - INFO -     test_loss      : 0.598162
2024-05-01 23:56:11,320 - trainer - INFO -     test_accuracy  : 0.789768
2024-05-01 23:56:11,320 - trainer - INFO -     test_macro_f   : 0.789421
2024-05-01 23:56:11,320 - trainer - INFO -     test_precision : 0.818609
2024-05-01 23:56:11,320 - trainer - INFO -     test_recall    : 0.789768
2024-05-02 00:13:17,761 - trainer - INFO -     epoch          : 2
2024-05-02 00:13:17,761 - trainer - INFO -     loss           : 0.531923
2024-05-02 00:13:17,761 - trainer - INFO -     accuracy       : 0.813843
2024-05-02 00:13:17,761 - trainer - INFO -     macro_f        : 0.809089
2024-05-02 00:13:17,761 - trainer - INFO -     precision      : 0.833361
2024-05-02 00:13:17,761 - trainer - INFO -     recall         : 0.813843
2024-05-02 00:13:17,761 - trainer - INFO -     val_loss       : 0.548616
2024-05-02 00:13:17,761 - trainer - INFO -     val_accuracy   : 0.805875
2024-05-02 00:13:17,761 - trainer - INFO -     val_macro_f    : 0.804807
2024-05-02 00:13:17,761 - trainer - INFO -     val_precision  : 0.833785
2024-05-02 00:13:17,761 - trainer - INFO -     val_recall     : 0.805875
2024-05-02 00:13:17,761 - trainer - INFO -     test_loss      : 0.553998
2024-05-02 00:13:17,761 - trainer - INFO -     test_accuracy  : 0.806029
2024-05-02 00:13:17,761 - trainer - INFO -     test_macro_f   : 0.805015
2024-05-02 00:13:17,761 - trainer - INFO -     test_precision : 0.832353
2024-05-02 00:13:17,761 - trainer - INFO -     test_recall    : 0.806029
2024-05-02 00:30:24,011 - trainer - INFO -     epoch          : 3
2024-05-02 00:30:24,011 - trainer - INFO -     loss           : 0.420849
2024-05-02 00:30:24,011 - trainer - INFO -     accuracy       : 0.853345
2024-05-02 00:30:24,011 - trainer - INFO -     macro_f        : 0.850375
2024-05-02 00:30:24,011 - trainer - INFO -     precision      : 0.871452
2024-05-02 00:30:24,011 - trainer - INFO -     recall         : 0.853345
2024-05-02 00:30:24,011 - trainer - INFO -     val_loss       : 0.558953
2024-05-02 00:30:24,011 - trainer - INFO -     val_accuracy   : 0.807793
2024-05-02 00:30:24,011 - trainer - INFO -     val_macro_f    : 0.803836
2024-05-02 00:30:24,011 - trainer - INFO -     val_precision  : 0.828789
2024-05-02 00:30:24,011 - trainer - INFO -     val_recall     : 0.807793
2024-05-02 00:30:24,011 - trainer - INFO -     test_loss      : 0.558451
2024-05-02 00:30:24,011 - trainer - INFO -     test_accuracy  : 0.811781
2024-05-02 00:30:24,011 - trainer - INFO -     test_macro_f   : 0.810246
2024-05-02 00:30:24,011 - trainer - INFO -     test_precision : 0.835265
2024-05-02 00:30:24,011 - trainer - INFO -     test_recall    : 0.811781
2024-05-02 00:32:32,888 - train - INFO - PretrainedBaseline(
  (model): RobertaForSequenceClassification(
    (roberta): RobertaModel(
      (embeddings): RobertaEmbeddings(
        (word_embeddings): Embedding(50265, 768, padding_idx=0)
        (position_embeddings): Embedding(514, 768, padding_idx=0)
        (token_type_embeddings): Embedding(1, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): RobertaEncoder(
        (layer): ModuleList(
          (0): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
    )
    (classifier): RobertaClassificationHead(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (dropout): Dropout(p=0.1, inplace=False)
      (out_proj): Linear(in_features=768, out_features=15, bias=True)
    )
  )
)
Trainable params: 46,690,575
Freeze params: 0
2024-05-02 00:49:46,120 - trainer - INFO -     epoch          : 1
2024-05-02 00:49:46,120 - trainer - INFO -     loss           : 0.72554
2024-05-02 00:49:46,120 - trainer - INFO -     accuracy       : 0.753574
2024-05-02 00:49:46,120 - trainer - INFO -     macro_f        : 0.740251
2024-05-02 00:49:46,120 - trainer - INFO -     precision      : 0.760942
2024-05-02 00:49:46,120 - trainer - INFO -     recall         : 0.753574
2024-05-02 00:49:46,120 - trainer - INFO -     val_loss       : 0.600481
2024-05-02 00:49:46,120 - trainer - INFO -     val_accuracy   : 0.787697
2024-05-02 00:49:46,120 - trainer - INFO -     val_macro_f    : 0.784297
2024-05-02 00:49:46,120 - trainer - INFO -     val_precision  : 0.810974
2024-05-02 00:49:46,120 - trainer - INFO -     val_recall     : 0.787697
2024-05-02 00:49:46,120 - trainer - INFO -     test_loss      : 0.597626
2024-05-02 00:49:46,120 - trainer - INFO -     test_accuracy  : 0.795137
2024-05-02 00:49:46,120 - trainer - INFO -     test_macro_f   : 0.791127
2024-05-02 00:49:46,120 - trainer - INFO -     test_precision : 0.816719
2024-05-02 00:49:46,120 - trainer - INFO -     test_recall    : 0.795137
2024-05-02 01:06:49,629 - trainer - INFO -     epoch          : 2
2024-05-02 01:06:49,629 - trainer - INFO -     loss           : 0.534407
2024-05-02 01:06:49,629 - trainer - INFO -     accuracy       : 0.812702
2024-05-02 01:06:49,629 - trainer - INFO -     macro_f        : 0.807035
2024-05-02 01:06:49,629 - trainer - INFO -     precision      : 0.829973
2024-05-02 01:06:49,629 - trainer - INFO -     recall         : 0.812702
2024-05-02 01:06:49,629 - trainer - INFO -     val_loss       : 0.568537
2024-05-02 01:06:49,629 - trainer - INFO -     val_accuracy   : 0.797055
2024-05-02 01:06:49,629 - trainer - INFO -     val_macro_f    : 0.795353
2024-05-02 01:06:49,629 - trainer - INFO -     val_precision  : 0.824828
2024-05-02 01:06:49,629 - trainer - INFO -     val_recall     : 0.797055
2024-05-02 01:06:49,629 - trainer - INFO -     test_loss      : 0.57678
2024-05-02 01:06:49,629 - trainer - INFO -     test_accuracy  : 0.802961
2024-05-02 01:06:49,629 - trainer - INFO -     test_macro_f   : 0.803123
2024-05-02 01:06:49,629 - trainer - INFO -     test_precision : 0.834428
2024-05-02 01:06:49,629 - trainer - INFO -     test_recall    : 0.802961
2024-05-02 01:23:55,494 - trainer - INFO -     epoch          : 3
2024-05-02 01:23:55,494 - trainer - INFO -     loss           : 0.424345
2024-05-02 01:23:55,494 - trainer - INFO -     accuracy       : 0.850296
2024-05-02 01:23:55,494 - trainer - INFO -     macro_f        : 0.847438
2024-05-02 01:23:55,494 - trainer - INFO -     precision      : 0.868859
2024-05-02 01:23:55,494 - trainer - INFO -     recall         : 0.850296
2024-05-02 01:23:55,494 - trainer - INFO -     val_loss       : 0.560843
2024-05-02 01:23:55,494 - trainer - INFO -     val_accuracy   : 0.808713
2024-05-02 01:23:55,494 - trainer - INFO -     val_macro_f    : 0.79824
2024-05-02 01:23:55,494 - trainer - INFO -     val_precision  : 0.818775
2024-05-02 01:23:55,494 - trainer - INFO -     val_recall     : 0.808713
2024-05-02 01:23:55,494 - trainer - INFO -     test_loss      : 0.556736
2024-05-02 01:23:55,494 - trainer - INFO -     test_accuracy  : 0.814465
2024-05-02 01:23:55,494 - trainer - INFO -     test_macro_f   : 0.804657
2024-05-02 01:23:55,494 - trainer - INFO -     test_precision : 0.822596
2024-05-02 01:23:55,494 - trainer - INFO -     test_recall    : 0.814465
